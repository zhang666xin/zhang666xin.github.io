<!--
	作者：Sariay
	时间：2018-09-25
	描述：There may be a bug, but don't worry, QiLing(器灵) says that it can work normally!
-->


	<!DOCTYPE html>
	<html>
		

<head>
	<title>折柳叶轻吹</title>
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="apple-mobile-web-app-title" content="Amaze UI" />
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0, user-scalable=no">
    <meta name="author" content="Mr.zx">
    <meta name="keywords" content="" />
    <meta name="description" content="你说旧梦已碎，解不开过往心结。" />
   	<!-- css -->
	<link rel="stylesheet" href="/css/style.css">

	<!-- favicon -->
	<link href="/img/favicon.ico" rel="Shortcut Icon" type="image/ico">
	
	<!-- font-awesome -->
	<link href="https://cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">
</head>
	<body>	
		<!--Preloader-->
<div id="preloader">
	<div id="status">
		<img alt="PRELOADER" src="/img/logo.png">
	</div>
</div>
<!--Preloader end-->

<!-- header -->

	<header id="header-bg-2">

	
		<div id="cd-logo"><a href="/"><img src="/img/logo.png" alt="Logo"></a></div>
	
	
	<!-- motto or description -->
		
 		<p class="motto">记录生活美</p>
	
	
	<!-- current page name or title -->
	
		
		
			
			<p class=page-name>当前文章&nbsp;:&nbsp;《》</p>
			
		
	
          
   <!-- others: such as change-bg, time... -->
   <style>
	.page-name-other {
		color: #000000;
		text-align: center;
		font-size: 20px;
		line-height: 1.4em;
		font-family: "KaiTi", "STXingkai", "Source Sans Pro", "Segoe UI", "Lucida Grande", Helvetica, Arial, "Microsoft YaHei", FreeSans, Arimo, "Droid Sans", "wenquanyi micro hei", "Hiragino Sans GB", "Hiragino Sans GB W3", FontAwesome, sans-serif;
		margin: 100px 20px 0 20px;
	}

	.page-name-other p{
		margin-bottom: 150px;
	}  
   </style>
   
   <div class="page-name-other">
		<p>
			<span>像风吹了八万里，不问归期。</span>
			<span>记录生活，记录美！   ---Mr.zx</span>
		</p>
		<p>
			3/1/2019  
			<style type="text/css">
	header:after {
		content: '';
		position: relative;
		top: 0;
		left: 0;
		height: 100%;
		width: 100%;
		background: #222222;
		opacity: .5;
		z-index: -1;
	}
	
	.change-header-bg{
		font-style: normal;
	}
	.change-header-bg i{
		text-align: center;
		cursor: pointer;
		pointer-events: bounding-box;
	}
	@media(max-width:512px) {
		.change-header-bg {
			display: none;
			visibility: hidden;
		}
	}
	
</style>

<script type="text/javascript">
	function changeHeaderBg(){
		var random_bg = Math.floor(Math.random() * 109 + 1);
		var bg = 'url(https://zhang666xin.github.io/Random-img/' + random_bg + '.jpg)';
		$("#header-bg-2").css("background-image", bg);
	}
</script>

<span class="change-header-bg">
	——&nbsp;<i  class="fa fa-camera-retro" onclick="changeHeaderBg()"></i>	
</span>
		</p>	
		
    </div>	
</header>

<!-- nav -->
<div id="cd-nav">
	<a href="#0" title="menu" class="cd-nav-trigger"><span></span></a>

	<nav id="cd-main-nav">
		<ul>
			
      		<li class="fa fa-/">
           		<a href="/" title="主页">主页</a>	
      		</li>
    		
      		<li class="fa fa-/archives">
           		<a href="/archives" title="归档">归档</a>	
      		</li>
    		
      		<li class="fa fa-/categories">
           		<a href="/categories" title="分类">分类</a>	
      		</li>
    		
      		<li class="fa fa-/tags">
           		<a href="/tags" title="标签">标签</a>	
      		</li>
    		
      		<li class="fa fa-/about">
           		<a href="/about" title="关于">关于</a>	
      		</li>
    		
      		<li class="fa fa-/gallery">
           		<a href="/gallery" title="相册">相册</a>	
      		</li>
    		
    		
        	
            	<li class="fa fa-/search"><a href="javascript:;" class="popup-trigger" title="Search">搜索</a></li>
        	
		</ul>
	</nav>
</div>

		<!--main-->
		<main> 
		<div class="page-container">
		<!-- content srart -->
<div class="am-g am-g-fixed blog-fixed blog-content">
	<div class="am-u-md-8 am-u-sm-12">

		<article class="am-article blog-article-p">

			<div class="am-article-hd">
				


				<h1 class="am-article-title blog-text-center">
					
					
				</h1>

				<p class="am-article-meta blog-text-center">
					<span>
						<i class="fa fa-clock-o"></i> 
						<a href="/2019/03/01/机器学习入门笔记/" itemprop="url">
	<time datetime="2019-03-01T14:40:31.680Z" itemprop="datePublished">
  		2019-03-01
  </time>
</a>    
&nbsp;
					</span>
					
					<span>						
						
					</span>
				</p>
			</div>

			<div class="am-article-bd">
				<div class="content" id="post-content">
					
						<pre><code>title: 机器学习入门笔记
cover: /img/12.jpg
categories: 机器学习
tags: 机器学习
</code></pre><h1 id="机器学习入门："><a href="#机器学习入门：" class="headerlink" title="机器学习入门："></a>机器学习入门：</h1><h3 id="1、机器学习算法分类："><a href="#1、机器学习算法分类：" class="headerlink" title="1、机器学习算法分类："></a><strong>1、机器学习算法分类：</strong></h3><p>●监督学习：</p>
<p>traget–&gt;类别 –&gt;分类问题  算法有：k-近邻（knn）、贝叶斯分类、决策树、随机森林、逻辑回归</p>
<p>traget–&gt;连续型的数据 –&gt;回归问题  算法有：线性回归、岭回归</p>
<p>●非监督学习：无目标值  算法有：聚类 K-means</p>
<h3 id="2、数据集："><a href="#2、数据集：" class="headerlink" title="2、数据集："></a><strong>2、数据集：</strong></h3><p>数据集=特征值（data）+目标值（target）</p>
<p>1）学习阶段可用数据集：sklearn、kaggle、UCI</p>
<p>2）使用sklearn数据集sklearn.datasets：</p>
<p>load_<em>()               </em>是数据集的名字，获取小规模的数据集  eg: sklearn.datasets.load_boston()</p>
<p>fetch_<em>(data_home=None)        </em>是数据集的名字，获取大规模的数据集，需要在网上下载  data_home表示数据集下载到哪（目录）默认是~/scikit_learn_data/   eg：<strong>sklearn.datasets.fetch_20newsgroups(data_home=None,subset=’train’)</strong></p>
<p>subset：可选train、test、all  –选择要加载的数据集</p>
<p>3）load和fetch返回的数据类型是datasets.base.Bunch(字典格式 键值对  获取值：values=dict[‘key’]或values=bunch.key)</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> load_iris

iris<span class="token operator">=</span>load_iris<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'特征：'</span><span class="token punctuation">,</span>iris<span class="token punctuation">.</span>feature_names<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'标签：'</span><span class="token punctuation">,</span>iris<span class="token punctuation">.</span>target_names<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"第一个样本的特征："</span><span class="token punctuation">,</span>iris<span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"第一个样本的标签："</span><span class="token punctuation">,</span>iris<span class="token punctuation">.</span>target<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>字典里的五个内容：</p>
<p>●data：特征数据数组，是[n_samples*n_features]的二维数组</p>
<p>●target：标签数组，是n_samples的一维数组</p>
<p>●DESCR：数据描述</p>
<p>●feature_names：有特征名、新闻数据，没有手写数字、回归数据集</p>
<p>●target_names：标签名</p>
<p>4）数据集的划分：将数据集划分为训练集（用于训练、构建模型）和测试集（在模型检验时使用，用于评估模型是否有效，一般占总数据集的20%-30%）</p>
<p><strong>sklearn.model_selection.train_test_split()</strong>参数有：</p>
<p>●x：数据集的特征值</p>
<p>●y：数据集的标签值</p>
<p>●test_size：测试集的大小，一般为float（0.2、0.3等）默认是0.25 </p>
<p>●random_state：随机数种子（个数），计算机随机划分数据集，不同的种子（个数）会造成不同的随机采样结果，相同的种子采样结果相同</p>
<p>返回值的顺序：训练集特征值x_train、测试集特征值x_test、训练集目标值y_train、测试集目标值y_test</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split

x<span class="token operator">=</span>iris<span class="token punctuation">.</span>data
y<span class="token operator">=</span>iris<span class="token punctuation">.</span>target
x_train<span class="token punctuation">,</span>x_test<span class="token punctuation">,</span>y_train<span class="token punctuation">,</span>y_test<span class="token operator">=</span>train_test_split<span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">,</span>test_size<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">,</span>random_state<span class="token operator">=</span><span class="token number">22</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'训练集的特征值：\n'</span><span class="token punctuation">,</span>x_train<span class="token punctuation">,</span>x_train<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="3、机器学习开发流程："><a href="#3、机器学习开发流程：" class="headerlink" title="3、机器学习开发流程："></a><strong>3、机器学习开发流程：</strong></h3><p>1）获取数据</p>
<p>2）数据处理(缺失值、不符要求数据等)</p>
<p>3）特征工程（将特征处理成计算机能识别的数据）</p>
<p>4）机器学习算法训练模型</p>
<p>5）模型评估</p>
<p>6）应用</p>
<p><img src="D:\Machine learning\机器学习流程图.png" alt=""></p>
<h3 id="4、如何学机器学习："><a href="#4、如何学机器学习：" class="headerlink" title="4、如何学机器学习："></a><strong>4、如何学机器学习：</strong></h3><p>1）入门：视频、书等</p>
<p>2）项目实战：视频、书、csdn等</p>
<p>3）*钻研算法推荐书：机器学习 -周志华  （西瓜书）、统计学习方法-李航、深度学习-被称为‘花书’（封皮有很多花）</p>
<h3 id="5、机器学习框架："><a href="#5、机器学习框架：" class="headerlink" title="5、机器学习框架："></a>5、机器学习框架：</h3><p>1）传统机器学习框架：sklearn</p>
<p>sklearn包含的内容：分类Classification、回归Regression、聚类Clustering、降维Dimensionality reduction、模型选择Model selection、特征工程(数据预处理)Preprocessing</p>
<p>2）深度学习框架：Tensorflow（最常见）、Pytorch、Caffe2、theano、Chainer</p>
<h3 id="6、特征工程："><a href="#6、特征工程：" class="headerlink" title="6、特征工程："></a>6、特征工程：</h3><p>1）特征工程是将属于类别的特征–&gt;one-hot编码</p>
<p>2）可用工具：</p>
<p>pandas：一个数据读取非常方便以及基本的处理格式的工具，用于数据清洗、数据处理</p>
<p>sklearn：对于特征的处理提供了强大的接口，用于特征工程</p>
<p><strong>3）特征工程内容：</strong></p>
<p><strong>a、特征抽取（提取）：将任意数据（如文本或图像）转换为可用于机器学习的数字特征，有字典特征提取（特征离散化）、文本特征提取、图像特征提取</strong> </p>
<p>特征提取API：sklearn.feature_extraction</p>
<p><strong>a-1、字典特征提取：sklearn.feature_extraction.DictVectorizer(sparse=True…)</strong></p>
<p>DictVectorizer是一个父类（转换器类）</p>
<p>●DictVectorizer.fit_transform(x)：x是字典或者包含字典的迭代器返回值，返回的结果是sparse（稀疏）矩阵</p>
<p>●DictVectorizer.inverse_transform(x)：x是array数组或者sparse矩阵，返回的结果是转换之前的数据格式</p>
<p>●DictVectorizer.get_feature_names()：返回类别名称</p>
<p>稀疏矩阵 —-将非零值按位置表示出来 eg： (0, 1)    1.0  表示1在第0行第一列   且右边1.0位置无0存在</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_extraction <span class="token keyword">import</span> DictVectorizer

data<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token string">'city'</span><span class="token punctuation">:</span><span class="token string">'北京'</span><span class="token punctuation">,</span><span class="token string">'temperature'</span><span class="token punctuation">:</span><span class="token number">100</span><span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token punctuation">{</span><span class="token string">'city'</span><span class="token punctuation">:</span><span class="token string">'上海'</span><span class="token punctuation">,</span><span class="token string">'temperature'</span><span class="token punctuation">:</span><span class="token number">60</span><span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token punctuation">{</span><span class="token string">'city'</span><span class="token punctuation">:</span><span class="token string">'深圳'</span><span class="token punctuation">,</span><span class="token string">'temperature'</span><span class="token punctuation">:</span><span class="token number">30</span><span class="token punctuation">}</span><span class="token punctuation">]</span>

<span class="token comment" spellcheck="true">#1、实例化一个转换器类</span>
transfer<span class="token operator">=</span>DictVectorizer<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#transfer=DictVectorizer(sparse=False)</span>
<span class="token comment" spellcheck="true">#2、调用fit_transform()</span>
data_new<span class="token operator">=</span>transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"特征名字：\n"</span><span class="token punctuation">,</span>transfer<span class="token punctuation">.</span>get_feature_names<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"data_new:\n"</span><span class="token punctuation">,</span>data_new<span class="token punctuation">)</span>


<span class="token number">1</span>）sparse<span class="token operator">=</span><span class="token boolean">True</span>结果：
特征名字：
 <span class="token punctuation">[</span><span class="token string">'city=上海'</span><span class="token punctuation">,</span> <span class="token string">'city=北京'</span><span class="token punctuation">,</span> <span class="token string">'city=深圳'</span><span class="token punctuation">,</span> <span class="token string">'temperature'</span><span class="token punctuation">]</span>
data_new<span class="token punctuation">:</span>
   <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>    <span class="token number">1.0</span>
  <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>    <span class="token number">100.0</span>
  <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>    <span class="token number">1.0</span>
  <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>    <span class="token number">60.0</span>
  <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>    <span class="token number">1.0</span>
  <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>    <span class="token number">30.0</span>

<span class="token number">2</span>）sparse<span class="token operator">=</span><span class="token boolean">False</span>结果： 
特征名字：
 <span class="token punctuation">[</span><span class="token string">'city=上海'</span><span class="token punctuation">,</span> <span class="token string">'city=北京'</span><span class="token punctuation">,</span> <span class="token string">'city=深圳'</span><span class="token punctuation">,</span> <span class="token string">'temperature'</span><span class="token punctuation">]</span>
data_new<span class="token punctuation">:</span>
 <span class="token punctuation">[</span><span class="token punctuation">[</span>  <span class="token number">0</span><span class="token punctuation">.</span>   <span class="token number">1</span><span class="token punctuation">.</span>   <span class="token number">0</span><span class="token punctuation">.</span> <span class="token number">100</span><span class="token punctuation">.</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span>  <span class="token number">1</span><span class="token punctuation">.</span>   <span class="token number">0</span><span class="token punctuation">.</span>   <span class="token number">0</span><span class="token punctuation">.</span>  <span class="token number">60</span><span class="token punctuation">.</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span>  <span class="token number">0</span><span class="token punctuation">.</span>   <span class="token number">0</span><span class="token punctuation">.</span>   <span class="token number">1</span><span class="token punctuation">.</span>  <span class="token number">30</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span>

<span class="token number">3</span>）<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"data_new:\n"</span><span class="token punctuation">,</span>data_new<span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#toarray也可以得到</span>
data_new<span class="token punctuation">:</span>
 <span class="token punctuation">[</span><span class="token punctuation">[</span>  <span class="token number">0</span><span class="token punctuation">.</span>   <span class="token number">1</span><span class="token punctuation">.</span>   <span class="token number">0</span><span class="token punctuation">.</span> <span class="token number">100</span><span class="token punctuation">.</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span>  <span class="token number">1</span><span class="token punctuation">.</span>   <span class="token number">0</span><span class="token punctuation">.</span>   <span class="token number">0</span><span class="token punctuation">.</span>  <span class="token number">60</span><span class="token punctuation">.</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span>  <span class="token number">0</span><span class="token punctuation">.</span>   <span class="token number">0</span><span class="token punctuation">.</span>   <span class="token number">1</span><span class="token punctuation">.</span>  <span class="token number">30</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><strong>a-2：文本特征提取：单词作为特征</strong></p>
<p><strong>方法一：sklearn.feature_extraction.text.CountVectorizer(stop_words=[])  返回的结果是词频矩阵，标点、字母不记录在内，统计的是每个样本特征单词的个数，stop_words是停用词，手动添加到列表里，如is、too等</strong></p>
<p>英文停用词表：<a href="https://blog.csdn.net/shijiebei2009/article/details/39696523/" target="_blank" rel="noopener">https://blog.csdn.net/shijiebei2009/article/details/39696523/</a></p>
<p>中文停用词表：<a href="https://blog.csdn.net/weixin_41931602/article/details/80430380" target="_blank" rel="noopener">https://blog.csdn.net/weixin_41931602/article/details/80430380</a> </p>
<p>●CountVectorizer.fit_transform(x) ：x是文本或者包含文本字符串的可迭代对象，返回的结果是sparse矩阵</p>
<p>●CountVectorizer.inverse_transform(x)：x是array数组或者sparse矩阵，返回的结果是转换之前的数据格式</p>
<p>●CountVectorizer.get_feature_names()：返回的结果是单词列表</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_extraction<span class="token punctuation">.</span>text <span class="token keyword">import</span> CountVectorizer

data<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'life is short,i like like python'</span><span class="token punctuation">,</span><span class="token string">'life is too long,i dislike python'</span><span class="token punctuation">]</span>

<span class="token comment" spellcheck="true">#1、实例化一个转换器类</span>
transfer<span class="token operator">=</span>CountVectorizer<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#2、调用fit_transform()</span>
data_new<span class="token operator">=</span>transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"特征名字：\n"</span><span class="token punctuation">,</span>transfer<span class="token punctuation">.</span>get_feature_names<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'data_new:\n'</span><span class="token punctuation">,</span>data_new<span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

结果如下：
特征名字：
 <span class="token punctuation">[</span><span class="token string">'dislike'</span><span class="token punctuation">,</span> <span class="token string">'is'</span><span class="token punctuation">,</span> <span class="token string">'life'</span><span class="token punctuation">,</span> <span class="token string">'like'</span><span class="token punctuation">,</span> <span class="token string">'long'</span><span class="token punctuation">,</span> <span class="token string">'python'</span><span class="token punctuation">,</span> <span class="token string">'short'</span><span class="token punctuation">,</span> <span class="token string">'too'</span><span class="token punctuation">]</span>
data_new<span class="token punctuation">:</span>
 <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">2</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>对于中文：</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_extraction<span class="token punctuation">.</span>text <span class="token keyword">import</span> CountVectorizer

data<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'我爱北京天安门'</span><span class="token punctuation">,</span><span class="token string">'天安门上太阳升'</span><span class="token punctuation">]</span>

<span class="token comment" spellcheck="true">#1、实例化一个转换器类</span>
transfer<span class="token operator">=</span>CountVectorizer<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#2、调用fit_transform()</span>
data_new<span class="token operator">=</span>transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"特征名字：\n"</span><span class="token punctuation">,</span>transfer<span class="token punctuation">.</span>get_feature_names<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'data_new:\n'</span><span class="token punctuation">,</span>data_new<span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

结果如下：
特征名字：
 <span class="token punctuation">[</span><span class="token string">'天安门上太阳升'</span><span class="token punctuation">,</span> <span class="token string">'我爱北京天安门'</span><span class="token punctuation">]</span>
data_new<span class="token punctuation">:</span>
 <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span> <span class="token number">1</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">1</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>中文没有英文单词的空格分割，所以以句子形式分割，若想实现中文分割效果，解决办法是结巴分词，如下：</p>
<p>结巴分词例子：</p>
<p>对字符串分割：</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> jieba

data<span class="token operator">=</span><span class="token string">'我爱北京天安门'</span>

a<span class="token operator">=</span>jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span>
结果：   <span class="token operator">&lt;</span>generator object Tokenizer<span class="token punctuation">.</span>cut at <span class="token number">0x00000202B3AD11A8</span><span class="token operator">></span>
a<span class="token operator">=</span>list<span class="token punctuation">(</span>jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span>
结果：  <span class="token punctuation">[</span><span class="token string">'我'</span><span class="token punctuation">,</span> <span class="token string">'爱'</span><span class="token punctuation">,</span> <span class="token string">'北京'</span><span class="token punctuation">,</span> <span class="token string">'天安门'</span><span class="token punctuation">]</span>
<span class="token comment" spellcheck="true">#转为str格式</span>
a<span class="token operator">=</span><span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>a<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># ''里面有一个空格</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span>
结果：  我 爱 北京 天安门
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>对列表内容分割：</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> jieba

<span class="token comment" spellcheck="true">#对中文文本分词</span>
data<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'有位客人到主人家里做客，不久，主人看到了看见主人的灶上烟囱是直的'</span><span class="token punctuation">,</span>
      <span class="token string">'不久主人家里果然失火，四周的邻居赶紧跑来救火，失火，最后火被扑灭了。'</span>
      <span class="token punctuation">]</span>

data_new<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> data<span class="token punctuation">:</span>
    data_new<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>list<span class="token punctuation">(</span>jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'data分词后结果：'</span><span class="token punctuation">,</span>data_new<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#1、实例化一个转换器类</span>
transfer<span class="token operator">=</span>CountVectorizer<span class="token punctuation">(</span>stop_words<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'一种'</span><span class="token punctuation">,</span><span class="token string">'因为'</span><span class="token punctuation">,</span><span class="token string">'所以'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#2、调用fit_transform()</span>
data_final<span class="token operator">=</span>transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data_new<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"特征名字：\n"</span><span class="token punctuation">,</span>transfer<span class="token punctuation">.</span>get_feature_names<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'data_new:\n'</span><span class="token punctuation">,</span>data_final<span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

结果如下：
data分词后结果： <span class="token punctuation">[</span><span class="token string">'有位 客人 到 主人 家里 做客 ， 不久 ， 主人 看到 了 看见 主人 的 灶 上 烟囱 是 直 的'</span><span class="token punctuation">,</span> <span class="token string">'不久 主人 家里 果然 失火 ， 四周 的 邻居 赶紧 跑 来 救火 ， 失火 ， 最后 火 被 扑灭 了 。'</span><span class="token punctuation">]</span>

特征名字：
 <span class="token punctuation">[</span><span class="token string">'不久'</span><span class="token punctuation">,</span> <span class="token string">'主人'</span><span class="token punctuation">,</span> <span class="token string">'做客'</span><span class="token punctuation">,</span> <span class="token string">'四周'</span><span class="token punctuation">,</span> <span class="token string">'失火'</span><span class="token punctuation">,</span> <span class="token string">'客人'</span><span class="token punctuation">,</span> <span class="token string">'家里'</span><span class="token punctuation">,</span> <span class="token string">'扑灭'</span><span class="token punctuation">,</span> <span class="token string">'救火'</span><span class="token punctuation">,</span> <span class="token string">'最后'</span><span class="token punctuation">,</span> <span class="token string">'有位'</span><span class="token punctuation">,</span> <span class="token string">'果然'</span><span class="token punctuation">,</span> <span class="token string">'烟囱'</span><span class="token punctuation">,</span> <span class="token string">'看到'</span><span class="token punctuation">,</span> <span class="token string">'看见'</span><span class="token punctuation">,</span> <span class="token string">'赶紧'</span><span class="token punctuation">,</span> <span class="token string">'邻居'</span><span class="token punctuation">]</span>
data_new<span class="token punctuation">:</span>
 <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span> <span class="token number">3</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">2</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>方法一弊端：方法一结果有0、1、2、3等，只是根据某个词在句子中出现的次数来分，若我们、你们等无用的词出现的次数很多时，不利于我们的分类</p>
<p>●关键词：在某一个类别的文章中，出现的次数很多，但是在其他类别的文章当中出现很少</p>
<p><strong>方法二：TfidfVectorizer   适合找关键词</strong></p>
<p>●TF-IDF主要思想：如果某个词或短语在一篇文章中出现的概率高，并且在其他文章中很少出现，则认为这个词或短语具有很好的类别区分能力，适合用来分类。</p>
<p>●TF-IDF作用：用于评估字词对于一个文件集或一个语料库中的其中一份文件的重要程度，TF-IDF=TF * IDF 值越高，越重要。</p>
<p>●TF：词频，指一个给定的词语在一篇文章中出现的频率。</p>
<p>●IDF：逆向文档频率，是一个词语普遍重要性的度量，可以由总文章除以包含该词语的文章数目，再将得到的商取以10为底的对数得到。</p>
<p>eg：有两个词 “经济” “非常”  </p>
<p>语料库共有1000篇文章，100篇文章中有非常，10篇中有经济。</p>
<p>现有两篇文章，有100个词的文章A和文章B,文章A出现10次“经济”，文章B出现10次“非常”。</p>
<p>对于文章A：TF=10/100=0.1  IDF=log 10 (1000/10)=2    TF-IDF=0.1 * 2=0.2</p>
<p>对于文章B：TF=10/100=0.1  IDF=log 10 (1000/100)=1  TF-IDF=0.1 * 1=0.1</p>
<p><strong>sklearn.feature_extraction.text.TfidfVectorizer(stop_words=None,….)</strong>   返回的结果是词的权重矩阵</p>
<p>●TfidfVectorizer.fit_transform(x)：x是文本或者包含文本字符串的可迭代对象，返回的结果是sparse矩阵</p>
<p>●TfidfVectorizer.inverse_transform(x)：x是array数组或者sparse矩阵，返回的结果是转换之前的数据格式</p>
<p>●TfidfVectorizer.get_feature_names()：返回的结果是单词列表</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_extraction<span class="token punctuation">.</span>text <span class="token keyword">import</span> TfidfVectorizer
<span class="token keyword">import</span> jieba

data<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'有位客人到主人家里做客，不久，主人看到了看见主人的灶上烟囱是直的'</span><span class="token punctuation">,</span>
      <span class="token string">'不久主人家里果然失火，四周的邻居赶紧跑来救火，失火，最后火被扑灭了。'</span>
      <span class="token punctuation">]</span>

data_new<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> data<span class="token punctuation">:</span>
    data_new<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>list<span class="token punctuation">(</span>jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'data分词后结果：'</span><span class="token punctuation">,</span>data_new<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#1、实例化一个转换器类</span>
transfer<span class="token operator">=</span>TfidfVectorizer<span class="token punctuation">(</span>stop_words<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'一种'</span><span class="token punctuation">,</span><span class="token string">'因为'</span><span class="token punctuation">,</span><span class="token string">'所以'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#2、调用fit_transform()</span>
data_final<span class="token operator">=</span>transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data_new<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"特征名字：\n"</span><span class="token punctuation">,</span>transfer<span class="token punctuation">.</span>get_feature_names<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'data_new:\n'</span><span class="token punctuation">,</span>data_final<span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

结果如下：
data分词后结果： <span class="token punctuation">[</span><span class="token string">'有位 客人 到 主人 家里 做客 ， 不久 ， 主人 看到 了 看见 主人 的 灶 上 烟囱 是 直 的'</span><span class="token punctuation">,</span> <span class="token string">'不久 主人 家里 果然 失火 ， 四周 的 邻居 赶紧 跑 来 救火 ， 失火 ， 最后 火 被 扑灭 了 。'</span><span class="token punctuation">]</span>

特征名字：
 <span class="token punctuation">[</span><span class="token string">'不久'</span><span class="token punctuation">,</span> <span class="token string">'主人'</span><span class="token punctuation">,</span> <span class="token string">'做客'</span><span class="token punctuation">,</span> <span class="token string">'四周'</span><span class="token punctuation">,</span> <span class="token string">'失火'</span><span class="token punctuation">,</span> <span class="token string">'客人'</span><span class="token punctuation">,</span> <span class="token string">'家里'</span><span class="token punctuation">,</span> <span class="token string">'扑灭'</span><span class="token punctuation">,</span> <span class="token string">'救火'</span><span class="token punctuation">,</span> <span class="token string">'最后'</span><span class="token punctuation">,</span> <span class="token string">'有位'</span><span class="token punctuation">,</span> <span class="token string">'果然'</span><span class="token punctuation">,</span> <span class="token string">'烟囱'</span><span class="token punctuation">,</span> <span class="token string">'看到'</span><span class="token punctuation">,</span> <span class="token string">'看见'</span><span class="token punctuation">,</span> <span class="token string">'赶紧'</span><span class="token punctuation">,</span> <span class="token string">'邻居'</span><span class="token punctuation">]</span>
data_new<span class="token punctuation">:</span>
 <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.20918857</span> <span class="token number">0.62756572</span> <span class="token number">0.29400724</span> <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0.29400724</span>
  <span class="token number">0.20918857</span> <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0.29400724</span> <span class="token number">0</span><span class="token punctuation">.</span>
  <span class="token number">0.29400724</span> <span class="token number">0.29400724</span> <span class="token number">0.29400724</span> <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.2010943</span>  <span class="token number">0.2010943</span>  <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0.28263102</span> <span class="token number">0.56526205</span> <span class="token number">0</span><span class="token punctuation">.</span>
  <span class="token number">0.2010943</span>  <span class="token number">0.28263102</span> <span class="token number">0.28263102</span> <span class="token number">0.28263102</span> <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0.28263102</span>
  <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0</span><span class="token punctuation">.</span>         <span class="token number">0.28263102</span> <span class="token number">0.28263102</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><strong>b、特征预处理：通过一些转换函数将特征数据转换成更加适合算法模型的特征数据过程</strong></p>
<p>●包含内容：</p>
<p>数值型数据的无量纲化： 归一化、标准化（原因：特征值大容易影响（支配）目标结果,导致值小的特征忽略）</p>
<p>●API：sklearn.preprocessing</p>
<p><strong>b-1:归一化：通过对原始数据进行变换，把数据映射到（默认为[0-1]）之间。</strong></p>
<p><img src="D:\Machine learning\归一化原理.png" alt=""></p>
<p>上面两个例子分别计算的是90和15</p>
<p><strong>sklearn.preprocessing.MinMaxScaler(feature_range=(0,1)…)   feature_range是映射的范围，返回的结果是与转换后形状相同的array</strong> </p>
<p>●MinMaxScaler.fit_transform(x)：x是numpy array格式的数据，[n_samples,n_features]二维数组，n_samples是行，表示样本数，n_features是列，表示特征</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> MinMaxScaler
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd


<span class="token comment" spellcheck="true">#1、获取数据</span>
data<span class="token operator">=</span>pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">"约会数据.txt"</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#取前三列，不要第四列的目标值</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#2、实例化一个转换器类</span>
transfer<span class="token operator">=</span>MinMaxScaler<span class="token punctuation">(</span>feature_range<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#3、调用fit_transform</span>
data_new<span class="token operator">=</span>transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'data_new:\n'</span><span class="token punctuation">,</span>data_new<span class="token punctuation">)</span>

结果如下：
    milage     Liters  Consumtime
<span class="token number">0</span>    <span class="token number">72999</span>  <span class="token number">10.141740</span>    <span class="token number">1.032952</span>
<span class="token number">1</span>    <span class="token number">35948</span>   <span class="token number">6.830792</span>    <span class="token number">1.213192</span>
<span class="token number">2</span>    <span class="token number">42666</span>  <span class="token number">13.276369</span>    <span class="token number">0.543880</span>
<span class="token number">3</span>    <span class="token number">67497</span>   <span class="token number">8.631577</span>    <span class="token number">0.749278</span>
<span class="token number">4</span>    <span class="token number">35483</span>  <span class="token number">12.273169</span>    <span class="token number">1.508053</span>
<span class="token number">5</span>    <span class="token number">50242</span>   <span class="token number">3.723498</span>    <span class="token number">0.831917</span>
<span class="token number">6</span>    <span class="token number">63275</span>   <span class="token number">8.385879</span>    <span class="token number">1.669485</span>
<span class="token number">7</span>     <span class="token number">5569</span>   <span class="token number">4.875435</span>    <span class="token number">0.728658</span>
<span class="token number">8</span>    <span class="token number">51052</span>   <span class="token number">4.680098</span>    <span class="token number">0.625224</span>
<span class="token number">9</span>    <span class="token number">77372</span>  <span class="token number">15.299570</span>    <span class="token number">0.331351</span>
<span class="token number">10</span>   <span class="token number">43673</span>   <span class="token number">1.889461</span>    <span class="token number">0.191283</span>
<span class="token number">11</span>   <span class="token number">61364</span>   <span class="token number">7.516754</span>    <span class="token number">1.269164</span>
<span class="token number">12</span>   <span class="token number">69673</span>  <span class="token number">14.239190</span>    <span class="token number">0.261333</span>
<span class="token number">13</span>   <span class="token number">15669</span>   <span class="token number">0.000000</span>    <span class="token number">1.250185</span>
<span class="token number">14</span>   <span class="token number">28488</span>  <span class="token number">10.528555</span>    <span class="token number">1.304844</span>
<span class="token number">15</span>    <span class="token number">6487</span>   <span class="token number">3.540265</span>    <span class="token number">0.822483</span>
<span class="token number">16</span>   <span class="token number">37708</span>   <span class="token number">2.991551</span>    <span class="token number">0.833920</span>
<span class="token number">17</span>   <span class="token number">22620</span>   <span class="token number">5.297865</span>    <span class="token number">0.638306</span>
<span class="token number">18</span>   <span class="token number">28782</span>   <span class="token number">6.593803</span>    <span class="token number">0.187108</span>
data_new<span class="token punctuation">:</span>
 <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2.93909725</span> <span class="token number">2.66287745</span> <span class="token number">2.57059979</span> <span class="token number">2</span><span class="token punctuation">.</span>        <span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">2.42308817</span> <span class="token number">2.44646954</span> <span class="token number">2.69218829</span> <span class="token number">3</span><span class="token punctuation">.</span>        <span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">2.51664972</span> <span class="token number">2.86776092</span> <span class="token number">2.24067562</span> <span class="token number">3</span><span class="token punctuation">.</span>        <span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">2.86247093</span> <span class="token number">2.56417122</span> <span class="token number">2.37923551</span> <span class="token number">2</span><span class="token punctuation">.</span>        <span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">2.41661212</span> <span class="token number">2.80219045</span> <span class="token number">2.89109923</span> <span class="token number">3</span><span class="token punctuation">.</span>        <span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">2.62216063</span> <span class="token number">2.24337272</span> <span class="token number">2.43498314</span> <span class="token number">2</span><span class="token punctuation">.</span>        <span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">2.80367116</span> <span class="token number">2.54811207</span> <span class="token number">3</span><span class="token punctuation">.</span>         <span class="token number">2</span><span class="token punctuation">.</span>        <span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">.</span>         <span class="token number">2.31866484</span> <span class="token number">2.36532542</span> <span class="token number">2.5</span>       <span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">2.6334415</span>  <span class="token number">2.30589736</span> <span class="token number">2.29554965</span> <span class="token number">2</span><span class="token punctuation">.</span>        <span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">.</span>         <span class="token number">3</span><span class="token punctuation">.</span>         <span class="token number">2.09730521</span> <span class="token number">2</span><span class="token punctuation">.</span>        <span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">2.53067421</span> <span class="token number">2.12349765</span> <span class="token number">2.00281642</span> <span class="token number">2</span><span class="token punctuation">.</span>        <span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">2.77705667</span> <span class="token number">2.49130492</span> <span class="token number">2.72994657</span> <span class="token number">2</span><span class="token punctuation">.</span>        <span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">2.89277607</span> <span class="token number">2.93069217</span> <span class="token number">2.05007161</span> <span class="token number">2</span><span class="token punctuation">.</span>        <span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">2.14066265</span> <span class="token number">2</span><span class="token punctuation">.</span>         <span class="token number">2.71714348</span> <span class="token number">2.5</span>       <span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">2.31919279</span> <span class="token number">2.68816019</span> <span class="token number">2.75401602</span> <span class="token number">3</span><span class="token punctuation">.</span>        <span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">2.01278498</span> <span class="token number">2.23139637</span> <span class="token number">2.42861904</span> <span class="token number">2.5</span>       <span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">2.44759968</span> <span class="token number">2.1955317</span>  <span class="token number">2.43633435</span> <span class="token number">2</span><span class="token punctuation">.</span>        <span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">2.23746919</span> <span class="token number">2.34627542</span> <span class="token number">2.30437466</span> <span class="token number">2.5</span>       <span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">2.32328733</span> <span class="token number">2.43097963</span> <span class="token number">2</span><span class="token punctuation">.</span>         <span class="token number">3</span><span class="token punctuation">.</span>        <span class="token punctuation">]</span><span class="token punctuation">]</span>

<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>归一化弊端：若原始数据中有异常值（最大值或最小值），会使归一化不准，稳定性较差，只适合传统精确小数据场景。</p>
<p><strong>b-2:标准化：通过对原始数据进行变换，把数据变换到均值为0，标准差为1范围内。</strong></p>
<p><img src="D:\Machine learning\标准化原理.png" alt=""></p>
<p>标准差反映数据的离散程度</p>
<p><img src="D:\Machine learning\数据异常.png" alt=""></p>
<p><strong>sklearn.preprocessing.StandardScaler()   返回的结果是与转换后形状相同的array</strong> </p>
<p>●StandardScaler.fit_transform(x)：x是numpy array格式的数据[n_samples,n_features]二维数组，n_samples是行，表示样本数，n_features是列，表示特征</p>
<pre><code>from sklearn.preprocessing import StandardScaler
import pandas as pd


#1、获取数据
data=pd.read_csv(&quot;约会数据.txt&quot;)
#取前三列，不要第四列的目标值
print(data.iloc[:,:3])

#2、实例化一个转换器类
transfer=StandardScaler()

#3、调用fit_transform
data_new=transfer.fit_transform(data)
print(&#39;data_new:\n&#39;,data_new)

结果如下：
    milage     Liters  Consumtime
0    72999  10.141740    1.032952
1    35948   6.830792    1.213192
2    42666  13.276369    0.543880
3    67497   8.631577    0.749278
4    35483  12.273169    1.508053
5    50242   3.723498    0.831917
6    63275   8.385879    1.669485
7     5569   4.875435    0.728658
8    51052   4.680098    0.625224
9    77372  15.299570    0.331351
10   43673   1.889461    0.191283
11   61364   7.516754    1.269164
12   69673  14.239190    0.261333
13   15669   0.000000    1.250185
14   28488  10.528555    1.304844
15    6487   3.540265    0.822483
16   37708   2.991551    0.833920
17   22620   5.297865    0.638306
18   28782   6.593803    0.187108
data_new:
 [[ 1.40277192  0.64726302  0.44458068 -0.86824314]
 [-0.32844075 -0.13611514  0.86359951  1.48841682]
 [-0.01454135  1.3889237  -0.69240545  1.48841682]
 [ 1.14569027  0.28995487 -0.21489973 -0.86824314]
 [-0.35016794  1.15156419  1.54908727  1.48841682]
 [ 0.33944821 -0.87130829 -0.02278201 -0.86824314]
 [ 0.94841679  0.23182214  1.92438159 -0.86824314]
 [-1.74790338 -0.59875726 -0.26283675  0.31008684]
 [ 0.37729556 -0.64497446 -0.50329833 -0.86824314]
 [ 1.6071009   1.86761786 -1.1864892  -0.86824314]
 [ 0.03251085 -1.3052458  -1.51211686 -0.86824314]
 [ 0.85912507  0.0261851   0.99372225 -0.86824314]
 [ 1.24736415  1.61672943 -1.34926583 -0.86824314]
 [-1.2759796  -1.75229677  0.9496002   0.31008684]
 [-0.6770102   0.73878437  1.0766705   1.48841682]
 [-1.70500972 -0.91466165 -0.04471401  0.31008684]
 [-0.24620453 -1.04448869 -0.01812547 -0.86824314]
 [-0.95119324 -0.49880932 -0.47288552  0.31008684]
 [-0.66327301 -0.1921873  -1.52182283  1.48841682]]
</code></pre><p>标准化在已有样本足够多的情况下比较稳定，适合现代嘈杂的大数据场景</p>
<p><strong>c、特征降维：在某些限定条件下，降低随机变量（特征）个数，得到一组特征与特征之间不相关的主变量过程</strong></p>
<p>●相关特征：比如要预测一个地区是否下雨，相对湿度与降雨量之间就是相关</p>
<p>●维数：嵌套的层数  0维 标量  1维 向量   2维 矩阵  3维……</p>
<p>●降维：对象是二维数组，降低特征的个数</p>
<p>​                  <img src="D:\Machine learning\降维.png" alt=""></p>
<p>●降维的两种方式：特征选择、主成分分析（可以理解成一种特征提取的方式）</p>
<p><strong>c-1：特征选择：数据中包含多余特征或相关特征，旨在从原有特征中找出主要特征</strong></p>
<p>c-1.1：模块：sklearn.feature_selection</p>
<p>c-1.2：两种方法：</p>
<p><strong>Filter(过滤式)：主要探究特征本身特点、特征与特征和目标值之间关联</strong> </p>
<p>●方差选择法：低方差特诊过滤（方差低的代表特征集中，有更多的相关特征，删除所有低方差特征 ）</p>
<p><strong>sklearn.feature_selection.VarianceThreshold(threshold=0.0)   返回的结果是训练集差异低于threshole的特征将被删除，默认值是保留所有非零方差特征，即删除所有样本中具有相同值的特征,threshold是阈值（临界值）</strong></p>
<p>Variance.fit_transform(x)：x是numpy array格式的数据[n_samples,n_features]</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_selection <span class="token keyword">import</span> VarianceThreshold
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd


<span class="token comment" spellcheck="true">#1、获取数据</span>
data<span class="token operator">=</span>pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">"低方差删除.csv"</span><span class="token punctuation">)</span>
data<span class="token operator">=</span>data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"data:\n"</span><span class="token punctuation">,</span>data<span class="token punctuation">,</span>data<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#2、实例化一个转换器类</span>
transfer<span class="token operator">=</span>VarianceThreshold<span class="token punctuation">(</span>threshold<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#3、调用fit_transform</span>
data_new<span class="token operator">=</span>transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'data_new:\n'</span><span class="token punctuation">,</span>data_new<span class="token punctuation">,</span>data_new<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>

结果如下：
data<span class="token punctuation">:</span>
    market_cap  return_on_asset_net_profit  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>  earnings_per_share  revenue
<span class="token number">0</span>      <span class="token number">5.2340</span>                      <span class="token number">1.2320</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>                <span class="token number">2.44</span>   <span class="token number">12.340</span>
<span class="token number">1</span>      <span class="token number">5.4234</span>                      <span class="token number">1.2320</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>                <span class="token number">2.44</span>  <span class="token number">123.240</span>
<span class="token number">2</span>      <span class="token number">5.2234</span>                      <span class="token number">1.2320</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>                <span class="token number">2.44</span>   <span class="token number">12.340</span>
<span class="token number">3</span>      <span class="token number">5.2340</span>                      <span class="token number">1.2320</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>                <span class="token number">2.44</span>   <span class="token number">12.340</span>
<span class="token number">4</span>      <span class="token number">5.2234</span>                      <span class="token number">1.2320</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>                <span class="token number">2.44</span>   <span class="token number">12.354</span>
<span class="token number">5</span>      <span class="token number">5.2340</span>                      <span class="token number">1.3232</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>                <span class="token number">2.44</span>   <span class="token number">12.334</span>

<span class="token punctuation">[</span><span class="token number">6</span> rows x <span class="token number">6</span> columns<span class="token punctuation">]</span> <span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span>
data_new<span class="token punctuation">:</span>
 <span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">12.34</span> <span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">123.24</span> <span class="token punctuation">]</span>
 <span class="token punctuation">[</span> <span class="token number">12.34</span> <span class="token punctuation">]</span>
 <span class="token punctuation">[</span> <span class="token number">12.34</span> <span class="token punctuation">]</span>
 <span class="token punctuation">[</span> <span class="token number">12.354</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span> <span class="token number">12.334</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#由原来的6行6列变成了6行1列</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>●相关系数法：衡量特征与特征之间的相关程度</p>
<p>方法：皮尔逊相关系数：反映变量之间相关关系密切程度的统计指标，求出的结果即相关系数的值范围是[-1,1]，即-1&lt;=r&lt;=1，性质如下：</p>
<p>·当r&gt;0时，表示两变量正相关，当r&lt;0时，表示两变量负相关</p>
<p>·当|r|=1时，表示两变量完全相关，当r=0时，表示两变量间无相关关系</p>
<p>·当0&lt;|r|&lt;1时，表示两变量存在一定程度的相关，且|r|越接近1，两变量间线性关系越密切，|r|越接近0，表示两变量的线性相关越弱</p>
<p>·一般可按三级划分：|r|&lt;0.4为低度相关，0.4&lt;=|r|&lt;=0.7为显著性相关，0.7&lt;=|r|&lt;=1为高度线性相关</p>
<p>API：from scipy.stats import pearsonr </p>
<p>参数：x、y两个特征</p>
<p>返回的结果中第一个是相关系数的值，</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> scipy<span class="token punctuation">.</span>stats <span class="token keyword">import</span> pearsonr

<span class="token comment" spellcheck="true">#计算两个特征market_cap与revenue之间的相关系数</span>
r<span class="token operator">=</span>pearsonr<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token string">'market_cap'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>data<span class="token punctuation">[</span><span class="token string">'revenue'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'market_cap与revenue之间的相关系数：\n'</span><span class="token punctuation">,</span>r<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#可视化特征间的相关性</span>
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">,</span>dpi<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token string">'market_cap'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>data<span class="token punctuation">[</span><span class="token string">'revenue'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

结果如下：
相关系数：
 <span class="token punctuation">(</span><span class="token number">0.9978430469117973</span><span class="token punctuation">,</span> <span class="token number">6.973652382503574e-06</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>当特征与特征之间相关性很高时：</p>
<p>方法一：选取其中一个特征</p>
<p>方法二：加权求和得到新的特征（特征多合一）</p>
<p>方法三：主成分分析（PCA）</p>
<p><strong>主成分分析（PCA）：将高维数据转化为低维数据的过程，在此过程可能会舍弃原有数据、创造新的变量</strong></p>
<p>●作用：数据维数的压缩，尽可能降低原数据的维数（复杂度），损失少量信息，降维后保持原有特征</p>
<p>●应用：回归分析或者聚类分析当中</p>
<p><strong>●API：sklearn.decomposition.PCA(n_components=None)   将数据分解为较低维数空间，返回的结果是指定维度的array</strong> </p>
<p>n_components：</p>
<p>小数：表示保留百分之几的信息</p>
<p>整数：减少到多少特征</p>
<p>PCA.fit_transform(x)：x是numpy array格式的数据[n_samples,n_features]</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>decomposition <span class="token keyword">import</span> PCA

data<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">9</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span>

<span class="token comment" spellcheck="true">#1、实例化一个转换器类</span>
transfer<span class="token operator">=</span>PCA<span class="token punctuation">(</span>n_components<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#2、调用fit_transform()</span>
data_new<span class="token operator">=</span>transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"保留百分之50信息：\n"</span><span class="token punctuation">,</span>data_new<span class="token punctuation">)</span>

结果如下：
保留百分之<span class="token number">50</span>信息：
 <span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">1.28620952e-15</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span> <span class="token number">5.74456265e+00</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">5.74456265e+00</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>decomposition <span class="token keyword">import</span> PCA

data<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">9</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span>

<span class="token comment" spellcheck="true">#1、实例化一个转换器类</span>
transfer<span class="token operator">=</span>PCA<span class="token punctuation">(</span>n_components<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#2、调用fit_transform()</span>
data_new<span class="token operator">=</span>transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"从四个特征变成两个特征：\n"</span><span class="token punctuation">,</span>data_new<span class="token punctuation">)</span>

结果如下：
从四个特征变成两个特征：
 <span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">1.28620952e-15</span>  <span class="token number">3.82970843e+00</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span> <span class="token number">5.74456265e+00</span> <span class="token operator">-</span><span class="token number">1.91485422e+00</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">5.74456265e+00</span> <span class="token operator">-</span><span class="token number">1.91485422e+00</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>降维—-主成分分析案列：</p>
<p>​                                        <img src="D:\Machine learning\降维案列.png" alt=""></p>
<p>分析：1）需要将aisle_id和aisle放在同一个表中</p>
<p>​            2）找到aisle_id和aisle两者关系   —交叉表和透视表</p>
<p>​            3）特征冗余（相关特征）过多–&gt;PCA降维</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span>  pandas <span class="token keyword">as</span> pd
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>decomposition <span class="token keyword">import</span> PCA

<span class="token comment" spellcheck="true">#1、获取数据</span>
a<span class="token operator">=</span>pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'1.csv'</span><span class="token punctuation">)</span>
b<span class="token operator">=</span>pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'2.csv'</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#2、合并表,第三个参数是连接方式，一般默认为内连接，on是按哪个字段进行合并,aisle_id是两个表都有的</span>
tab1<span class="token operator">=</span>pd<span class="token punctuation">.</span>merge<span class="token punctuation">(</span>a<span class="token punctuation">,</span>b<span class="token punctuation">,</span>on<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'aisle_id'</span><span class="token punctuation">,</span><span class="token string">'aisle_id'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>tab1<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#3、找到product_id和aisle两者关系</span>
table<span class="token operator">=</span>pd<span class="token punctuation">.</span>crosstab<span class="token punctuation">(</span>tab1<span class="token punctuation">[</span><span class="token string">'product_id'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>tab1<span class="token punctuation">[</span><span class="token string">'aisle'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>table<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#4、PCA降维</span>
<span class="token comment" spellcheck="true">#1)、实例化一个转换器类</span>
transfer<span class="token operator">=</span>PCA<span class="token punctuation">(</span>n_components<span class="token operator">=</span><span class="token number">0.99</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#2)、调用fit_transform()</span>
data_new<span class="token operator">=</span>transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>table<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"data_new：\n"</span><span class="token punctuation">,</span>data_new<span class="token punctuation">)</span>

结果如下：
   product_id product_name  aisle_id  department_id aisle
<span class="token number">0</span>           <span class="token number">4</span>            a         <span class="token number">4</span>              <span class="token number">4</span>     b
<span class="token number">1</span>           <span class="token number">6</span>            c         <span class="token number">3</span>             <span class="token number">55</span>     b

aisle       b
product_id   
<span class="token number">4</span>           <span class="token number">1</span>
<span class="token number">6</span>           <span class="token number">1</span>

data_new：
 <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><strong>Embedded(嵌入式)：算法自动选择特征（特征与目标之间的关联）</strong> </p>
<p>●决策树：信息熵、信息增益（详细内容在下面）</p>
<p>●正则化：L1、L2（详细内容在下面）</p>
<p>●深度学习：卷积等</p>
<h4 id="7、以上内容总结："><a href="#7、以上内容总结：" class="headerlink" title="7、以上内容总结："></a><strong>7、以上内容总结：</strong></h4><p>​                                     1）人工智能概述                2)-1 、数据 —&gt;数据集—&gt; 特征值和目标值</p>
<p>1、机器学习概述 —&gt; 2）什么是机器学习 —&gt;     2)-2、模型</p>
<p>​                                                                                  2)-3、预测</p>
<p>​                                                                                                                                       3)-1-1、分类</p>
<p>​                                                                                  3)-1、监督学习(有目标值)—&gt;</p>
<p>​                                     3）机器学习算法分类—&gt;                                                       3)-1-2、回归                 </p>
<p>​                                                                                  3)-2、无监督学习(无目标值)     聚类</p>
<p>​                                                                                                                                                           </p>
<p>​                                    4）机器学习开发流程—&gt;获取数据、数据处理、特征工程、算法训练模型、模型评估、应用                               </p>
<p>​                                                                 1)-1、可用数据集              </p>
<p>​                                                                                                      </p>
<p>​                                    1)数据集 —&gt;                                                     1)-2-1、load_*小规模数据集</p>
<p>​                                                                                                              1)-2-2、fetch_*大规模数据集</p>
<p>​                                                                 1)-2、sklearn数据集—&gt;    </p>
<p>​                                                                                                              1)-2-3、都返回Bunch类型</p>
<p>​                                                                                                              1)-2-4、数据集划分    数据集=训练集+测试集</p>
<p>​                                                             </p>
<p>​                                                                 2)-1、字典特征抽取   DictVectorizer、sparse矩阵–节省空间</p>
<p>2、特征工程       —&gt; 2)特征抽取—&gt;     </p>
<p>​                                                                 2)-2、文本特征抽取   CountVectorizer、 TfidfVectorizer</p>
<p>​                                                               </p>
<p>​                                                                 3)-1、归一化    MinMaxScaler()</p>
<p>​                                   3)无量纲化—&gt;</p>
<p>​                                                                 3)-2、标准化    StandardScaler()</p>
<p>​                                                                                                              4)-1-1-1、删除低方差特征Variance Threshold()</p>
<p>​                                                                                                  4)-1-1、过滤式—&gt;</p>
<p>​                                                                                                               4)-1-1-2、相关系数 取值范围[-1,1]</p>
<p>​                                                                 4)-1、特征选择—&gt;</p>
<p>​                                                                                                  4)-1-2、嵌入式</p>
<p>​                                   4)特征选择—&gt;</p>
<p>​                                                                 4)-2、主成分分析（PCA降维）</p>
<h4 id="7、分类算法："><a href="#7、分类算法：" class="headerlink" title="7、分类算法："></a><strong>7、分类算法：</strong></h4><p>1）目标值是类别</p>
<p>2）sklearn转换器和估计器</p>
<p><strong>a、转换器：  -  特征工程的父类</strong> </p>
<p>a-1、实例化（实例化的是一个转换器类（Transformer））</p>
<p>a-2、调用fit_transform（对于文档建立分类词频矩阵，不能同时调用）</p>
<p>​         以标准化为例：（x-mean）/std</p>
<p>​         fit_transform()可拆分成：fit()—-计算每一列的平均值、标准差、transform()—-对计算之后的结果转换</p>
<p><strong>b、估计器： -  sklearn机器学习算法的实现</strong></p>
<p>b-1、用于分类的估计器：</p>
<p>​               ●sklearn.neighbors         k-近邻算法</p>
<p>​               ●sklearn.naive_bayes      贝叶斯</p>
<p>​               ●sklearn.linear_model.LogisticRegression    逻辑回归</p>
<p>​               ●sklearn.tree                     决策树与随机森林</p>
<p>​          用于回归的估计器：</p>
<p>​                ●sklearn.linear_model.LinearRegression     线性回归</p>
<p>​                ●sklearn.linear_model.Ridge   岭回归</p>
<p>​           用于无监督学习的估计器：</p>
<p>​                ●sklearn.cluster.KMeans  聚类</p>
<p>b-2、估计器工作流程：</p>
<p>​              1、实例化一个估计器estimator</p>
<p>​              2、estimator.fit(x_train,y_train)  生成训练完的模型</p>
<p>​              3、模型评估 ：</p>
<p>​                              3-1：直接比对真实值和预测值  y_predict=estimator.predict(x_test)    y_predict是否等于y_test</p>
<p>​                              3-2：计算准确率   estimator.score(x_test,y_test)</p>
<p><strong>3）knn算法(k-近邻算法)：如果一个样本在特征空间中的k个最邻近的样本中的大多数属于某一个类别，则样本也属于这个类别</strong></p>
<p>a、k一般设为奇数，但k=1容易受到异常点的影响，k值取得过大也会受样本不均衡的影响</p>
<p>b、计算距离：有欧式距离、曼哈顿距离、明可夫斯基距离</p>
<p>eg：a（a1，a2，a3）  b（b1，b2，b3）</p>
<p>欧式距离：根号下    （a1-b1）平方+（a2-b2）平方+（a3-b3）平方</p>
<p>曼哈顿距离： |a1-b1|+|a2-b2|+|a3-b3|</p>
<p>c、在算法之前，要对数据做标准化，将大的数据转换成小数据，避免计算复杂</p>
<p><strong>d、API：sklearn.neighbors.KNeighborsClassifier(n_neighbors=5,algorithm=’auto’)  </strong></p>
<p>● n_neighbors是整数（默认为5），代表查询的邻居个数，即k值</p>
<p>● algorithm：是计算最近邻居的算法，可选参数有’auto‘、’ball_tree‘、’kd_tree‘、’brute‘，默认为auto，可不写algorithm这个参数，auto将根据传递给fit方法的值来决定最合适的算法（不同算法效率不同）</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> load_iris
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>neighbors <span class="token keyword">import</span> KNeighborsClassifier


<span class="token comment" spellcheck="true">#1、获取数据</span>
iris<span class="token operator">=</span>load_iris<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#2、划分数据集</span>
x_train<span class="token punctuation">,</span>x_test<span class="token punctuation">,</span>y_train<span class="token punctuation">,</span>y_test<span class="token operator">=</span>train_test_split<span class="token punctuation">(</span>iris<span class="token punctuation">.</span>data<span class="token punctuation">,</span>iris<span class="token punctuation">.</span>target<span class="token punctuation">,</span>random_state<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#3、特征工程：标准化</span>
transfer<span class="token operator">=</span>StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#对训练集标准化</span>
transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>x_train<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#对测试集标准化,训练集已经fit过，不用重复fit</span>
x_test<span class="token operator">=</span>transfer<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#4、knn算法估计器</span>
knn<span class="token operator">=</span>KNeighborsClassifier<span class="token punctuation">(</span>n_neighbors<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">)</span>
knn<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span>y_train<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#5、模型评估</span>
<span class="token comment" spellcheck="true">#方法一：直接比对真实值和预测值</span>
y_predict<span class="token operator">=</span>knn<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"y_predict:\n"</span><span class="token punctuation">,</span>y_predict<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"直接比对真实值和预测值:\n"</span><span class="token punctuation">,</span>y_test<span class="token operator">==</span>y_predict<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#方法二：计算准确率</span>
score<span class="token operator">=</span>knn<span class="token punctuation">.</span>score<span class="token punctuation">(</span>x_test<span class="token punctuation">,</span>y_test<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'准确率为：\n'</span><span class="token punctuation">,</span>score<span class="token punctuation">)</span>

结果如下：
y_predict<span class="token punctuation">:</span>
 <span class="token punctuation">[</span><span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span>
 <span class="token number">0</span><span class="token punctuation">]</span>
直接比对真实值和预测值<span class="token punctuation">:</span>
 <span class="token punctuation">[</span> <span class="token boolean">True</span> <span class="token boolean">False</span>  <span class="token boolean">True</span>  <span class="token boolean">True</span> <span class="token boolean">False</span> <span class="token boolean">False</span> <span class="token boolean">False</span>  <span class="token boolean">True</span> <span class="token boolean">False</span> <span class="token boolean">False</span> <span class="token boolean">False</span> <span class="token boolean">False</span>
 <span class="token boolean">False</span> <span class="token boolean">False</span> <span class="token boolean">False</span> <span class="token boolean">False</span> <span class="token boolean">False</span> <span class="token boolean">False</span> <span class="token boolean">False</span>  <span class="token boolean">True</span>  <span class="token boolean">True</span> <span class="token boolean">False</span>  <span class="token boolean">True</span>  <span class="token boolean">True</span>
 <span class="token boolean">False</span> <span class="token boolean">False</span> <span class="token boolean">False</span> <span class="token boolean">False</span>  <span class="token boolean">True</span> <span class="token boolean">False</span>  <span class="token boolean">True</span> <span class="token boolean">False</span>  <span class="token boolean">True</span>  <span class="token boolean">True</span> <span class="token boolean">False</span> <span class="token boolean">False</span>
 <span class="token boolean">False</span> <span class="token boolean">False</span><span class="token punctuation">]</span>
准确率为：
 <span class="token number">0.3157894736842105</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>e、knn优点：简单、易理解、实现，无需训练   </p>
<p>​             缺点：1、必须指定k值，k值选择不当则分类精度不能保证</p>
<p>​                         2、懒惰算法，对测试样本分类时的计算量大，内存开销大</p>
<p>f、使用场景：小数据场景，几千~几万样本也可以</p>
<p>4）模型选择与调优</p>
<p>a、交叉验证：将训练集分为训练集和验证集，比如将训练集分成</p>
<p>四份，其中一份是验证集，然后经过4组的验证，每次都更换不同的验证集，即得到4组模型的结果，取平均值作为最终结果，又称4折交叉验证，目的是让被评估的模型更加准确可信</p>
<p>训练集：训练集+验证集</p>
<p>测试集：测试集</p>
<p><img src="D:\Machine learning\交叉验证.png" alt=""></p>
<p>b、超参数搜索-网格搜索：需要手动指定的参数（如knn中的k值），这种参数叫超参数，用网格搜索选出最合适的值</p>
<p><strong>c、模型选择与调优API：sklearn.model_selection.GridSearchCV(estimator,param_grid=None,cv=None)   对估计器的指定参数值进行详尽搜索，暴力破解</strong> </p>
<p>●estimator：估计器对象</p>
<p>●param_grid：估计器参数（如n_neighbors）</p>
<p>●cv：指定几折交叉验证</p>
<p>●fit()：输入训练数据</p>
<p>●score()：准确率</p>
<p>●结果属性分析：最佳参数best_params_ 、最佳结果best_score_、最佳估计器best_estimator、交叉验证结果cv_results_ </p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> load_iris
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>neighbors <span class="token keyword">import</span> KNeighborsClassifier
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> GridSearchCV

<span class="token comment" spellcheck="true">#1、获取数据</span>
iris<span class="token operator">=</span>load_iris<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#2、划分数据集</span>
x_train<span class="token punctuation">,</span>x_test<span class="token punctuation">,</span>y_train<span class="token punctuation">,</span>y_test<span class="token operator">=</span>train_test_split<span class="token punctuation">(</span>iris<span class="token punctuation">.</span>data<span class="token punctuation">,</span>iris<span class="token punctuation">.</span>target<span class="token punctuation">,</span>random_state<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#3、特征工程：标准化</span>
transfer<span class="token operator">=</span>StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#对训练集标准化</span>
transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>x_train<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#对测试集标准化,训练集已经fit过，不用重复fit</span>
x_test<span class="token operator">=</span>transfer<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#4、knn算法估计器</span>
knn<span class="token operator">=</span>KNeighborsClassifier<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#加入网格搜索与交叉验证</span>
<span class="token comment" spellcheck="true">#参数准备,注意中间是：号</span>
k_range<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">'n_neighbors'</span><span class="token punctuation">:</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">9</span><span class="token punctuation">,</span><span class="token number">11</span><span class="token punctuation">]</span><span class="token punctuation">}</span>
knn<span class="token operator">=</span>GridSearchCV<span class="token punctuation">(</span>knn<span class="token punctuation">,</span>param_grid<span class="token operator">=</span>k_range<span class="token punctuation">,</span>cv<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>
knn<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span>y_train<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"最佳参数：\n"</span><span class="token punctuation">,</span>knn<span class="token punctuation">.</span>best_params_<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"最佳结果：\n"</span><span class="token punctuation">,</span>knn<span class="token punctuation">.</span>best_score_<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"最佳估计器：\n"</span><span class="token punctuation">,</span>knn<span class="token punctuation">.</span>best_estimator_<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"交叉验证结果：\n"</span><span class="token punctuation">,</span>knn<span class="token punctuation">.</span>cv_results_<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#5、模型评估</span>
<span class="token comment" spellcheck="true">#方法一：直接比对真实值和预测值</span>
y_predict<span class="token operator">=</span>knn<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"y_predict:\n"</span><span class="token punctuation">,</span>y_predict<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"直接比对真实值和预测值:\n"</span><span class="token punctuation">,</span>y_test<span class="token operator">==</span>y_predict<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#方法二：计算准确率</span>
score<span class="token operator">=</span>knn<span class="token punctuation">.</span>score<span class="token punctuation">(</span>x_test<span class="token punctuation">,</span>y_test<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'准确率为：\n'</span><span class="token punctuation">,</span>score<span class="token punctuation">)</span>

结果如下：
最佳参数：
 <span class="token punctuation">{</span><span class="token string">'n_neighbors'</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">}</span>

最佳结果：
 <span class="token number">0.9642857142857143</span>

最佳估计器：
 KNeighborsClassifier<span class="token punctuation">(</span>algorithm<span class="token operator">=</span><span class="token string">'auto'</span><span class="token punctuation">,</span> leaf_size<span class="token operator">=</span><span class="token number">30</span><span class="token punctuation">,</span> metric<span class="token operator">=</span><span class="token string">'minkowski'</span><span class="token punctuation">,</span>
           metric_params<span class="token operator">=</span>None<span class="token punctuation">,</span> n_jobs<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> n_neighbors<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> p<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>
           weights<span class="token operator">=</span><span class="token string">'uniform'</span><span class="token punctuation">)</span>

交叉验证结果：
 <span class="token punctuation">{</span><span class="token string">'mean_fit_time'</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.00019844</span><span class="token punctuation">,</span> <span class="token number">0.0005018</span> <span class="token punctuation">,</span> <span class="token number">0.00069561</span><span class="token punctuation">,</span> <span class="token number">0.00059736</span><span class="token punctuation">,</span> <span class="token number">0.00059884</span><span class="token punctuation">,</span>
       <span class="token number">0.00079825</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'std_fit_time'</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.00039689</span><span class="token punctuation">,</span> <span class="token number">0.00050185</span><span class="token punctuation">,</span> <span class="token number">0.00045541</span><span class="token punctuation">,</span> <span class="token number">0.00066075</span><span class="token punctuation">,</span> <span class="token number">0.00066213</span><span class="token punctuation">,</span>
       <span class="token number">0.0007461</span> <span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'mean_score_time'</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.00119684</span><span class="token punctuation">,</span> <span class="token number">0.00079341</span><span class="token punctuation">,</span> <span class="token number">0.00069685</span><span class="token punctuation">,</span> <span class="token number">0.00069926</span><span class="token punctuation">,</span> <span class="token number">0.00089424</span><span class="token punctuation">,</span>
       <span class="token number">0.00119553</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'std_score_time'</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.00040068</span><span class="token punctuation">,</span> <span class="token number">0.00039679</span><span class="token punctuation">,</span> <span class="token number">0.00045622</span><span class="token punctuation">,</span> <span class="token number">0.0008997</span> <span class="token punctuation">,</span> <span class="token number">0.00069588</span><span class="token punctuation">,</span>
       <span class="token number">0.00107592</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'param_n_neighbors'</span><span class="token punctuation">:</span> masked_array<span class="token punctuation">(</span>data<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
             mask<span class="token operator">=</span><span class="token punctuation">[</span><span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
       fill_value<span class="token operator">=</span><span class="token string">'?'</span><span class="token punctuation">,</span>
            dtype<span class="token operator">=</span>object<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'params'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token string">'n_neighbors'</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span><span class="token string">'n_neighbors'</span><span class="token punctuation">:</span> <span class="token number">3</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span><span class="token string">'n_neighbors'</span><span class="token punctuation">:</span> <span class="token number">5</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span><span class="token string">'n_neighbors'</span><span class="token punctuation">:</span> <span class="token number">7</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span><span class="token string">'n_neighbors'</span><span class="token punctuation">:</span> <span class="token number">9</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span><span class="token string">'n_neighbors'</span><span class="token punctuation">:</span> <span class="token number">11</span><span class="token punctuation">}</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'split0_test_score'</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'split1_test_score'</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.91666667</span><span class="token punctuation">,</span> <span class="token number">0.91666667</span><span class="token punctuation">,</span> <span class="token number">0.91666667</span><span class="token punctuation">,</span> <span class="token number">0.91666667</span><span class="token punctuation">,</span> <span class="token number">0.91666667</span><span class="token punctuation">,</span>
       <span class="token number">0.91666667</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'split2_test_score'</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'split3_test_score'</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'split4_test_score'</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'split5_test_score'</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.91666667</span><span class="token punctuation">,</span> <span class="token number">0.91666667</span><span class="token punctuation">,</span> <span class="token number">0.91666667</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span>
       <span class="token number">1</span><span class="token punctuation">.</span>        <span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'split6_test_score'</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span> <span class="token number">0.90909091</span><span class="token punctuation">,</span> <span class="token number">0.90909091</span><span class="token punctuation">,</span> <span class="token number">0.90909091</span><span class="token punctuation">,</span> <span class="token number">0.90909091</span><span class="token punctuation">,</span>
       <span class="token number">0.90909091</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'split7_test_score'</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'split8_test_score'</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'split9_test_score'</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.77777778</span><span class="token punctuation">,</span> <span class="token number">0.88888889</span><span class="token punctuation">,</span> <span class="token number">0.77777778</span><span class="token punctuation">,</span> <span class="token number">0.77777778</span><span class="token punctuation">,</span> <span class="token number">0.77777778</span><span class="token punctuation">,</span>
       <span class="token number">0.77777778</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'mean_test_score'</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.96428571</span><span class="token punctuation">,</span> <span class="token number">0.96428571</span><span class="token punctuation">,</span> <span class="token number">0.95535714</span><span class="token punctuation">,</span> <span class="token number">0.96428571</span><span class="token punctuation">,</span> <span class="token number">0.96428571</span><span class="token punctuation">,</span>
       <span class="token number">0.96428571</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'std_test_score'</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.06465941</span><span class="token punctuation">,</span> <span class="token number">0.04490364</span><span class="token punctuation">,</span> <span class="token number">0.06538389</span><span class="token punctuation">,</span> <span class="token number">0.06518036</span><span class="token punctuation">,</span> <span class="token number">0.06518036</span><span class="token punctuation">,</span>
       <span class="token number">0.06518036</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'rank_test_score'</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'split0_train_score'</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span>  <span class="token punctuation">,</span> <span class="token number">0.97</span><span class="token punctuation">,</span> <span class="token number">0.98</span><span class="token punctuation">,</span> <span class="token number">0.96</span><span class="token punctuation">,</span> <span class="token number">0.96</span><span class="token punctuation">,</span> <span class="token number">0.96</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'split1_train_score'</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span>  <span class="token punctuation">,</span> <span class="token number">0.98</span><span class="token punctuation">,</span> <span class="token number">0.99</span><span class="token punctuation">,</span> <span class="token number">0.97</span><span class="token punctuation">,</span> <span class="token number">0.97</span><span class="token punctuation">,</span> <span class="token number">0.97</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'split2_train_score'</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span>  <span class="token punctuation">,</span> <span class="token number">0.97</span><span class="token punctuation">,</span> <span class="token number">0.98</span><span class="token punctuation">,</span> <span class="token number">0.96</span><span class="token punctuation">,</span> <span class="token number">0.96</span><span class="token punctuation">,</span> <span class="token number">0.96</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'split3_train_score'</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span>  <span class="token punctuation">,</span> <span class="token number">0.97</span><span class="token punctuation">,</span> <span class="token number">0.98</span><span class="token punctuation">,</span> <span class="token number">0.96</span><span class="token punctuation">,</span> <span class="token number">0.96</span><span class="token punctuation">,</span> <span class="token number">0.96</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'split4_train_score'</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span>  <span class="token punctuation">,</span> <span class="token number">0.97</span><span class="token punctuation">,</span> <span class="token number">0.97</span><span class="token punctuation">,</span> <span class="token number">0.96</span><span class="token punctuation">,</span> <span class="token number">0.97</span><span class="token punctuation">,</span> <span class="token number">0.97</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'split5_train_score'</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span>  <span class="token punctuation">,</span> <span class="token number">0.98</span><span class="token punctuation">,</span> <span class="token number">0.98</span><span class="token punctuation">,</span> <span class="token number">0.96</span><span class="token punctuation">,</span> <span class="token number">0.96</span><span class="token punctuation">,</span> <span class="token number">0.97</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'split6_train_score'</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span> <span class="token number">0.97029703</span><span class="token punctuation">,</span> <span class="token number">0.97029703</span><span class="token punctuation">,</span> <span class="token number">0.97029703</span><span class="token punctuation">,</span> <span class="token number">0.97029703</span><span class="token punctuation">,</span>
       <span class="token number">0.97029703</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'split7_train_score'</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span> <span class="token number">0.97029703</span><span class="token punctuation">,</span> <span class="token number">0.97029703</span><span class="token punctuation">,</span> <span class="token number">0.96039604</span><span class="token punctuation">,</span> <span class="token number">0.95049505</span><span class="token punctuation">,</span>
       <span class="token number">0.96039604</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'split8_train_score'</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span> <span class="token number">0.97087379</span><span class="token punctuation">,</span> <span class="token number">0.98058252</span><span class="token punctuation">,</span> <span class="token number">0.96116505</span><span class="token punctuation">,</span> <span class="token number">0.96116505</span><span class="token punctuation">,</span>
       <span class="token number">0.96116505</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'split9_train_score'</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span> <span class="token number">0.98058252</span><span class="token punctuation">,</span> <span class="token number">0.98058252</span><span class="token punctuation">,</span> <span class="token number">0.98058252</span><span class="token punctuation">,</span> <span class="token number">0.98058252</span><span class="token punctuation">,</span>
       <span class="token number">0.98058252</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'mean_train_score'</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span> <span class="token number">0.97320504</span><span class="token punctuation">,</span> <span class="token number">0.97817591</span><span class="token punctuation">,</span> <span class="token number">0.96424406</span><span class="token punctuation">,</span> <span class="token number">0.96425397</span><span class="token punctuation">,</span>
       <span class="token number">0.96624406</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'std_train_score'</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span> <span class="token number">0.00458484</span><span class="token punctuation">,</span> <span class="token number">0.00596407</span><span class="token punctuation">,</span> <span class="token number">0.00671612</span><span class="token punctuation">,</span> <span class="token number">0.00800255</span><span class="token punctuation">,</span>
       <span class="token number">0.00664304</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">}</span>

y_predict<span class="token punctuation">:</span>
 <span class="token punctuation">[</span><span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span>
 <span class="token number">0</span><span class="token punctuation">]</span>

直接比对真实值和预测值<span class="token punctuation">:</span>
 <span class="token punctuation">[</span> <span class="token boolean">True</span> <span class="token boolean">False</span>  <span class="token boolean">True</span>  <span class="token boolean">True</span> <span class="token boolean">False</span> <span class="token boolean">False</span> <span class="token boolean">False</span>  <span class="token boolean">True</span> <span class="token boolean">False</span> <span class="token boolean">False</span> <span class="token boolean">False</span> <span class="token boolean">False</span>
 <span class="token boolean">False</span> <span class="token boolean">False</span> <span class="token boolean">False</span> <span class="token boolean">False</span> <span class="token boolean">False</span> <span class="token boolean">False</span> <span class="token boolean">False</span>  <span class="token boolean">True</span>  <span class="token boolean">True</span> <span class="token boolean">False</span>  <span class="token boolean">True</span>  <span class="token boolean">True</span>
 <span class="token boolean">False</span> <span class="token boolean">False</span> <span class="token boolean">False</span> <span class="token boolean">False</span>  <span class="token boolean">True</span> <span class="token boolean">False</span>  <span class="token boolean">True</span> <span class="token boolean">False</span>  <span class="token boolean">True</span>  <span class="token boolean">True</span> <span class="token boolean">False</span> <span class="token boolean">False</span>
 <span class="token boolean">False</span> <span class="token boolean">False</span><span class="token punctuation">]</span>

准确率为：
 <span class="token number">0.3157894736842105</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>案列：预测facebook签到位置</p>
<p><img src="D:\Machine learning\facebook.png" alt=""></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> StandardScaler
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>neighbors <span class="token keyword">import</span> KNeighborsClassifier
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> GridSearchCV
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd

<span class="token comment" spellcheck="true">#1、获取数据</span>
data<span class="token operator">=</span>pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'submissions_metadata.csv'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#2、基本的数据处理</span>
<span class="token comment" spellcheck="true">#1）缩小数据范围 x在2-2.5之间，1.0-1.5之间</span>
data<span class="token operator">=</span>data<span class="token punctuation">.</span>query<span class="token punctuation">(</span><span class="token string">'x&lt;2.5&amp;x>2&amp;y&lt;1.5&amp;y>1.0>'</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#2）处理时间戳，改为年月日时分秒</span>
time_value<span class="token operator">=</span>pd<span class="token punctuation">.</span>to_datetime<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token string">'time'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>unit<span class="token operator">=</span><span class="token string">'s'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>time_value<span class="token punctuation">.</span>values<span class="token punctuation">)</span>
date<span class="token operator">=</span>pd<span class="token punctuation">.</span>DatetimeIndex<span class="token punctuation">(</span>time_value<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'年份：\n'</span><span class="token punctuation">,</span>date<span class="token punctuation">.</span>year<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'月份：\n'</span><span class="token punctuation">,</span>date<span class="token punctuation">.</span>month<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'日期：\n'</span><span class="token punctuation">,</span>date<span class="token punctuation">.</span>day<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'小时：\n'</span><span class="token punctuation">,</span>date<span class="token punctuation">.</span>hour<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'星期：\n'</span><span class="token punctuation">,</span>date<span class="token punctuation">.</span>weekday<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#添加日期、星期、小时特征到data里</span>
data<span class="token punctuation">[</span><span class="token string">'day'</span><span class="token punctuation">]</span><span class="token operator">=</span>date<span class="token punctuation">.</span>day
data<span class="token punctuation">[</span><span class="token string">'weekday'</span><span class="token punctuation">]</span><span class="token operator">=</span>date<span class="token punctuation">.</span>weekday
data<span class="token punctuation">[</span><span class="token string">'hour'</span><span class="token punctuation">]</span><span class="token operator">=</span>date<span class="token punctuation">.</span>hour
<span class="token keyword">print</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#3）过滤签到次数少的地点</span>
<span class="token comment" spellcheck="true">#统计下不同的地方签到的次数</span>
place_count<span class="token operator">=</span>data<span class="token punctuation">.</span>groupby<span class="token punctuation">(</span><span class="token string">'place_id'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>count<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">'row_id'</span><span class="token punctuation">]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>place_count<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#过滤掉签到小于4的地方</span>
place_count<span class="token operator">=</span>place_count<span class="token punctuation">[</span>place_count<span class="token operator">></span><span class="token number">3</span><span class="token punctuation">]</span>
<span class="token comment" spellcheck="true">#找出date中符合条件的</span>
date<span class="token punctuation">[</span><span class="token string">'place_id'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>isin<span class="token punctuation">(</span>place_count<span class="token punctuation">.</span>index<span class="token punctuation">.</span>values<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#找出data中符合条件的</span>
data_final<span class="token operator">=</span>data<span class="token punctuation">[</span>date<span class="token punctuation">[</span><span class="token string">'place_id'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>isin<span class="token punctuation">(</span>place_count<span class="token punctuation">.</span>index<span class="token punctuation">.</span>values<span class="token punctuation">)</span><span class="token punctuation">]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>data_final<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#3、筛选特征值和目标值</span>
x<span class="token operator">=</span>data_final<span class="token punctuation">[</span><span class="token string">'x'</span><span class="token punctuation">,</span><span class="token string">'y'</span><span class="token punctuation">.</span><span class="token string">'accuracy'</span><span class="token punctuation">,</span><span class="token string">'day'</span><span class="token punctuation">,</span><span class="token string">'weekday'</span><span class="token punctuation">,</span><span class="token string">'hour'</span><span class="token punctuation">]</span>
y<span class="token operator">=</span>data_final<span class="token punctuation">[</span><span class="token string">'place_id'</span><span class="token punctuation">]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'x:\n'</span><span class="token punctuation">,</span>x<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'y:\n'</span><span class="token punctuation">,</span>y<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#4、数据集划分</span>
x_train<span class="token punctuation">,</span>x_test<span class="token punctuation">,</span>y_train<span class="token punctuation">,</span>y_test<span class="token operator">=</span>train_test_split<span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#5、特征工程：标准化</span>
transfer<span class="token operator">=</span>StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#对训练集标准化</span>
transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>x_train<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#对测试集标准化,训练集已经fit过，不用重复fit</span>
x_test<span class="token operator">=</span>transfer<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#6、knn算法估计器</span>
knn<span class="token operator">=</span>KNeighborsClassifier<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#加入网格搜索与交叉验证</span>
<span class="token comment" spellcheck="true">#参数准备,注意中间是：号</span>
k_range<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">'n_neighbors'</span><span class="token punctuation">:</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">9</span><span class="token punctuation">]</span><span class="token punctuation">}</span>
knn<span class="token operator">=</span>GridSearchCV<span class="token punctuation">(</span>knn<span class="token punctuation">,</span>param_grid<span class="token operator">=</span>k_range<span class="token punctuation">,</span>cv<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>
knn<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span>y_train<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"最佳参数：\n"</span><span class="token punctuation">,</span>knn<span class="token punctuation">.</span>best_params_<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"最佳结果：\n"</span><span class="token punctuation">,</span>knn<span class="token punctuation">.</span>best_score_<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"最佳估计器：\n"</span><span class="token punctuation">,</span>knn<span class="token punctuation">.</span>best_estimator_<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"交叉验证结果：\n"</span><span class="token punctuation">,</span>knn<span class="token punctuation">.</span>cv_results_<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#因为没有数据集，所以结果暂时无法显示</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><strong>5）朴素贝叶斯算法：朴素+贝叶斯    计算特征之间的概率，得出最大的概率</strong></p>
<p>a、概率基础知识：</p>
<p>​            a-1：<img src="D:\Machine learning\概率知识.png" alt=""></p>
<p>eg：</p>
<p><img src="D:\Machine learning\概率.png" alt=""></p>
<p>b、朴素贝叶斯中的朴素：假设特征与特征之间是相互独立的</p>
<p>c、贝叶斯公式</p>
<p><img src="D:\Machine learning\贝叶斯.png" alt=""></p>
<p>d、应用场景：文本分类、单词作为特征</p>
<p><img src="D:\Machine learning\文本分类.png" alt=""></p>
<p>e、拉普拉斯平滑系数：加数的话不止概率为0的加，不为0的也加</p>
<p><img src="D:\Machine learning\拉普拉斯平滑系数.png" alt=""></p>
<p><strong>f、API：sklearn.naive_bayes.MultinomiaINB(alpha=1.0)  alpha是拉普拉斯平滑系数</strong></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#20类新闻分类</span>

<span class="token keyword">from</span> sklearn <span class="token punctuation">.</span>datasets <span class="token keyword">import</span> fetch_20newsgroups
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_extraction<span class="token punctuation">.</span>text <span class="token keyword">import</span> TfidfVectorizer
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>naive_bayes <span class="token keyword">import</span> MultinomialNB


<span class="token comment" spellcheck="true">#1、获取数据</span>
<span class="token comment" spellcheck="true">#第一个参数data_home是将下载的数据集存到哪，默认在家目录，第二个参数subset默认是train</span>
news<span class="token operator">=</span>fetch_20newsgroups<span class="token punctuation">(</span>subset<span class="token operator">=</span><span class="token string">'all'</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#2、划分数据集</span>
train_test_split<span class="token punctuation">(</span>news<span class="token punctuation">.</span>data<span class="token punctuation">,</span>news<span class="token punctuation">.</span>target<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#3、特征工程：文本特征抽取 tfidf</span>
transfer<span class="token operator">=</span>TfidfVectorizer<span class="token punctuation">(</span><span class="token punctuation">)</span>
x_train<span class="token operator">=</span>transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>x_train<span class="token punctuation">)</span>
x_test<span class="token operator">=</span>transfer<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#4、朴素贝叶斯算法估计器</span>
bayes<span class="token operator">=</span>MultinomialNB<span class="token punctuation">(</span><span class="token punctuation">)</span>
bayes<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span>y_train<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#5、模型评估</span>
<span class="token comment" spellcheck="true">#方法一：直接比对真实值和预测值</span>
y_predict<span class="token operator">=</span>knn<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"y_predict:\n"</span><span class="token punctuation">,</span>y_predict<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"直接比对真实值和预测值:\n"</span><span class="token punctuation">,</span>y_test<span class="token operator">==</span>y_predict<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#方法二：计算准确率</span>
score<span class="token operator">=</span>knn<span class="token punctuation">.</span>score<span class="token punctuation">(</span>x_test<span class="token punctuation">,</span>y_test<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'准确率为：\n'</span><span class="token punctuation">,</span>score<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>g、朴素贝叶斯优点：有稳定的分类效率，对缺失数据不太敏感，常用于分类，分类准确度高，速度快</p>
<p>​                         缺点：假设了特征于特征之间相互独立，如果特征属性有关联时，效果不好</p>
<p>6）决策树：条件分支结构就是if-else结构，思想就是如何高效的进行决策</p>
<p><img src="D:\Machine learning\决策树.png" alt=""></p>
<p>a、决策树分类原理：</p>
<p>b、信息熵、信息增益：</p>
<p>b-1：信息论基础，信息的定义：消除随机不定性的东西</p>
<p>eg：我问小明年龄多大，小明说“我今年18岁”，小华在旁边说“小明明年19岁”。小明说的话是信息。小华说的不是信息。</p>
<p>b-2：信息熵：衡量消除的不定性有多少，单位是比特</p>
<p><img src="D:\Machine learning\信息熵.png" alt=""></p>
<p>b-3：信息增益：在已求出信息熵H(D)的前提下，特征A在给定条件下D的信息条件熵H(D|A)之差</p>
<p><img src="D:\Machine learning\信息增益.png" alt=""></p>
<p><img src="D:\Machine learning\信息熵、增益.png" alt=""></p>
<p>eg：已知有四个特征，预测是否贷款给某个人</p>
<p><img src="D:\Machine learning\决策树eg.png" alt=""></p>
<p>解决：</p>
<p><img src="D:\Machine learning\信息熵eg1.png" alt=""></p>
<p>c、决策树划分的依据之一  —–  信息增益</p>
<p><img src="D:\Machine learning\决策树1.png" alt=""></p>
<p><strong>d、API：sklearn.tree.DecisionTreeClassifier(criterion=’gini’,max_depth=None,random_state=None) 决策树分类器</strong></p>
<p>●criterion:默认是’gini‘系数，也可以选择信息增益的熵’entropy‘</p>
<p>●max_depth：树的深度大小，选择合适的值能提高准确率</p>
<p>●random_state：随机数种子</p>
<p><strong>e、决策树可视化：sklearn.tree.export_graphviz()  该函数能够导出DOT格式</strong></p>
<p><strong>tree.export_graphviz(estimator,out_file=’tree.dot’,feature_names=[‘,’]) out_file是导出的路径和名字，注意加后缀，feature_names是导出的名字</strong></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> load_iris
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>tree <span class="token keyword">import</span> DecisionTreeClassifier<span class="token punctuation">,</span>export_graphviz


<span class="token comment" spellcheck="true">#1、获取数据</span>
iris<span class="token operator">=</span>load_iris<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#2、数据集划分</span>
x_train<span class="token punctuation">,</span>x_test<span class="token punctuation">,</span>y_train<span class="token punctuation">,</span>y_test<span class="token operator">=</span>train_test_split<span class="token punctuation">(</span>iris<span class="token punctuation">.</span>data<span class="token punctuation">,</span>iris<span class="token punctuation">.</span>target<span class="token punctuation">,</span>random_state<span class="token operator">=</span><span class="token number">22</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#3、决策树预估器</span>
dtc<span class="token operator">=</span>DecisionTreeClassifier<span class="token punctuation">(</span>criterion<span class="token operator">=</span><span class="token string">'entropy'</span><span class="token punctuation">)</span>
dtc<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span>y_train<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#4、模型评估</span>
<span class="token comment" spellcheck="true">#方法一：直接比对真实值和预测值</span>
y_predict<span class="token operator">=</span>knn<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"y_predict:\n"</span><span class="token punctuation">,</span>y_predict<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"直接比对真实值和预测值:\n"</span><span class="token punctuation">,</span>y_test<span class="token operator">==</span>y_predict<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#方法二：计算准确率</span>
score<span class="token operator">=</span>knn<span class="token punctuation">.</span>score<span class="token punctuation">(</span>x_test<span class="token punctuation">,</span>y_test<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'准确率为：\n'</span><span class="token punctuation">,</span>score<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#5、可视化决策树</span>
export_graphviz<span class="token punctuation">(</span>dtc<span class="token punctuation">,</span>out_file<span class="token operator">=</span><span class="token string">'iris_tree.dot'</span><span class="token punctuation">,</span>feature_names<span class="token operator">=</span>iris<span class="token punctuation">.</span>feature_names<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#将生成的iris_tree.dot文件里面的内容复制，打开网页http://webgraphviz.com/  然后粘贴进文本框内（先清除原来的），再点击Generate Graph</span>

结果如下：
y_predict<span class="token punctuation">:</span>
 <span class="token punctuation">[</span><span class="token number">0</span> <span class="token number">2</span> <span class="token number">1</span> <span class="token number">2</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">2</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">2</span> <span class="token number">1</span> <span class="token number">2</span> <span class="token number">2</span> <span class="token number">0</span> <span class="token number">2</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">2</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">2</span> <span class="token number">0</span> <span class="token number">2</span> <span class="token number">2</span> <span class="token number">2</span> <span class="token number">2</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span>
 <span class="token number">0</span><span class="token punctuation">]</span>
直接比对真实值和预测值<span class="token punctuation">:</span>
 <span class="token punctuation">[</span> <span class="token boolean">True</span>  <span class="token boolean">True</span>  <span class="token boolean">True</span>  <span class="token boolean">True</span>  <span class="token boolean">True</span>  <span class="token boolean">True</span>  <span class="token boolean">True</span>  <span class="token boolean">True</span>  <span class="token boolean">True</span>  <span class="token boolean">True</span>  <span class="token boolean">True</span>  <span class="token boolean">True</span>
  <span class="token boolean">True</span>  <span class="token boolean">True</span>  <span class="token boolean">True</span>  <span class="token boolean">True</span>  <span class="token boolean">True</span>  <span class="token boolean">True</span> <span class="token boolean">False</span>  <span class="token boolean">True</span>  <span class="token boolean">True</span>  <span class="token boolean">True</span>  <span class="token boolean">True</span>  <span class="token boolean">True</span>
  <span class="token boolean">True</span>  <span class="token boolean">True</span>  <span class="token boolean">True</span>  <span class="token boolean">True</span>  <span class="token boolean">True</span>  <span class="token boolean">True</span>  <span class="token boolean">True</span>  <span class="token boolean">True</span>  <span class="token boolean">True</span>  <span class="token boolean">True</span>  <span class="token boolean">True</span>  <span class="token boolean">True</span>
  <span class="token boolean">True</span>  <span class="token boolean">True</span><span class="token punctuation">]</span>
准确率为：
 <span class="token number">0.9736842105263158</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>f、决策树总结：</p>
<p>优点：可视化–可解释能力强</p>
<p>缺点：容易产生过拟合</p>
<p>改进：减枝cart算法（可以直接调用API）、随机森林</p>
<p><strong>g、案列——泰坦尼克号乘客生存预测</strong> </p>
<p><img src="D:\Machine learning\泰坦尼克号案列.png" alt=""></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>tree <span class="token keyword">import</span> DecisionTreeClassifier<span class="token punctuation">,</span>export_graphviz
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_extraction <span class="token keyword">import</span> DictVectorizer

<span class="token comment" spellcheck="true">#1、获取数据</span>
path<span class="token operator">=</span><span class="token string">'http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic.txt'</span>
data<span class="token operator">=</span>pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>path<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#print(data)</span>
<span class="token comment" spellcheck="true">#筛选特征值和目标值</span>
x<span class="token operator">=</span>data<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'pclass'</span><span class="token punctuation">,</span><span class="token string">'age'</span><span class="token punctuation">,</span><span class="token string">'sex'</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
y<span class="token operator">=</span>data<span class="token punctuation">[</span><span class="token string">'survived'</span><span class="token punctuation">]</span>
<span class="token comment" spellcheck="true">#print(x)</span>
<span class="token comment" spellcheck="true">#print(y)</span>
<span class="token comment" spellcheck="true">#2、数据处理</span>
<span class="token comment" spellcheck="true">#缺失值处理</span>
x<span class="token punctuation">[</span><span class="token string">'age'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>fillna<span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token string">'age'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#print(x)</span>
<span class="token comment" spellcheck="true">#转换成字典</span>
x<span class="token operator">=</span>x<span class="token punctuation">.</span>to_dict<span class="token punctuation">(</span>orient<span class="token operator">=</span><span class="token string">'records'</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#3、数据集划分</span>
x_train<span class="token punctuation">,</span>x_test<span class="token punctuation">,</span>y_train<span class="token punctuation">,</span>y_test<span class="token operator">=</span>train_test_split<span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">,</span>random_state<span class="token operator">=</span><span class="token number">22</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#4、字典特征抽取</span>
transfer<span class="token operator">=</span>DictVectorizer<span class="token punctuation">(</span><span class="token punctuation">)</span>
x_train<span class="token operator">=</span>transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>x_train<span class="token punctuation">)</span>
x_test<span class="token operator">=</span>transfer<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#5、决策树预估器  max_depth可以改</span>
dtc<span class="token operator">=</span>DecisionTreeClassifier<span class="token punctuation">(</span>criterion<span class="token operator">=</span><span class="token string">'entropy'</span><span class="token punctuation">,</span>max_depth<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">)</span>
dtc<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span>y_train<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#6、模型评估</span>
<span class="token comment" spellcheck="true">#方法一：直接比对真实值和预测值</span>
y_predict<span class="token operator">=</span>dtc<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"y_predict:\n"</span><span class="token punctuation">,</span>y_predict<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"直接比对真实值和预测值:\n"</span><span class="token punctuation">,</span>y_test<span class="token operator">==</span>y_predict<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#方法二：计算准确率</span>
score<span class="token operator">=</span>dtc<span class="token punctuation">.</span>score<span class="token punctuation">(</span>x_test<span class="token punctuation">,</span>y_test<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'准确率为：\n'</span><span class="token punctuation">,</span>score<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#6、可视化决策树  这里feature_names不能写原表格的了，因为原表格的特征已经转换成了ont-hot编码，可以用transfer来代替</span>
export_graphviz<span class="token punctuation">(</span>dtc<span class="token punctuation">,</span>out_file<span class="token operator">=</span><span class="token string">'taitan_tree.dot'</span><span class="token punctuation">,</span>feature_names<span class="token operator">=</span>transfer<span class="token punctuation">.</span>feature_names_<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#将生成的iris_tree.dot文件里面的内容复制，打开网页http://webgraphviz.com/  然后粘贴进文本框内（先清除原来的），再点击Generate Graph</span>

结果如下：
y_predict<span class="token punctuation">:</span>
 <span class="token punctuation">[</span><span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span>
 <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span>
 <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span>
 <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span>
 <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span>
 <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span>
 <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span>
 <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span>
 <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span><span class="token punctuation">]</span>
直接比对真实值和预测值<span class="token punctuation">:</span>
 <span class="token number">831</span>      <span class="token boolean">True</span>
<span class="token number">261</span>     <span class="token boolean">False</span>
<span class="token number">1210</span>     <span class="token boolean">True</span>
<span class="token number">1155</span>     <span class="token boolean">True</span>
<span class="token number">255</span>      <span class="token boolean">True</span>
<span class="token number">762</span>      <span class="token boolean">True</span>
<span class="token number">615</span>      <span class="token boolean">True</span>
<span class="token number">507</span>      <span class="token boolean">True</span>
<span class="token number">1175</span>     <span class="token boolean">True</span>
<span class="token number">301</span>      <span class="token boolean">True</span>
<span class="token number">1134</span>     <span class="token boolean">True</span>
<span class="token number">177</span>     <span class="token boolean">False</span>
<span class="token number">183</span>     <span class="token boolean">False</span>
<span class="token number">125</span>     <span class="token boolean">False</span>
<span class="token number">1093</span>     <span class="token boolean">True</span>
<span class="token number">1304</span>    <span class="token boolean">False</span>
<span class="token number">1124</span>     <span class="token boolean">True</span>
<span class="token number">798</span>     <span class="token boolean">False</span>
<span class="token number">1101</span>     <span class="token boolean">True</span>
<span class="token number">1239</span>    <span class="token boolean">False</span>
<span class="token number">1153</span>     <span class="token boolean">True</span>
<span class="token number">1068</span>    <span class="token boolean">False</span>
<span class="token number">846</span>      <span class="token boolean">True</span>
<span class="token number">148</span>      <span class="token boolean">True</span>
<span class="token number">478</span>      <span class="token boolean">True</span>
<span class="token number">642</span>      <span class="token boolean">True</span>
<span class="token number">1298</span>     <span class="token boolean">True</span>
<span class="token number">540</span>      <span class="token boolean">True</span>
<span class="token number">28</span>       <span class="token boolean">True</span>
<span class="token number">130</span>      <span class="token boolean">True</span>
        <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>  
<span class="token number">194</span>      <span class="token boolean">True</span>
<span class="token number">663</span>      <span class="token boolean">True</span>
<span class="token number">1209</span>     <span class="token boolean">True</span>
<span class="token number">117</span>      <span class="token boolean">True</span>
<span class="token number">595</span>     <span class="token boolean">False</span>
<span class="token number">1151</span>    <span class="token boolean">False</span>
<span class="token number">1143</span>     <span class="token boolean">True</span>
<span class="token number">1216</span>     <span class="token boolean">True</span>
<span class="token number">874</span>      <span class="token boolean">True</span>
<span class="token number">246</span>      <span class="token boolean">True</span>
<span class="token number">160</span>      <span class="token boolean">True</span>
<span class="token number">1208</span>     <span class="token boolean">True</span>
<span class="token number">682</span>      <span class="token boolean">True</span>
<span class="token number">307</span>      <span class="token boolean">True</span>
<span class="token number">67</span>       <span class="token boolean">True</span>
<span class="token number">961</span>      <span class="token boolean">True</span>
<span class="token number">400</span>      <span class="token boolean">True</span>
<span class="token number">923</span>     <span class="token boolean">False</span>
<span class="token number">866</span>      <span class="token boolean">True</span>
<span class="token number">134</span>      <span class="token boolean">True</span>
<span class="token number">613</span>      <span class="token boolean">True</span>
<span class="token number">242</span>      <span class="token boolean">True</span>
<span class="token number">320</span>     <span class="token boolean">False</span>
<span class="token number">829</span>      <span class="token boolean">True</span>
<span class="token number">94</span>       <span class="token boolean">True</span>
<span class="token number">1146</span>     <span class="token boolean">True</span>
<span class="token number">1125</span>    <span class="token boolean">False</span>
<span class="token number">386</span>      <span class="token boolean">True</span>
<span class="token number">1025</span>    <span class="token boolean">False</span>
<span class="token number">337</span>      <span class="token boolean">True</span>
Name<span class="token punctuation">:</span> survived<span class="token punctuation">,</span> Length<span class="token punctuation">:</span> <span class="token number">329</span><span class="token punctuation">,</span> dtype<span class="token punctuation">:</span> bool
准确率为：
 <span class="token number">0.7811550151975684</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>7）集成学习方法之随机森林：</p>
<p>a、集成学习方法：通过建立几个模型组合来解决单一预测问题，它的工作原理是生成多个分类器/模型，各自独立的学习和作出预测，这些预测最后结合成组合预测，因此优于任何一个单分类的做出预测</p>
<p>b、随机森林：是一个包含多个决策树的分类器，并且其输出的类别是由个别树输出的类别的众数而定(少数服从多数)</p>
<p>c、随机森林原理：</p>
<p>随机：</p>
<p>●训练集随机—用bootstrap（随机有放回抽样）在N个样本中随机有放回的抽样N个</p>
<p>eg：现有训练集[1,2,3]，第一次取到了2，第二次取到了2，第三次取到了1，就形成了新的树的训练集[2,2,1]，重复三次随机取数，</p>
<p>●特征随机—从M个特征中随机抽取m个特征 （M&gt;&gt;m），建立决策树，可以降维</p>
<p><strong>d、API：sklearn.ensemble.RandomForestClassifier(n_estimators=10,criterion=’gini’,max_depth=None,bootstrap=True,random_state=None,min_samples_split=2)</strong></p>
<p>●n_estimators：int，是森林的树的个数，120，200，300，500，800，1200</p>
<p>●criterion：string，是分割特征的测量方法，可选’gini‘、’entropy‘</p>
<p>●max_depth：int或None，是树的最大深度，默认为None，5，8，15，25，30</p>
<p>●man_features=’auto’：每个决策树的最大特征数量 </p>
<p>​          auto或sqrt：m就是对M平方根求得</p>
<p>​          log2：m就是log2（M）求得</p>
<p>​          None：m就等于M，但耗时长，也没有降维</p>
<p>●bootstrap：boolean，是否在构建树时使用有放回抽样，默认为True</p>
<p>●min_samples_split：节点划分最少样本数</p>
<p>●min_samples_leaf：叶子节点的最少样本数</p>
<p>●超参数（可以修改值的参数）：n_estimators、max_depth、min_samples_split、min_samples_leaf</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split<span class="token punctuation">,</span>GridSearchCV
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>tree <span class="token keyword">import</span> export_graphviz
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_extraction <span class="token keyword">import</span> DictVectorizer
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>ensemble <span class="token keyword">import</span> RandomForestClassifier

<span class="token comment" spellcheck="true">#1、获取数据</span>
path<span class="token operator">=</span><span class="token string">'http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic.txt'</span>
data<span class="token operator">=</span>pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>path<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#print(data)</span>
<span class="token comment" spellcheck="true">#筛选特征值和目标值</span>
x<span class="token operator">=</span>data<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'pclass'</span><span class="token punctuation">,</span><span class="token string">'age'</span><span class="token punctuation">,</span><span class="token string">'sex'</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
y<span class="token operator">=</span>data<span class="token punctuation">[</span><span class="token string">'survived'</span><span class="token punctuation">]</span>
<span class="token comment" spellcheck="true">#print(x)</span>
<span class="token comment" spellcheck="true">#print(y)</span>
<span class="token comment" spellcheck="true">#2、数据处理</span>
<span class="token comment" spellcheck="true">#缺失值处理</span>
x<span class="token punctuation">[</span><span class="token string">'age'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>fillna<span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token string">'age'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#print(x)</span>
<span class="token comment" spellcheck="true">#转换成字典</span>
x<span class="token operator">=</span>x<span class="token punctuation">.</span>to_dict<span class="token punctuation">(</span>orient<span class="token operator">=</span><span class="token string">'records'</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#3、数据集划分</span>
x_train<span class="token punctuation">,</span>x_test<span class="token punctuation">,</span>y_train<span class="token punctuation">,</span>y_test<span class="token operator">=</span>train_test_split<span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">,</span>random_state<span class="token operator">=</span><span class="token number">22</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#4、字典特征抽取</span>
transfer<span class="token operator">=</span>DictVectorizer<span class="token punctuation">(</span><span class="token punctuation">)</span>
x_train<span class="token operator">=</span>transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>x_train<span class="token punctuation">)</span>
x_test<span class="token operator">=</span>transfer<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#5、随机森林预估器</span>
estimator<span class="token operator">=</span>RandomForestClassifier<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#加入网格搜索与交叉验证</span>
<span class="token comment" spellcheck="true">#参数准备,注意中间是：号</span>
k_range<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">'n_estimators'</span><span class="token punctuation">:</span><span class="token punctuation">[</span><span class="token number">120</span><span class="token punctuation">,</span><span class="token number">200</span><span class="token punctuation">,</span><span class="token number">300</span><span class="token punctuation">,</span><span class="token number">500</span><span class="token punctuation">,</span><span class="token number">800</span><span class="token punctuation">,</span><span class="token number">1200</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token string">'max_depth'</span><span class="token punctuation">:</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">15</span><span class="token punctuation">,</span><span class="token number">25</span><span class="token punctuation">,</span><span class="token number">30</span><span class="token punctuation">]</span><span class="token punctuation">}</span>
estimator<span class="token operator">=</span>GridSearchCV<span class="token punctuation">(</span>estimator<span class="token punctuation">,</span>param_grid<span class="token operator">=</span>k_range<span class="token punctuation">,</span>cv<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>
estimator<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span>y_train<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"最佳参数：\n"</span><span class="token punctuation">,</span>estimator<span class="token punctuation">.</span>best_params_<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"最佳结果：\n"</span><span class="token punctuation">,</span>estimator<span class="token punctuation">.</span>best_score_<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"最佳估计器：\n"</span><span class="token punctuation">,</span>estimator<span class="token punctuation">.</span>best_estimator_<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"交叉验证结果：\n"</span><span class="token punctuation">,</span>estimator<span class="token punctuation">.</span>cv_results_<span class="token punctuation">)</span>
estimator<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span>y_train<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#6、模型评估</span>
<span class="token comment" spellcheck="true">#方法一：直接比对真实值和预测值</span>
y_predict<span class="token operator">=</span>estimator<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"y_predict:\n"</span><span class="token punctuation">,</span>y_predict<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"直接比对真实值和预测值:\n"</span><span class="token punctuation">,</span>y_test<span class="token operator">==</span>y_predict<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#方法二：计算准确率</span>
score<span class="token operator">=</span>estimator<span class="token punctuation">.</span>score<span class="token punctuation">(</span>x_test<span class="token punctuation">,</span>y_test<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'准确率为：\n'</span><span class="token punctuation">,</span>score<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#6、可视化决策树  这里feature_names不能写原表格的了，因为原表格的特征已经转换成了ont-hot编码，可以用transfer来代替</span>
export_graphviz<span class="token punctuation">(</span>estimator<span class="token punctuation">,</span>out_file<span class="token operator">=</span><span class="token string">'taitan_tree.dot'</span><span class="token punctuation">,</span>feature_names<span class="token operator">=</span>transfer<span class="token punctuation">.</span>feature_names_<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#将生成的iris_tree.dot文件里面的内容复制，打开网页http://webgraphviz.com/  然后粘贴进文本框内（先清除原来的），再点击Generate Graph</span>

结果如下：
最佳参数：
 <span class="token punctuation">{</span><span class="token string">'max_depth'</span><span class="token punctuation">:</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token string">'n_estimators'</span><span class="token punctuation">:</span> <span class="token number">200</span><span class="token punctuation">}</span>
最佳结果：
 <span class="token number">0.8353658536585366</span>
最佳估计器：
 RandomForestClassifier<span class="token punctuation">(</span>bootstrap<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> class_weight<span class="token operator">=</span>None<span class="token punctuation">,</span> criterion<span class="token operator">=</span><span class="token string">'gini'</span><span class="token punctuation">,</span>
            max_depth<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> max_features<span class="token operator">=</span><span class="token string">'auto'</span><span class="token punctuation">,</span> max_leaf_nodes<span class="token operator">=</span>None<span class="token punctuation">,</span>
            min_impurity_decrease<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">,</span> min_impurity_split<span class="token operator">=</span>None<span class="token punctuation">,</span>
            min_samples_leaf<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> min_samples_split<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>
            min_weight_fraction_leaf<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">,</span> n_estimators<span class="token operator">=</span><span class="token number">200</span><span class="token punctuation">,</span> n_jobs<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>
            oob_score<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span>None<span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>
            warm_start<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
交叉验证结果：
 <span class="token punctuation">{</span><span class="token string">'mean_fit_time'</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.13497988</span><span class="token punctuation">,</span> <span class="token number">0.22993271</span><span class="token punctuation">,</span> <span class="token number">0.33974361</span><span class="token punctuation">,</span> <span class="token number">0.57004078</span><span class="token punctuation">,</span> <span class="token number">0.91253829</span><span class="token punctuation">,</span>
       <span class="token number">1.51141604</span><span class="token punctuation">,</span> <span class="token number">0.1615816</span> <span class="token punctuation">,</span> <span class="token number">0.28006363</span><span class="token punctuation">,</span> <span class="token number">0.43485618</span><span class="token punctuation">,</span> <span class="token number">0.66296236</span><span class="token punctuation">,</span>
       <span class="token number">1.23243022</span><span class="token punctuation">,</span> <span class="token number">1.7259535</span> <span class="token punctuation">,</span> <span class="token number">0.19537401</span><span class="token punctuation">,</span> <span class="token number">0.31062762</span><span class="token punctuation">,</span> <span class="token number">0.52124492</span><span class="token punctuation">,</span>
       <span class="token number">0.71280917</span><span class="token punctuation">,</span> <span class="token number">1.15506212</span><span class="token punctuation">,</span> <span class="token number">2.36032724</span><span class="token punctuation">,</span> <span class="token number">0.22091881</span><span class="token punctuation">,</span> <span class="token number">0.396523</span>  <span class="token punctuation">,</span>
       <span class="token number">0.42929665</span><span class="token punctuation">,</span> <span class="token number">0.67285188</span><span class="token punctuation">,</span> <span class="token number">1.19811018</span><span class="token punctuation">,</span> <span class="token number">2.48138499</span><span class="token punctuation">,</span> <span class="token number">0.20146855</span><span class="token punctuation">,</span>
       <span class="token number">0.2733709</span> <span class="token punctuation">,</span> <span class="token number">0.40365314</span><span class="token punctuation">,</span> <span class="token number">0.7274344</span> <span class="token punctuation">,</span> <span class="token number">1.27463214</span><span class="token punctuation">,</span> <span class="token number">1.66134715</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'std_fit_time'</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.00248424</span><span class="token punctuation">,</span> <span class="token number">0.00915963</span><span class="token punctuation">,</span> <span class="token number">0.00506458</span><span class="token punctuation">,</span> <span class="token number">0.02951781</span><span class="token punctuation">,</span> <span class="token number">0.02784634</span><span class="token punctuation">,</span>
       <span class="token number">0.02390283</span><span class="token punctuation">,</span> <span class="token number">0.00711442</span><span class="token punctuation">,</span> <span class="token number">0.00478776</span><span class="token punctuation">,</span> <span class="token number">0.01021137</span><span class="token punctuation">,</span> <span class="token number">0.01989368</span><span class="token punctuation">,</span>
       <span class="token number">0.10124015</span><span class="token punctuation">,</span> <span class="token number">0.10005842</span><span class="token punctuation">,</span> <span class="token number">0.01958192</span><span class="token punctuation">,</span> <span class="token number">0.05043796</span><span class="token punctuation">,</span> <span class="token number">0.10473496</span><span class="token punctuation">,</span>
       <span class="token number">0.05259235</span><span class="token punctuation">,</span> <span class="token number">0.15432069</span><span class="token punctuation">,</span> <span class="token number">0.14537128</span><span class="token punctuation">,</span> <span class="token number">0.01095421</span><span class="token punctuation">,</span> <span class="token number">0.02758387</span><span class="token punctuation">,</span>
       <span class="token number">0.05188313</span><span class="token punctuation">,</span> <span class="token number">0.04176852</span><span class="token punctuation">,</span> <span class="token number">0.10909219</span><span class="token punctuation">,</span> <span class="token number">0.32678635</span><span class="token punctuation">,</span> <span class="token number">0.01648684</span><span class="token punctuation">,</span>
       <span class="token number">0.02547753</span><span class="token punctuation">,</span> <span class="token number">0.00637631</span><span class="token punctuation">,</span> <span class="token number">0.07555031</span><span class="token punctuation">,</span> <span class="token number">0.09740699</span><span class="token punctuation">,</span> <span class="token number">0.05736806</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'mean_score_time'</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.00994436</span><span class="token punctuation">,</span> <span class="token number">0.01485085</span><span class="token punctuation">,</span> <span class="token number">0.02362704</span><span class="token punctuation">,</span> <span class="token number">0.03722167</span><span class="token punctuation">,</span> <span class="token number">0.06304256</span><span class="token punctuation">,</span>
       <span class="token number">0.0949537</span> <span class="token punctuation">,</span> <span class="token number">0.01064054</span><span class="token punctuation">,</span> <span class="token number">0.01762025</span><span class="token punctuation">,</span> <span class="token number">0.02527142</span><span class="token punctuation">,</span> <span class="token number">0.03991191</span><span class="token punctuation">,</span>
       <span class="token number">0.08746322</span><span class="token punctuation">,</span> <span class="token number">0.10489575</span><span class="token punctuation">,</span> <span class="token number">0.01230081</span><span class="token punctuation">,</span> <span class="token number">0.01825452</span><span class="token punctuation">,</span> <span class="token number">0.03473608</span><span class="token punctuation">,</span>
       <span class="token number">0.04585862</span><span class="token punctuation">,</span> <span class="token number">0.06484</span>   <span class="token punctuation">,</span> <span class="token number">0.13069789</span><span class="token punctuation">,</span> <span class="token number">0.01364191</span><span class="token punctuation">,</span> <span class="token number">0.02396957</span><span class="token punctuation">,</span>
       <span class="token number">0.02559376</span><span class="token punctuation">,</span> <span class="token number">0.058091</span>  <span class="token punctuation">,</span> <span class="token number">0.08546575</span><span class="token punctuation">,</span> <span class="token number">0.14314755</span><span class="token punctuation">,</span> <span class="token number">0.01228372</span><span class="token punctuation">,</span>
       <span class="token number">0.016512</span>  <span class="token punctuation">,</span> <span class="token number">0.0240887</span> <span class="token punctuation">,</span> <span class="token number">0.04587722</span><span class="token punctuation">,</span> <span class="token number">0.07265441</span><span class="token punctuation">,</span> <span class="token number">0.09430226</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'std_score_time'</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2.48949288e-05</span><span class="token punctuation">,</span> <span class="token number">1.54766288e-04</span><span class="token punctuation">,</span> <span class="token number">2.34618238e-03</span><span class="token punctuation">,</span> <span class="token number">1.24763292e-03</span><span class="token punctuation">,</span>
       <span class="token number">8.43396227e-03</span><span class="token punctuation">,</span> <span class="token number">8.57349376e-03</span><span class="token punctuation">,</span> <span class="token number">9.77920517e-04</span><span class="token punctuation">,</span> <span class="token number">2.35083916e-03</span><span class="token punctuation">,</span>
       <span class="token number">4.65903009e-04</span><span class="token punctuation">,</span> <span class="token number">2.84732870e-03</span><span class="token punctuation">,</span> <span class="token number">1.72072683e-02</span><span class="token punctuation">,</span> <span class="token number">8.78540306e-03</span><span class="token punctuation">,</span>
       <span class="token number">1.69504566e-03</span><span class="token punctuation">,</span> <span class="token number">1.26758512e-03</span><span class="token punctuation">,</span> <span class="token number">8.77921087e-03</span><span class="token punctuation">,</span> <span class="token number">9.88598798e-03</span><span class="token punctuation">,</span>
       <span class="token number">4.20874057e-03</span><span class="token punctuation">,</span> <span class="token number">1.19616886e-02</span><span class="token punctuation">,</span> <span class="token number">1.23282701e-03</span><span class="token punctuation">,</span> <span class="token number">8.13135534e-04</span><span class="token punctuation">,</span>
       <span class="token number">3.76236524e-03</span><span class="token punctuation">,</span> <span class="token number">6.46747949e-03</span><span class="token punctuation">,</span> <span class="token number">3.20138516e-02</span><span class="token punctuation">,</span> <span class="token number">6.06464537e-03</span><span class="token punctuation">,</span>
       <span class="token number">2.06910676e-03</span><span class="token punctuation">,</span> <span class="token number">8.10619904e-04</span><span class="token punctuation">,</span> <span class="token number">6.24292037e-04</span><span class="token punctuation">,</span> <span class="token number">8.49751829e-03</span><span class="token punctuation">,</span>
       <span class="token number">1.62478913e-03</span><span class="token punctuation">,</span> <span class="token number">1.45730998e-03</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'param_max_depth'</span><span class="token punctuation">:</span> masked_array<span class="token punctuation">(</span>data<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">,</span>
                   <span class="token number">15</span><span class="token punctuation">,</span> <span class="token number">25</span><span class="token punctuation">,</span> <span class="token number">25</span><span class="token punctuation">,</span> <span class="token number">25</span><span class="token punctuation">,</span> <span class="token number">25</span><span class="token punctuation">,</span> <span class="token number">25</span><span class="token punctuation">,</span> <span class="token number">25</span><span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
             mask<span class="token operator">=</span><span class="token punctuation">[</span><span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span>
                   <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span>
                   <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span>
                   <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
       fill_value<span class="token operator">=</span><span class="token string">'?'</span><span class="token punctuation">,</span>
            dtype<span class="token operator">=</span>object<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'param_n_estimators'</span><span class="token punctuation">:</span> masked_array<span class="token punctuation">(</span>data<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">120</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">,</span> <span class="token number">300</span><span class="token punctuation">,</span> <span class="token number">500</span><span class="token punctuation">,</span> <span class="token number">800</span><span class="token punctuation">,</span> <span class="token number">1200</span><span class="token punctuation">,</span> <span class="token number">120</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">,</span> <span class="token number">300</span><span class="token punctuation">,</span> <span class="token number">500</span><span class="token punctuation">,</span> <span class="token number">800</span><span class="token punctuation">,</span>
                   <span class="token number">1200</span><span class="token punctuation">,</span> <span class="token number">120</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">,</span> <span class="token number">300</span><span class="token punctuation">,</span> <span class="token number">500</span><span class="token punctuation">,</span> <span class="token number">800</span><span class="token punctuation">,</span> <span class="token number">1200</span><span class="token punctuation">,</span> <span class="token number">120</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">,</span> <span class="token number">300</span><span class="token punctuation">,</span>
                   <span class="token number">500</span><span class="token punctuation">,</span> <span class="token number">800</span><span class="token punctuation">,</span> <span class="token number">1200</span><span class="token punctuation">,</span> <span class="token number">120</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">,</span> <span class="token number">300</span><span class="token punctuation">,</span> <span class="token number">500</span><span class="token punctuation">,</span> <span class="token number">800</span><span class="token punctuation">,</span> <span class="token number">1200</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
             mask<span class="token operator">=</span><span class="token punctuation">[</span><span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span>
                   <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span>
                   <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span>
                   <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
       fill_value<span class="token operator">=</span><span class="token string">'?'</span><span class="token punctuation">,</span>
            dtype<span class="token operator">=</span>object<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'params'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token string">'max_depth'</span><span class="token punctuation">:</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token string">'n_estimators'</span><span class="token punctuation">:</span> <span class="token number">120</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span><span class="token string">'max_depth'</span><span class="token punctuation">:</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token string">'n_estimators'</span><span class="token punctuation">:</span> <span class="token number">200</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span><span class="token string">'max_depth'</span><span class="token punctuation">:</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token string">'n_estimators'</span><span class="token punctuation">:</span> <span class="token number">300</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span><span class="token string">'max_depth'</span><span class="token punctuation">:</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token string">'n_estimators'</span><span class="token punctuation">:</span> <span class="token number">500</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span><span class="token string">'max_depth'</span><span class="token punctuation">:</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token string">'n_estimators'</span><span class="token punctuation">:</span> <span class="token number">800</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span><span class="token string">'max_depth'</span><span class="token punctuation">:</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token string">'n_estimators'</span><span class="token punctuation">:</span> <span class="token number">1200</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span><span class="token string">'max_depth'</span><span class="token punctuation">:</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token string">'n_estimators'</span><span class="token punctuation">:</span> <span class="token number">120</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span><span class="token string">'max_depth'</span><span class="token punctuation">:</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token string">'n_estimators'</span><span class="token punctuation">:</span> <span class="token number">200</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span><span class="token string">'max_depth'</span><span class="token punctuation">:</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token string">'n_estimators'</span><span class="token punctuation">:</span> <span class="token number">300</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span><span class="token string">'max_depth'</span><span class="token punctuation">:</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token string">'n_estimators'</span><span class="token punctuation">:</span> <span class="token number">500</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span><span class="token string">'max_depth'</span><span class="token punctuation">:</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token string">'n_estimators'</span><span class="token punctuation">:</span> <span class="token number">800</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span><span class="token string">'max_depth'</span><span class="token punctuation">:</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token string">'n_estimators'</span><span class="token punctuation">:</span> <span class="token number">1200</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span><span class="token string">'max_depth'</span><span class="token punctuation">:</span> <span class="token number">15</span><span class="token punctuation">,</span> <span class="token string">'n_estimators'</span><span class="token punctuation">:</span> <span class="token number">120</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span><span class="token string">'max_depth'</span><span class="token punctuation">:</span> <span class="token number">15</span><span class="token punctuation">,</span> <span class="token string">'n_estimators'</span><span class="token punctuation">:</span> <span class="token number">200</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span><span class="token string">'max_depth'</span><span class="token punctuation">:</span> <span class="token number">15</span><span class="token punctuation">,</span> <span class="token string">'n_estimators'</span><span class="token punctuation">:</span> <span class="token number">300</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span><span class="token string">'max_depth'</span><span class="token punctuation">:</span> <span class="token number">15</span><span class="token punctuation">,</span> <span class="token string">'n_estimators'</span><span class="token punctuation">:</span> <span class="token number">500</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span><span class="token string">'max_depth'</span><span class="token punctuation">:</span> <span class="token number">15</span><span class="token punctuation">,</span> <span class="token string">'n_estimators'</span><span class="token punctuation">:</span> <span class="token number">800</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span><span class="token string">'max_depth'</span><span class="token punctuation">:</span> <span class="token number">15</span><span class="token punctuation">,</span> <span class="token string">'n_estimators'</span><span class="token punctuation">:</span> <span class="token number">1200</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span><span class="token string">'max_depth'</span><span class="token punctuation">:</span> <span class="token number">25</span><span class="token punctuation">,</span> <span class="token string">'n_estimators'</span><span class="token punctuation">:</span> <span class="token number">120</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span><span class="token string">'max_depth'</span><span class="token punctuation">:</span> <span class="token number">25</span><span class="token punctuation">,</span> <span class="token string">'n_estimators'</span><span class="token punctuation">:</span> <span class="token number">200</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span><span class="token string">'max_depth'</span><span class="token punctuation">:</span> <span class="token number">25</span><span class="token punctuation">,</span> <span class="token string">'n_estimators'</span><span class="token punctuation">:</span> <span class="token number">300</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span><span class="token string">'max_depth'</span><span class="token punctuation">:</span> <span class="token number">25</span><span class="token punctuation">,</span> <span class="token string">'n_estimators'</span><span class="token punctuation">:</span> <span class="token number">500</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span><span class="token string">'max_depth'</span><span class="token punctuation">:</span> <span class="token number">25</span><span class="token punctuation">,</span> <span class="token string">'n_estimators'</span><span class="token punctuation">:</span> <span class="token number">800</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span><span class="token string">'max_depth'</span><span class="token punctuation">:</span> <span class="token number">25</span><span class="token punctuation">,</span> <span class="token string">'n_estimators'</span><span class="token punctuation">:</span> <span class="token number">1200</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span><span class="token string">'max_depth'</span><span class="token punctuation">:</span> <span class="token number">30</span><span class="token punctuation">,</span> <span class="token string">'n_estimators'</span><span class="token punctuation">:</span> <span class="token number">120</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span><span class="token string">'max_depth'</span><span class="token punctuation">:</span> <span class="token number">30</span><span class="token punctuation">,</span> <span class="token string">'n_estimators'</span><span class="token punctuation">:</span> <span class="token number">200</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span><span class="token string">'max_depth'</span><span class="token punctuation">:</span> <span class="token number">30</span><span class="token punctuation">,</span> <span class="token string">'n_estimators'</span><span class="token punctuation">:</span> <span class="token number">300</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span><span class="token string">'max_depth'</span><span class="token punctuation">:</span> <span class="token number">30</span><span class="token punctuation">,</span> <span class="token string">'n_estimators'</span><span class="token punctuation">:</span> <span class="token number">500</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span><span class="token string">'max_depth'</span><span class="token punctuation">:</span> <span class="token number">30</span><span class="token punctuation">,</span> <span class="token string">'n_estimators'</span><span class="token punctuation">:</span> <span class="token number">800</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span><span class="token string">'max_depth'</span><span class="token punctuation">:</span> <span class="token number">30</span><span class="token punctuation">,</span> <span class="token string">'n_estimators'</span><span class="token punctuation">:</span> <span class="token number">1200</span><span class="token punctuation">}</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'split0_test_score'</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.82370821</span><span class="token punctuation">,</span> <span class="token number">0.82674772</span><span class="token punctuation">,</span> <span class="token number">0.82370821</span><span class="token punctuation">,</span> <span class="token number">0.82674772</span><span class="token punctuation">,</span> <span class="token number">0.82674772</span><span class="token punctuation">,</span>
       <span class="token number">0.82674772</span><span class="token punctuation">,</span> <span class="token number">0.81155015</span><span class="token punctuation">,</span> <span class="token number">0.81155015</span><span class="token punctuation">,</span> <span class="token number">0.79635258</span><span class="token punctuation">,</span> <span class="token number">0.80243161</span><span class="token punctuation">,</span>
       <span class="token number">0.80243161</span><span class="token punctuation">,</span> <span class="token number">0.81155015</span><span class="token punctuation">,</span> <span class="token number">0.7993921</span> <span class="token punctuation">,</span> <span class="token number">0.79635258</span><span class="token punctuation">,</span> <span class="token number">0.79027356</span><span class="token punctuation">,</span>
       <span class="token number">0.79635258</span><span class="token punctuation">,</span> <span class="token number">0.79027356</span><span class="token punctuation">,</span> <span class="token number">0.79027356</span><span class="token punctuation">,</span> <span class="token number">0.79635258</span><span class="token punctuation">,</span> <span class="token number">0.79027356</span><span class="token punctuation">,</span>
       <span class="token number">0.7993921</span> <span class="token punctuation">,</span> <span class="token number">0.7993921</span> <span class="token punctuation">,</span> <span class="token number">0.79027356</span><span class="token punctuation">,</span> <span class="token number">0.79331307</span><span class="token punctuation">,</span> <span class="token number">0.7993921</span> <span class="token punctuation">,</span>
       <span class="token number">0.79331307</span><span class="token punctuation">,</span> <span class="token number">0.79027356</span><span class="token punctuation">,</span> <span class="token number">0.79635258</span><span class="token punctuation">,</span> <span class="token number">0.79331307</span><span class="token punctuation">,</span> <span class="token number">0.79331307</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'split1_test_score'</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.85060976</span><span class="token punctuation">,</span> <span class="token number">0.85365854</span><span class="token punctuation">,</span> <span class="token number">0.85365854</span><span class="token punctuation">,</span> <span class="token number">0.85365854</span><span class="token punctuation">,</span> <span class="token number">0.85365854</span><span class="token punctuation">,</span>
       <span class="token number">0.85365854</span><span class="token punctuation">,</span> <span class="token number">0.85365854</span><span class="token punctuation">,</span> <span class="token number">0.85365854</span><span class="token punctuation">,</span> <span class="token number">0.85365854</span><span class="token punctuation">,</span> <span class="token number">0.85060976</span><span class="token punctuation">,</span>
       <span class="token number">0.85060976</span><span class="token punctuation">,</span> <span class="token number">0.85670732</span><span class="token punctuation">,</span> <span class="token number">0.85365854</span><span class="token punctuation">,</span> <span class="token number">0.85670732</span><span class="token punctuation">,</span> <span class="token number">0.85365854</span><span class="token punctuation">,</span>
       <span class="token number">0.8445122</span> <span class="token punctuation">,</span> <span class="token number">0.85670732</span><span class="token punctuation">,</span> <span class="token number">0.8597561</span> <span class="token punctuation">,</span> <span class="token number">0.84756098</span><span class="token punctuation">,</span> <span class="token number">0.85365854</span><span class="token punctuation">,</span>
       <span class="token number">0.85365854</span><span class="token punctuation">,</span> <span class="token number">0.85365854</span><span class="token punctuation">,</span> <span class="token number">0.85670732</span><span class="token punctuation">,</span> <span class="token number">0.85060976</span><span class="token punctuation">,</span> <span class="token number">0.85670732</span><span class="token punctuation">,</span>
       <span class="token number">0.85365854</span><span class="token punctuation">,</span> <span class="token number">0.85060976</span><span class="token punctuation">,</span> <span class="token number">0.85060976</span><span class="token punctuation">,</span> <span class="token number">0.8597561</span> <span class="token punctuation">,</span> <span class="token number">0.85365854</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'split2_test_score'</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.82262997</span><span class="token punctuation">,</span> <span class="token number">0.82568807</span><span class="token punctuation">,</span> <span class="token number">0.82568807</span><span class="token punctuation">,</span> <span class="token number">0.82262997</span><span class="token punctuation">,</span> <span class="token number">0.82262997</span><span class="token punctuation">,</span>
       <span class="token number">0.82262997</span><span class="token punctuation">,</span> <span class="token number">0.80428135</span><span class="token punctuation">,</span> <span class="token number">0.80428135</span><span class="token punctuation">,</span> <span class="token number">0.80428135</span><span class="token punctuation">,</span> <span class="token number">0.80122324</span><span class="token punctuation">,</span>
       <span class="token number">0.80122324</span><span class="token punctuation">,</span> <span class="token number">0.80122324</span><span class="token punctuation">,</span> <span class="token number">0.80122324</span><span class="token punctuation">,</span> <span class="token number">0.80122324</span><span class="token punctuation">,</span> <span class="token number">0.80122324</span><span class="token punctuation">,</span>
       <span class="token number">0.80428135</span><span class="token punctuation">,</span> <span class="token number">0.80122324</span><span class="token punctuation">,</span> <span class="token number">0.80428135</span><span class="token punctuation">,</span> <span class="token number">0.80122324</span><span class="token punctuation">,</span> <span class="token number">0.80122324</span><span class="token punctuation">,</span>
       <span class="token number">0.80428135</span><span class="token punctuation">,</span> <span class="token number">0.80122324</span><span class="token punctuation">,</span> <span class="token number">0.80428135</span><span class="token punctuation">,</span> <span class="token number">0.80122324</span><span class="token punctuation">,</span> <span class="token number">0.80122324</span><span class="token punctuation">,</span>
       <span class="token number">0.79816514</span><span class="token punctuation">,</span> <span class="token number">0.80122324</span><span class="token punctuation">,</span> <span class="token number">0.80122324</span><span class="token punctuation">,</span> <span class="token number">0.80122324</span><span class="token punctuation">,</span> <span class="token number">0.80428135</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'mean_test_score'</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.83231707</span><span class="token punctuation">,</span> <span class="token number">0.83536585</span><span class="token punctuation">,</span> <span class="token number">0.83434959</span><span class="token punctuation">,</span> <span class="token number">0.83434959</span><span class="token punctuation">,</span> <span class="token number">0.83434959</span><span class="token punctuation">,</span>
       <span class="token number">0.83434959</span><span class="token punctuation">,</span> <span class="token number">0.82317073</span><span class="token punctuation">,</span> <span class="token number">0.82317073</span><span class="token punctuation">,</span> <span class="token number">0.81808943</span><span class="token punctuation">,</span> <span class="token number">0.81808943</span><span class="token punctuation">,</span>
       <span class="token number">0.81808943</span><span class="token punctuation">,</span> <span class="token number">0.82317073</span><span class="token punctuation">,</span> <span class="token number">0.81808943</span><span class="token punctuation">,</span> <span class="token number">0.81808943</span><span class="token punctuation">,</span> <span class="token number">0.81504065</span><span class="token punctuation">,</span>
       <span class="token number">0.81504065</span><span class="token punctuation">,</span> <span class="token number">0.81605691</span><span class="token punctuation">,</span> <span class="token number">0.81808943</span><span class="token punctuation">,</span> <span class="token number">0.81504065</span><span class="token punctuation">,</span> <span class="token number">0.81504065</span><span class="token punctuation">,</span>
       <span class="token number">0.81910569</span><span class="token punctuation">,</span> <span class="token number">0.81808943</span><span class="token punctuation">,</span> <span class="token number">0.81707317</span><span class="token punctuation">,</span> <span class="token number">0.81504065</span><span class="token punctuation">,</span> <span class="token number">0.81910569</span><span class="token punctuation">,</span>
       <span class="token number">0.81504065</span><span class="token punctuation">,</span> <span class="token number">0.81402439</span><span class="token punctuation">,</span> <span class="token number">0.81605691</span><span class="token punctuation">,</span> <span class="token number">0.81808943</span><span class="token punctuation">,</span> <span class="token number">0.81707317</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'std_test_score'</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.01294237</span><span class="token punctuation">,</span> <span class="token number">0.01294211</span><span class="token punctuation">,</span> <span class="token number">0.01367739</span><span class="token punctuation">,</span> <span class="token number">0.01375658</span><span class="token punctuation">,</span> <span class="token number">0.01375658</span><span class="token punctuation">,</span>
       <span class="token number">0.01375658</span><span class="token punctuation">,</span> <span class="token number">0.02176141</span><span class="token punctuation">,</span> <span class="token number">0.02176141</span><span class="token punctuation">,</span> <span class="token number">0.02535859</span><span class="token punctuation">,</span> <span class="token number">0.02300063</span><span class="token punctuation">,</span>
       <span class="token number">0.02300063</span><span class="token punctuation">,</span> <span class="token number">0.02408579</span><span class="token punctuation">,</span> <span class="token number">0.02516226</span><span class="token punctuation">,</span> <span class="token number">0.02737927</span><span class="token punctuation">,</span> <span class="token number">0.02767044</span><span class="token punctuation">,</span>
       <span class="token number">0.02108941</span><span class="token punctuation">,</span> <span class="token number">0.02908969</span><span class="token punctuation">,</span> <span class="token number">0.03001264</span><span class="token punctuation">,</span> <span class="token number">0.02308115</span><span class="token punctuation">,</span> <span class="token number">0.02767044</span><span class="token punctuation">,</span>
       <span class="token number">0.02451395</span><span class="token punctuation">,</span> <span class="token number">0.02516226</span><span class="token punctuation">,</span> <span class="token number">0.02860307</span><span class="token punctuation">,</span> <span class="token number">0.02535762</span><span class="token punctuation">,</span> <span class="token number">0.02659887</span><span class="token punctuation">,</span>
       <span class="token number">0.02737872</span><span class="token punctuation">,</span> <span class="token number">0.02625313</span><span class="token punctuation">,</span> <span class="token number">0.02451333</span><span class="token punctuation">,</span> <span class="token number">0.02963923</span><span class="token punctuation">,</span> <span class="token number">0.02625442</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'rank_test_score'</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">6</span><span class="token punctuation">,</span>  <span class="token number">1</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">,</span>  <span class="token number">7</span><span class="token punctuation">,</span>  <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">,</span>  <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">22</span><span class="token punctuation">,</span>
       <span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">,</span> <span class="token number">22</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'split0_train_score'</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.8610687</span> <span class="token punctuation">,</span> <span class="token number">0.85648855</span><span class="token punctuation">,</span> <span class="token number">0.85801527</span><span class="token punctuation">,</span> <span class="token number">0.85648855</span><span class="token punctuation">,</span> <span class="token number">0.85648855</span><span class="token punctuation">,</span>
       <span class="token number">0.85801527</span><span class="token punctuation">,</span> <span class="token number">0.87328244</span><span class="token punctuation">,</span> <span class="token number">0.87480916</span><span class="token punctuation">,</span> <span class="token number">0.87480916</span><span class="token punctuation">,</span> <span class="token number">0.87633588</span><span class="token punctuation">,</span>
       <span class="token number">0.87633588</span><span class="token punctuation">,</span> <span class="token number">0.87480916</span><span class="token punctuation">,</span> <span class="token number">0.88244275</span><span class="token punctuation">,</span> <span class="token number">0.88244275</span><span class="token punctuation">,</span> <span class="token number">0.88244275</span><span class="token punctuation">,</span>
       <span class="token number">0.88244275</span><span class="token punctuation">,</span> <span class="token number">0.88244275</span><span class="token punctuation">,</span> <span class="token number">0.88244275</span><span class="token punctuation">,</span> <span class="token number">0.88244275</span><span class="token punctuation">,</span> <span class="token number">0.88244275</span><span class="token punctuation">,</span>
       <span class="token number">0.88244275</span><span class="token punctuation">,</span> <span class="token number">0.88244275</span><span class="token punctuation">,</span> <span class="token number">0.88244275</span><span class="token punctuation">,</span> <span class="token number">0.88244275</span><span class="token punctuation">,</span> <span class="token number">0.88244275</span><span class="token punctuation">,</span>
       <span class="token number">0.88244275</span><span class="token punctuation">,</span> <span class="token number">0.88244275</span><span class="token punctuation">,</span> <span class="token number">0.88244275</span><span class="token punctuation">,</span> <span class="token number">0.88244275</span><span class="token punctuation">,</span> <span class="token number">0.88244275</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'split1_train_score'</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.8445122</span> <span class="token punctuation">,</span> <span class="token number">0.84756098</span><span class="token punctuation">,</span> <span class="token number">0.84603659</span><span class="token punctuation">,</span> <span class="token number">0.84756098</span><span class="token punctuation">,</span> <span class="token number">0.84756098</span><span class="token punctuation">,</span>
       <span class="token number">0.84756098</span><span class="token punctuation">,</span> <span class="token number">0.86128049</span><span class="token punctuation">,</span> <span class="token number">0.86128049</span><span class="token punctuation">,</span> <span class="token number">0.86128049</span><span class="token punctuation">,</span> <span class="token number">0.86128049</span><span class="token punctuation">,</span>
       <span class="token number">0.86128049</span><span class="token punctuation">,</span> <span class="token number">0.86128049</span><span class="token punctuation">,</span> <span class="token number">0.86128049</span><span class="token punctuation">,</span> <span class="token number">0.86128049</span><span class="token punctuation">,</span> <span class="token number">0.86128049</span><span class="token punctuation">,</span>
       <span class="token number">0.86128049</span><span class="token punctuation">,</span> <span class="token number">0.86128049</span><span class="token punctuation">,</span> <span class="token number">0.86128049</span><span class="token punctuation">,</span> <span class="token number">0.86128049</span><span class="token punctuation">,</span> <span class="token number">0.86128049</span><span class="token punctuation">,</span>
       <span class="token number">0.86128049</span><span class="token punctuation">,</span> <span class="token number">0.86128049</span><span class="token punctuation">,</span> <span class="token number">0.86128049</span><span class="token punctuation">,</span> <span class="token number">0.86128049</span><span class="token punctuation">,</span> <span class="token number">0.86128049</span><span class="token punctuation">,</span>
       <span class="token number">0.86128049</span><span class="token punctuation">,</span> <span class="token number">0.86128049</span><span class="token punctuation">,</span> <span class="token number">0.86128049</span><span class="token punctuation">,</span> <span class="token number">0.86128049</span><span class="token punctuation">,</span> <span class="token number">0.86128049</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'split2_train_score'</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.87062405</span><span class="token punctuation">,</span> <span class="token number">0.86910198</span><span class="token punctuation">,</span> <span class="token number">0.86910198</span><span class="token punctuation">,</span> <span class="token number">0.86910198</span><span class="token punctuation">,</span> <span class="token number">0.86757991</span><span class="token punctuation">,</span>
       <span class="token number">0.86757991</span><span class="token punctuation">,</span> <span class="token number">0.88432268</span><span class="token punctuation">,</span> <span class="token number">0.88736682</span><span class="token punctuation">,</span> <span class="token number">0.88736682</span><span class="token punctuation">,</span> <span class="token number">0.88584475</span><span class="token punctuation">,</span>
       <span class="token number">0.88584475</span><span class="token punctuation">,</span> <span class="token number">0.88584475</span><span class="token punctuation">,</span> <span class="token number">0.88736682</span><span class="token punctuation">,</span> <span class="token number">0.88736682</span><span class="token punctuation">,</span> <span class="token number">0.88736682</span><span class="token punctuation">,</span>
       <span class="token number">0.88736682</span><span class="token punctuation">,</span> <span class="token number">0.88736682</span><span class="token punctuation">,</span> <span class="token number">0.88736682</span><span class="token punctuation">,</span> <span class="token number">0.88736682</span><span class="token punctuation">,</span> <span class="token number">0.88736682</span><span class="token punctuation">,</span>
       <span class="token number">0.88736682</span><span class="token punctuation">,</span> <span class="token number">0.88736682</span><span class="token punctuation">,</span> <span class="token number">0.88736682</span><span class="token punctuation">,</span> <span class="token number">0.88736682</span><span class="token punctuation">,</span> <span class="token number">0.88736682</span><span class="token punctuation">,</span>
       <span class="token number">0.88736682</span><span class="token punctuation">,</span> <span class="token number">0.88736682</span><span class="token punctuation">,</span> <span class="token number">0.88736682</span><span class="token punctuation">,</span> <span class="token number">0.88736682</span><span class="token punctuation">,</span> <span class="token number">0.88736682</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'mean_train_score'</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.85873498</span><span class="token punctuation">,</span> <span class="token number">0.85771717</span><span class="token punctuation">,</span> <span class="token number">0.85771794</span><span class="token punctuation">,</span> <span class="token number">0.85771717</span><span class="token punctuation">,</span> <span class="token number">0.85720981</span><span class="token punctuation">,</span>
       <span class="token number">0.85771872</span><span class="token punctuation">,</span> <span class="token number">0.87296187</span><span class="token punctuation">,</span> <span class="token number">0.87448549</span><span class="token punctuation">,</span> <span class="token number">0.87448549</span><span class="token punctuation">,</span> <span class="token number">0.87448704</span><span class="token punctuation">,</span>
       <span class="token number">0.87448704</span><span class="token punctuation">,</span> <span class="token number">0.87397813</span><span class="token punctuation">,</span> <span class="token number">0.87703002</span><span class="token punctuation">,</span> <span class="token number">0.87703002</span><span class="token punctuation">,</span> <span class="token number">0.87703002</span><span class="token punctuation">,</span>
       <span class="token number">0.87703002</span><span class="token punctuation">,</span> <span class="token number">0.87703002</span><span class="token punctuation">,</span> <span class="token number">0.87703002</span><span class="token punctuation">,</span> <span class="token number">0.87703002</span><span class="token punctuation">,</span> <span class="token number">0.87703002</span><span class="token punctuation">,</span>
       <span class="token number">0.87703002</span><span class="token punctuation">,</span> <span class="token number">0.87703002</span><span class="token punctuation">,</span> <span class="token number">0.87703002</span><span class="token punctuation">,</span> <span class="token number">0.87703002</span><span class="token punctuation">,</span> <span class="token number">0.87703002</span><span class="token punctuation">,</span>
       <span class="token number">0.87703002</span><span class="token punctuation">,</span> <span class="token number">0.87703002</span><span class="token punctuation">,</span> <span class="token number">0.87703002</span><span class="token punctuation">,</span> <span class="token number">0.87703002</span><span class="token punctuation">,</span> <span class="token number">0.87703002</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'std_train_score'</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.01078709</span><span class="token punctuation">,</span> <span class="token number">0.00883689</span><span class="token punctuation">,</span> <span class="token number">0.00941875</span><span class="token punctuation">,</span> <span class="token number">0.00883689</span><span class="token punctuation">,</span> <span class="token number">0.00818859</span><span class="token punctuation">,</span>
       <span class="token number">0.00817538</span><span class="token punctuation">,</span> <span class="token number">0.00940967</span><span class="token punctuation">,</span> <span class="token number">0.01065216</span><span class="token punctuation">,</span> <span class="token number">0.01065216</span><span class="token punctuation">,</span> <span class="token number">0.01011317</span><span class="token punctuation">,</span>
       <span class="token number">0.01011317</span><span class="token punctuation">,</span> <span class="token number">0.01004552</span><span class="token punctuation">,</span> <span class="token number">0.01131658</span><span class="token punctuation">,</span> <span class="token number">0.01131658</span><span class="token punctuation">,</span> <span class="token number">0.01131658</span><span class="token punctuation">,</span>
       <span class="token number">0.01131658</span><span class="token punctuation">,</span> <span class="token number">0.01131658</span><span class="token punctuation">,</span> <span class="token number">0.01131658</span><span class="token punctuation">,</span> <span class="token number">0.01131658</span><span class="token punctuation">,</span> <span class="token number">0.01131658</span><span class="token punctuation">,</span>
       <span class="token number">0.01131658</span><span class="token punctuation">,</span> <span class="token number">0.01131658</span><span class="token punctuation">,</span> <span class="token number">0.01131658</span><span class="token punctuation">,</span> <span class="token number">0.01131658</span><span class="token punctuation">,</span> <span class="token number">0.01131658</span><span class="token punctuation">,</span>
       <span class="token number">0.01131658</span><span class="token punctuation">,</span> <span class="token number">0.01131658</span><span class="token punctuation">,</span> <span class="token number">0.01131658</span><span class="token punctuation">,</span> <span class="token number">0.01131658</span><span class="token punctuation">,</span> <span class="token number">0.01131658</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
y_predict<span class="token punctuation">:</span>
 <span class="token punctuation">[</span><span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span>
 <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span>
 <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span>
 <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span>
 <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span>
 <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span>
 <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span>
 <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span>
 <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span><span class="token punctuation">]</span>
直接比对真实值和预测值<span class="token punctuation">:</span>
 <span class="token number">831</span>      <span class="token boolean">True</span>
<span class="token number">261</span>      <span class="token boolean">True</span>
<span class="token number">1210</span>     <span class="token boolean">True</span>
<span class="token number">1155</span>     <span class="token boolean">True</span>
<span class="token number">255</span>      <span class="token boolean">True</span>
<span class="token number">762</span>      <span class="token boolean">True</span>
<span class="token number">615</span>      <span class="token boolean">True</span>
<span class="token number">507</span>      <span class="token boolean">True</span>
<span class="token number">1175</span>     <span class="token boolean">True</span>
<span class="token number">301</span>      <span class="token boolean">True</span>
<span class="token number">1134</span>     <span class="token boolean">True</span>
<span class="token number">177</span>      <span class="token boolean">True</span>
<span class="token number">183</span>     <span class="token boolean">False</span>
<span class="token number">125</span>     <span class="token boolean">False</span>
<span class="token number">1093</span>     <span class="token boolean">True</span>
<span class="token number">1304</span>    <span class="token boolean">False</span>
<span class="token number">1124</span>     <span class="token boolean">True</span>
<span class="token number">798</span>     <span class="token boolean">False</span>
<span class="token number">1101</span>     <span class="token boolean">True</span>
<span class="token number">1239</span>    <span class="token boolean">False</span>
<span class="token number">1153</span>     <span class="token boolean">True</span>
<span class="token number">1068</span>    <span class="token boolean">False</span>
<span class="token number">846</span>      <span class="token boolean">True</span>
<span class="token number">148</span>      <span class="token boolean">True</span>
<span class="token number">478</span>      <span class="token boolean">True</span>
<span class="token number">642</span>      <span class="token boolean">True</span>
<span class="token number">1298</span>     <span class="token boolean">True</span>
<span class="token number">540</span>      <span class="token boolean">True</span>
<span class="token number">28</span>       <span class="token boolean">True</span>
<span class="token number">130</span>      <span class="token boolean">True</span>
        <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>  
<span class="token number">194</span>      <span class="token boolean">True</span>
<span class="token number">663</span>      <span class="token boolean">True</span>
<span class="token number">1209</span>     <span class="token boolean">True</span>
<span class="token number">117</span>     <span class="token boolean">False</span>
<span class="token number">595</span>     <span class="token boolean">False</span>
<span class="token number">1151</span>    <span class="token boolean">False</span>
<span class="token number">1143</span>     <span class="token boolean">True</span>
<span class="token number">1216</span>     <span class="token boolean">True</span>
<span class="token number">874</span>      <span class="token boolean">True</span>
<span class="token number">246</span>      <span class="token boolean">True</span>
<span class="token number">160</span>      <span class="token boolean">True</span>
<span class="token number">1208</span>     <span class="token boolean">True</span>
<span class="token number">682</span>      <span class="token boolean">True</span>
<span class="token number">307</span>      <span class="token boolean">True</span>
<span class="token number">67</span>       <span class="token boolean">True</span>
<span class="token number">961</span>      <span class="token boolean">True</span>
<span class="token number">400</span>      <span class="token boolean">True</span>
<span class="token number">923</span>     <span class="token boolean">False</span>
<span class="token number">866</span>      <span class="token boolean">True</span>
<span class="token number">134</span>      <span class="token boolean">True</span>
<span class="token number">613</span>      <span class="token boolean">True</span>
<span class="token number">242</span>      <span class="token boolean">True</span>
<span class="token number">320</span>     <span class="token boolean">False</span>
<span class="token number">829</span>      <span class="token boolean">True</span>
<span class="token number">94</span>       <span class="token boolean">True</span>
<span class="token number">1146</span>     <span class="token boolean">True</span>
<span class="token number">1125</span>    <span class="token boolean">False</span>
<span class="token number">386</span>      <span class="token boolean">True</span>
<span class="token number">1025</span>    <span class="token boolean">False</span>
<span class="token number">337</span>      <span class="token boolean">True</span>
Name<span class="token punctuation">:</span> survived<span class="token punctuation">,</span> Length<span class="token punctuation">:</span> <span class="token number">329</span><span class="token punctuation">,</span> dtype<span class="token punctuation">:</span> bool
准确率为：
 <span class="token number">0.7872340425531915</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>e、总结：随机森林具有极好的准确率，能够运行在大数据集上，处理具有高维特征的输入样本，而且不需要降维，并且能评估各个特征在分类问题上的重要性</p>
<h4 id="八、以上总结："><a href="#八、以上总结：" class="headerlink" title="八、以上总结："></a><strong>八、以上总结：</strong></h4><p>​                                           1-1：转换器—在特征工程里用           实例化转换器类—&gt;fit_transform</p>
<p>1、转换器与估计器   —&gt;</p>
<p>​                                           1-2：估计器—在机器学习算法里用   实例化估计器类—&gt;fit—&gt;predict</p>
<p>​                                            2-1： 根据邻居确定类别</p>
<p>2、knn算法  —&gt;               2-2：判断谁是邻居 —距离公式</p>
<p>​                                           2-3： k的取值—&gt; k过小，容易受到异常值影响，k过大容易受到样本不均衡的影响</p>
<p>​                                           2-4： 应用场景—&gt;少量数据  </p>
<p>​                                           3-1：朴素—&gt;假定了特征与特征之间相互独立</p>
<p>3、朴素贝叶斯算法  —&gt;  3-2：贝叶斯—&gt;贝叶斯公式</p>
<p>​                                           3-3：拉普拉斯平滑系数</p>
<p>​                                           3-4：应用场景：文本分类</p>
<p>​                                      </p>
<p>​                                            4-1：找到最高效的决策顺序—比如信息增益</p>
<p>4、决策树  —&gt;                  4-2：信息增益=总的信息熵-条件熵</p>
<p>​                                            4-3：优：可以可视化   缺：过拟合</p>
<p>​                      </p>
<p>​                                                                            5-1-1：训练集随机</p>
<p>​                                             5-1：随机  —&gt;</p>
<p>​                                                                            5-1-2：特征随机</p>
<p>5、随机森林  —&gt;               5-2：森林  —&gt; 多个决策树组成</p>
<p>​                                             5-3：应用场景：适合用于高维度特征、大数据场景</p>
<p>​                                            </p>
<h4 id="九、回归与聚类："><a href="#九、回归与聚类：" class="headerlink" title="九、回归与聚类："></a><strong>九、回归与聚类：</strong></h4><p>1）线性回归：利用回归方程（函数）对一个或多个特征值和目标值之间关系进行建模的一种分析方式，只有一个自变量的称为单变量回归，多个自变量的称为多元回归</p>
<p>a、回归问题：目标值–&gt;连续的数据</p>
<p>b、线性模型：一是线性关系（直线），二是非线性关系（非直线）</p>
<p>自变量是一次方的、参数只有一种（x，无x1）都属于线性模型</p>
<p>c、线性关系与线性模型关系：线性关系一定是线性模型，但线性模型不一定是线性关系</p>
<p>d、线性回归的损失和优化</p>
<p>d-1：目标：求模型参数（即y=w1x1+w2x2中的w1、w2）</p>
<p>d-2：损失函数/cost/成本函数/目标函数：真实模型参数与预测模型参数之间的误差</p>
<p><img src="D:\Machine learning\image\损失函数.png" alt=""></p>
<p>d-3：优化损失的方法：</p>
<p>●正规方程：直接求解w</p>
<p><img src="D:\Machine learning\image\正规方程.png" alt=""></p>
<p>●梯度下降：不断试错、改进（数据量大时有优势）</p>
<p><img src="D:\Machine learning\image\梯度下降.png" alt=""></p>
<pre class="line-numbers language-python"><code class="language-python">对于：h（x）<span class="token operator">=</span>w0<span class="token operator">+</span>w1<span class="token operator">*</span>x
<span class="token number">1</span>、代价函数：J（w）对有样本m个的x，（预测的h（x）<span class="token operator">-</span>实际的y值）平方求和再除以2m<span class="token punctuation">,</span>假设h（x）<span class="token operator">=</span>w1<span class="token operator">*</span>x（保留两个参数w0和w1也可以，但是得出的图像是<span class="token number">3</span>维图，x、y、z的坐标）根据不同的w1的值画h（x）<span class="token operator">-</span>x图像，再通过公式画出J（w1）<span class="token operator">-</span>w1的图像，观察可得，如果我们想得到比较好的拟合线，我们要最小化J（w1） 
<span class="token number">2</span>、梯度下降法（Batch）来最小化函数：w1<span class="token operator">=</span>w1<span class="token operator">-</span>阿尔法<span class="token operator">*</span>J（w1）的求导（微积分），先把w0和w1初始化为<span class="token number">0</span>，再不断同步更新w0和w1找到最小的J（w），当我们接近局部最低时，梯度下降法会自动采用更小的幅度，因为局部最低点处的导数为<span class="token number">0</span>
<span class="token number">3</span>、代价函数<span class="token operator">+</span>梯度下降法<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">></span>线性回归算法<span class="token punctuation">:</span>线性回归函数只有全局最低，无局部最低
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p><strong>d-4：</strong></p>
<p><strong>正规方程API：sklearn.linear_model.LinearRegression(fit_intercept=True)</strong></p>
<p>●fit_intercept：是否计算偏置，一般都用True</p>
<p>●属性：LinearRegression.coef_：回归系数</p>
<p>●属性：LinearRegression.intercept_：偏置</p>
<p><strong>梯度下降API：sklearn.linear_model.SGDRegressor(loss=’squared_loss’,fit_intercept=True,learning_rate=’invscaling’,eta0=0.01)，它支持不同的loss函数和正则化惩罚项来拟合线性回归模型</strong></p>
<p>●loss：损失函数，squared_loss是普通最小二乘法，默认用它</p>
<p>●learning_rate：学习率算法，invscaling的意思是在距离局部最优远点时，下降梯度快，近的时候下降梯度慢</p>
<p>●属性：SGDRegressor.coef_：回归系数</p>
<p>●属性：SGDRegressor.intercept_：偏置</p>
<p>e、回归性能评估：均方误差小的性能好</p>
<p><img src="D:\Machine learning\image\均方误差.png" alt=""></p>
<p><strong>API：sklearn.metrics.mean_squared_error(y_true,y_pred)  y_true是真实值   y_pred是预测值，返回的结果是浮点小数</strong></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#正规方程</span>
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> load_boston
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> mean_squared_error
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> StandardScaler
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>linear_model <span class="token keyword">import</span> LinearRegression

<span class="token comment" spellcheck="true">#1、获取数据集</span>
boston<span class="token operator">=</span>load_boston<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#2、数据集划分</span>
x_train<span class="token punctuation">,</span>x_test<span class="token punctuation">,</span>y_train<span class="token punctuation">,</span>y_test<span class="token operator">=</span>train_test_split<span class="token punctuation">(</span>boston<span class="token punctuation">.</span>data<span class="token punctuation">,</span>boston<span class="token punctuation">.</span>target<span class="token punctuation">,</span>random_state<span class="token operator">=</span><span class="token number">22</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#3、特征工程--标准化</span>
transfer<span class="token operator">=</span>StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span>
x_train<span class="token operator">=</span>transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>x_train<span class="token punctuation">)</span>
x_test<span class="token operator">=</span>transfer<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#4、估计器</span>
estimator<span class="token operator">=</span>LinearRegression<span class="token punctuation">(</span><span class="token punctuation">)</span>
estimator<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span>y_train<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#5、得出模型</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'权重系数：\n'</span><span class="token punctuation">,</span>estimator<span class="token punctuation">.</span>coef_<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'偏置：\n'</span><span class="token punctuation">,</span>estimator<span class="token punctuation">.</span>intercept_<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#6、模型评估</span>
y_predict<span class="token operator">=</span>estimator<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"预测房价：\n"</span><span class="token punctuation">,</span>y_predict<span class="token punctuation">)</span>
error<span class="token operator">=</span>mean_squared_error<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span>y_predict<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'正规方程-均方误差：\n'</span><span class="token punctuation">,</span>error<span class="token punctuation">)</span>

结果如下：
权重系数：
 <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.63330277</span>  <span class="token number">1.14524456</span> <span class="token operator">-</span><span class="token number">0.05645213</span>  <span class="token number">0.74282329</span> <span class="token operator">-</span><span class="token number">1.95823403</span>  <span class="token number">2.70614818</span>
 <span class="token operator">-</span><span class="token number">0.07544614</span> <span class="token operator">-</span><span class="token number">3.29771933</span>  <span class="token number">2.49437742</span> <span class="token operator">-</span><span class="token number">1.85578218</span> <span class="token operator">-</span><span class="token number">1.7518438</span>   <span class="token number">0.8816005</span>
 <span class="token operator">-</span><span class="token number">3.92011059</span><span class="token punctuation">]</span>
偏置：
 <span class="token number">22.62137203166228</span>
预测房价：
 <span class="token punctuation">[</span><span class="token number">28.23494214</span> <span class="token number">31.51307591</span> <span class="token number">21.11158648</span> <span class="token number">32.66626323</span> <span class="token number">20.00183117</span> <span class="token number">19.06699551</span>
 <span class="token number">21.0961119</span>  <span class="token number">19.61374904</span> <span class="token number">19.61770489</span> <span class="token number">32.88592905</span> <span class="token number">20.9786404</span>  <span class="token number">27.52841267</span>
 <span class="token number">15.54828312</span> <span class="token number">19.78740662</span> <span class="token number">36.89507874</span> <span class="token number">18.81564352</span>  <span class="token number">9.34846191</span> <span class="token number">18.49591496</span>
 <span class="token number">30.67162831</span> <span class="token number">24.30515001</span> <span class="token number">19.06869647</span> <span class="token number">34.10872969</span> <span class="token number">29.82133504</span> <span class="token number">17.52652164</span>
 <span class="token number">34.90809099</span> <span class="token number">26.5518049</span>  <span class="token number">34.71029597</span> <span class="token number">27.42733357</span> <span class="token number">19.096319</span>   <span class="token number">14.92856162</span>
 <span class="token number">30.86006302</span> <span class="token number">15.8783044</span>  <span class="token number">37.1757242</span>   <span class="token number">7.80943257</span> <span class="token number">16.23745554</span> <span class="token number">17.17366271</span>
  <span class="token number">7.46619503</span> <span class="token number">20.00428873</span> <span class="token number">40.58796715</span> <span class="token number">28.93648294</span> <span class="token number">25.25640752</span> <span class="token number">17.73215197</span>
 <span class="token number">38.74782311</span>  <span class="token number">6.87753104</span> <span class="token number">21.79892653</span> <span class="token number">25.2879307</span>  <span class="token number">20.43140241</span> <span class="token number">20.47297067</span>
 <span class="token number">17.25472052</span> <span class="token number">26.14086662</span>  <span class="token number">8.47995047</span> <span class="token number">27.51138229</span> <span class="token number">30.58418801</span> <span class="token number">16.57906517</span>
  <span class="token number">9.35431527</span> <span class="token number">35.54126306</span> <span class="token number">32.29698317</span> <span class="token number">21.81396457</span> <span class="token number">17.60000884</span> <span class="token number">22.07940501</span>
 <span class="token number">23.49673392</span> <span class="token number">24.10792657</span> <span class="token number">20.13898247</span> <span class="token number">38.52731389</span> <span class="token number">24.58425972</span> <span class="token number">19.7678374</span>
 <span class="token number">13.90105731</span>  <span class="token number">6.77759905</span> <span class="token number">42.04821253</span> <span class="token number">21.92454718</span> <span class="token number">16.8868124</span>  <span class="token number">22.58439325</span>
 <span class="token number">40.75850574</span> <span class="token number">21.40493055</span> <span class="token number">36.89550591</span> <span class="token number">27.19933607</span> <span class="token number">20.98475235</span> <span class="token number">20.35089273</span>
 <span class="token number">25.35827725</span> <span class="token number">22.19234062</span> <span class="token number">31.13660054</span> <span class="token number">20.39576992</span> <span class="token number">23.99395511</span> <span class="token number">31.54664956</span>
 <span class="token number">26.74584297</span> <span class="token number">20.89907127</span> <span class="token number">29.08389387</span> <span class="token number">21.98344006</span> <span class="token number">26.29122253</span> <span class="token number">20.1757307</span>
 <span class="token number">25.49308523</span> <span class="token number">24.08473351</span> <span class="token number">19.89049624</span> <span class="token number">16.50220723</span> <span class="token number">15.21335458</span> <span class="token number">18.38992582</span>
 <span class="token number">24.83578855</span> <span class="token number">16.59840245</span> <span class="token number">20.88232963</span> <span class="token number">26.7138003</span>  <span class="token number">20.75135414</span> <span class="token number">17.87670216</span>
 <span class="token number">24.2990126</span>  <span class="token number">23.37979066</span> <span class="token number">21.6475525</span>  <span class="token number">36.8205059</span>  <span class="token number">15.86479489</span> <span class="token number">21.42514368</span>
 <span class="token number">32.81282808</span> <span class="token number">33.74331087</span> <span class="token number">20.62139404</span> <span class="token number">26.88700445</span> <span class="token number">22.65319133</span> <span class="token number">17.34888735</span>
 <span class="token number">21.67595777</span> <span class="token number">21.65498295</span> <span class="token number">27.66634446</span> <span class="token number">25.05030923</span> <span class="token number">23.74424639</span> <span class="token number">14.65940118</span>
 <span class="token number">15.19817822</span>  <span class="token number">3.8188746</span>  <span class="token number">29.18611337</span> <span class="token number">20.67170992</span> <span class="token number">22.3295488</span>  <span class="token number">28.01966146</span>
 <span class="token number">28.59358258</span><span class="token punctuation">]</span>
正规方程<span class="token operator">-</span>均方误差：
 <span class="token number">20.630254348291196</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#梯度下降</span>
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> load_boston
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> StandardScaler
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>linear_model <span class="token keyword">import</span> SGDRegressor
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> mean_squared_error

<span class="token comment" spellcheck="true">#1、获取数据集</span>
boston<span class="token operator">=</span>load_boston<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#2、数据集划分</span>
x_train<span class="token punctuation">,</span>x_test<span class="token punctuation">,</span>y_train<span class="token punctuation">,</span>y_test<span class="token operator">=</span>train_test_split<span class="token punctuation">(</span>boston<span class="token punctuation">.</span>data<span class="token punctuation">,</span>boston<span class="token punctuation">.</span>target<span class="token punctuation">,</span>random_state<span class="token operator">=</span><span class="token number">22</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#3、特征工程--标准化</span>
transfer<span class="token operator">=</span>StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span>
x_train<span class="token operator">=</span>transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>x_train<span class="token punctuation">)</span>
x_test<span class="token operator">=</span>transfer<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#4、估计器 learning_rate='constant' eta0=0.001,max_iter=10000可以修改这几个参数，得到比较好的解</span>
estimator<span class="token operator">=</span>SGDRegressor<span class="token punctuation">(</span><span class="token punctuation">)</span>
estimator<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span>y_train<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#5、得出模型</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'权重系数：\n'</span><span class="token punctuation">,</span>estimator<span class="token punctuation">.</span>coef_<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'偏置：\n'</span><span class="token punctuation">,</span>estimator<span class="token punctuation">.</span>intercept_<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#6、模型评估</span>
y_predict<span class="token operator">=</span>estimator<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"预测房价：\n"</span><span class="token punctuation">,</span>y_predict<span class="token punctuation">)</span>
error<span class="token operator">=</span>mean_squared_error<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span>y_predict<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'梯度下降-均方误差：\n'</span><span class="token punctuation">,</span>error<span class="token punctuation">)</span>

结果如下：
权重系数：
 <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.31756363</span>  <span class="token number">0.54850906</span> <span class="token operator">-</span><span class="token number">0.57119471</span>  <span class="token number">0.83892057</span> <span class="token operator">-</span><span class="token number">0.8309124</span>   <span class="token number">3.28185309</span>
 <span class="token operator">-</span><span class="token number">0.43918997</span> <span class="token operator">-</span><span class="token number">2.09211417</span>  <span class="token number">0.74860025</span> <span class="token operator">-</span><span class="token number">0.39513382</span> <span class="token operator">-</span><span class="token number">1.55875279</span>  <span class="token number">0.9502491</span>
 <span class="token operator">-</span><span class="token number">3.40917222</span><span class="token punctuation">]</span>
偏置：
 <span class="token punctuation">[</span><span class="token number">22.13393755</span><span class="token punctuation">]</span>
预测房价：
 <span class="token punctuation">[</span><span class="token number">27.81674971</span> <span class="token number">30.57035333</span> <span class="token number">21.04432663</span> <span class="token number">31.73604573</span> <span class="token number">20.51848793</span> <span class="token number">18.64287769</span>
 <span class="token number">20.70154043</span> <span class="token number">19.48349491</span> <span class="token number">19.91416364</span> <span class="token number">31.70373289</span> <span class="token number">20.65870527</span> <span class="token number">25.91894274</span>
 <span class="token number">15.22755101</span> <span class="token number">19.86167563</span> <span class="token number">36.4655692</span>  <span class="token number">17.46874465</span> <span class="token number">10.50065295</span> <span class="token number">18.56940931</span>
 <span class="token number">30.71479595</span> <span class="token number">24.05585072</span> <span class="token number">18.58016766</span> <span class="token number">33.14257201</span> <span class="token number">28.57625652</span> <span class="token number">16.59746557</span>
 <span class="token number">33.94523588</span> <span class="token number">25.0092459</span>  <span class="token number">32.87830632</span> <span class="token number">27.09453911</span> <span class="token number">18.55999689</span> <span class="token number">17.13946118</span>
 <span class="token number">29.97585226</span> <span class="token number">13.44856141</span> <span class="token number">36.73973631</span>  <span class="token number">9.87943571</span> <span class="token number">16.59376551</span> <span class="token number">15.5601214</span>
  <span class="token number">7.92476475</span> <span class="token number">18.8735827</span>  <span class="token number">39.72807461</span> <span class="token number">29.48371495</span> <span class="token number">24.94168103</span> <span class="token number">17.63498743</span>
 <span class="token number">39.40345757</span>  <span class="token number">5.93332229</span> <span class="token number">20.32296792</span> <span class="token number">23.91875497</span> <span class="token number">20.99324348</span> <span class="token number">20.59423877</span>
 <span class="token number">16.29824265</span> <span class="token number">25.81149972</span> <span class="token number">10.0960961</span>  <span class="token number">26.22840519</span> <span class="token number">29.95908163</span> <span class="token number">16.38473509</span>
  <span class="token number">9.68293138</span> <span class="token number">34.26772836</span> <span class="token number">29.4848277</span>  <span class="token number">23.55867715</span> <span class="token number">17.47678994</span> <span class="token number">21.99889493</span>
 <span class="token number">22.96383334</span> <span class="token number">22.84132842</span> <span class="token number">20.47639028</span> <span class="token number">37.1117672</span>  <span class="token number">26.13196429</span> <span class="token number">18.8908303</span>
 <span class="token number">14.34671115</span>  <span class="token number">5.97361679</span> <span class="token number">42.24926657</span> <span class="token number">21.50423794</span> <span class="token number">15.29365286</span> <span class="token number">23.14324306</span>
 <span class="token number">40.36757935</span> <span class="token number">21.75163229</span> <span class="token number">35.92320464</span> <span class="token number">26.13022109</span> <span class="token number">23.07044859</span> <span class="token number">20.11345121</span>
 <span class="token number">25.23947952</span> <span class="token number">25.24992563</span> <span class="token number">31.01903711</span> <span class="token number">19.86643211</span> <span class="token number">23.63614629</span> <span class="token number">30.80683536</span>
 <span class="token number">26.72128163</span> <span class="token number">20.30471524</span> <span class="token number">27.71997706</span> <span class="token number">22.58760425</span> <span class="token number">26.30705614</span> <span class="token number">17.55318269</span>
 <span class="token number">23.68735383</span> <span class="token number">23.00169065</span> <span class="token number">19.62210262</span> <span class="token number">19.54423616</span> <span class="token number">15.57291589</span> <span class="token number">17.53078406</span>
 <span class="token number">23.50042547</span> <span class="token number">16.29612106</span> <span class="token number">19.62227464</span> <span class="token number">26.35594696</span> <span class="token number">20.01392395</span> <span class="token number">17.82658594</span>
 <span class="token number">23.13612831</span> <span class="token number">22.29090142</span> <span class="token number">19.07733299</span> <span class="token number">34.96926114</span> <span class="token number">16.18468441</span> <span class="token number">22.71953217</span>
 <span class="token number">31.76540925</span> <span class="token number">31.80949037</span> <span class="token number">20.03210208</span> <span class="token number">24.19540771</span> <span class="token number">24.13381314</span> <span class="token number">17.6552268</span>
 <span class="token number">21.24350196</span> <span class="token number">21.79322833</span> <span class="token number">27.18863546</span> <span class="token number">25.27988341</span> <span class="token number">22.80403154</span> <span class="token number">13.3561175</span>
 <span class="token number">15.63275295</span>  <span class="token number">2.81219281</span> <span class="token number">28.0786303</span>  <span class="token number">20.17682374</span> <span class="token number">21.77779314</span> <span class="token number">27.47447247</span>
 <span class="token number">26.83721489</span><span class="token punctuation">]</span>
梯度下降<span class="token operator">-</span>均方误差：
 <span class="token number">21.347339602420547</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>f、两种方法对比：</p>
<p><img src="D:\Machine learning\image\文字对比.png" alt=""></p>
<p>h、梯度下降的优化方法：GD、SGD、SAG</p>
<p>GD：计算所有样本的值才能够得出梯度，计算量大，所以后面才会有一系列的改进</p>
<p>SGD：随机梯度下降，只考虑一个训练样本，优点是高效、容易实现，缺点是需要许多超参数，如正则项参数、迭代数，对于特征标准化是敏感的</p>
<p>SAG：随机平均梯度法</p>
<p>2）欠拟合和过拟合：</p>
<p>欠拟合：在训练的时候预测的不好，在测试的时候预测的也不好，解决办法：增加数据的特征数量</p>
<p>过拟合：在训练的时候预测的好，在测试的时候预测的不好，解决办法：正则化</p>
<p><img src="D:\Machine learning\image\正则化.png" alt=""></p>
<p>正则化：有两种L1和L2（更常用）</p>
<p>L1（LASSO）：损失函数+入（惩罚系数）惩罚项（绝对值）</p>
<p>L2（Ridge 岭回归）：损失函数+入（惩罚系数）*惩罚项（平方） </p>
<p><img src="D:\Machine learning\image\正则化1.png" alt=""></p>
<p>3）岭回归：带有L2正则化的线性回归</p>
<p><strong>API：sklearn.liner_model.Ridge(alpha=1.0,fit_intercept=True,solver=’auto’,normalize=False)</strong></p>
<p>●alpha：正则化力度，也叫入（惩罚项系数），入取值0~1  1~10，默认是1</p>
<p>●solver：会根据数据自动选择优化方法，如果数据集、特征都比较大，选择随机梯度下降优化 –’sag‘</p>
<p>●normalize：数据是否进行标准化，默认为False，normalize=False可以在fit之前调用preprocessing.StandardScaler标准化数据，为True，就不用做标准化了</p>
<p>●属性：Ridge.coef_：回归权重</p>
<p>●属性：Ridge.intercept_：回归偏置</p>
<p><strong>sklearn.liner_model.RidgeCV(BaseRidgeCV,RegressorMixin)  可以进行交叉验证的岭回归 coef_：回归系数</strong></p>
<p><img src="D:\Machine learning\image\正则化2.png" alt=""></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#岭回归</span>
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> load_boston
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> StandardScaler
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>linear_model <span class="token keyword">import</span> SGDRegressor<span class="token punctuation">,</span>Ridge
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> mean_squared_error

<span class="token comment" spellcheck="true">#1、获取数据集</span>
boston<span class="token operator">=</span>load_boston<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#2、数据集划分</span>
x_train<span class="token punctuation">,</span>x_test<span class="token punctuation">,</span>y_train<span class="token punctuation">,</span>y_test<span class="token operator">=</span>train_test_split<span class="token punctuation">(</span>boston<span class="token punctuation">.</span>data<span class="token punctuation">,</span>boston<span class="token punctuation">.</span>target<span class="token punctuation">,</span>random_state<span class="token operator">=</span><span class="token number">22</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#3、特征工程--标准化</span>
transfer<span class="token operator">=</span>StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span>
x_train<span class="token operator">=</span>transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>x_train<span class="token punctuation">)</span>
x_test<span class="token operator">=</span>transfer<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#4、估计器</span>
estimator<span class="token operator">=</span>Ridge<span class="token punctuation">(</span>alpha<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span>max_iter<span class="token operator">=</span><span class="token number">10000</span><span class="token punctuation">)</span>
estimator<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span>y_train<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#5、得出模型</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'权重系数：\n'</span><span class="token punctuation">,</span>estimator<span class="token punctuation">.</span>coef_<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'偏置：\n'</span><span class="token punctuation">,</span>estimator<span class="token punctuation">.</span>intercept_<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#6、模型评估</span>
y_predict<span class="token operator">=</span>estimator<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"预测房价：\n"</span><span class="token punctuation">,</span>y_predict<span class="token punctuation">)</span>
error<span class="token operator">=</span>mean_squared_error<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span>y_predict<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'梯度下降-均方误差：\n'</span><span class="token punctuation">,</span>error<span class="token punctuation">)</span>

结果如下：
权重系数：
 <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.62710135</span>  <span class="token number">1.13221555</span> <span class="token operator">-</span><span class="token number">0.07373898</span>  <span class="token number">0.74492864</span> <span class="token operator">-</span><span class="token number">1.93983515</span>  <span class="token number">2.71141843</span>
 <span class="token operator">-</span><span class="token number">0.07982198</span> <span class="token operator">-</span><span class="token number">3.27753496</span>  <span class="token number">2.44876703</span> <span class="token operator">-</span><span class="token number">1.81107644</span> <span class="token operator">-</span><span class="token number">1.74796456</span>  <span class="token number">0.88083243</span>
 <span class="token operator">-</span><span class="token number">3.91211699</span><span class="token punctuation">]</span>
偏置：
 <span class="token number">22.62137203166228</span>
预测房价：
 <span class="token punctuation">[</span><span class="token number">28.23082349</span> <span class="token number">31.50636545</span> <span class="token number">21.12739377</span> <span class="token number">32.65793823</span> <span class="token number">20.02076945</span> <span class="token number">19.06632771</span>
 <span class="token number">21.106687</span>   <span class="token number">19.61624365</span> <span class="token number">19.63161548</span> <span class="token number">32.86596512</span> <span class="token number">20.9946695</span>  <span class="token number">27.50329913</span>
 <span class="token number">15.55414648</span> <span class="token number">19.79639417</span> <span class="token number">36.88392371</span> <span class="token number">18.80672342</span>  <span class="token number">9.38096</span>    <span class="token number">18.50907253</span>
 <span class="token number">30.67484295</span> <span class="token number">24.30753141</span> <span class="token number">19.0666843</span>  <span class="token number">34.09564382</span> <span class="token number">29.80095002</span> <span class="token number">17.51949727</span>
 <span class="token number">34.8916544</span>  <span class="token number">26.5394645</span>  <span class="token number">34.68264723</span> <span class="token number">27.42856108</span> <span class="token number">19.09405963</span> <span class="token number">14.98997618</span>
 <span class="token number">30.8505874</span>  <span class="token number">15.81996969</span> <span class="token number">37.18247113</span>  <span class="token number">7.85916465</span> <span class="token number">16.25653448</span> <span class="token number">17.15490009</span>
  <span class="token number">7.48867279</span> <span class="token number">19.99147768</span> <span class="token number">40.57329959</span> <span class="token number">28.95128807</span> <span class="token number">25.25723034</span> <span class="token number">17.73738109</span>
 <span class="token number">38.75700749</span>  <span class="token number">6.87711291</span> <span class="token number">21.78043375</span> <span class="token number">25.27159224</span> <span class="token number">20.45456114</span> <span class="token number">20.48220948</span>
 <span class="token number">17.25258857</span> <span class="token number">26.1375367</span>   <span class="token number">8.5448374</span>  <span class="token number">27.49204889</span> <span class="token number">30.58183066</span> <span class="token number">16.58438621</span>
  <span class="token number">9.37182303</span> <span class="token number">35.52269097</span> <span class="token number">32.24958654</span> <span class="token number">21.87431027</span> <span class="token number">17.60876103</span> <span class="token number">22.08124517</span>
 <span class="token number">23.50114904</span> <span class="token number">24.09591554</span> <span class="token number">20.15605099</span> <span class="token number">38.49857046</span> <span class="token number">24.64026646</span> <span class="token number">19.75933465</span>
 <span class="token number">13.91713858</span>  <span class="token number">6.78030217</span> <span class="token number">42.04984214</span> <span class="token number">21.92558236</span> <span class="token number">16.8702938</span>  <span class="token number">22.59592875</span>
 <span class="token number">40.74980559</span> <span class="token number">21.4284924</span>  <span class="token number">36.88064128</span> <span class="token number">27.18855416</span> <span class="token number">21.04326386</span> <span class="token number">20.36536628</span>
 <span class="token number">25.36109432</span> <span class="token number">22.27869444</span> <span class="token number">31.14592486</span> <span class="token number">20.39487869</span> <span class="token number">23.99757481</span> <span class="token number">31.54428168</span>
 <span class="token number">26.76210157</span> <span class="token number">20.89486664</span> <span class="token number">29.07215993</span> <span class="token number">21.99603204</span> <span class="token number">26.30599891</span> <span class="token number">20.11183257</span>
 <span class="token number">25.47912071</span> <span class="token number">24.0792631</span>  <span class="token number">19.89111149</span> <span class="token number">16.56247916</span> <span class="token number">15.22770226</span> <span class="token number">18.38342191</span>
 <span class="token number">24.82070397</span> <span class="token number">16.60156656</span> <span class="token number">20.86675004</span> <span class="token number">26.71162923</span> <span class="token number">20.74443479</span> <span class="token number">17.8825254</span>
 <span class="token number">24.28515984</span> <span class="token number">23.37007961</span> <span class="token number">21.58413976</span> <span class="token number">36.79386382</span> <span class="token number">15.88357121</span> <span class="token number">21.47915185</span>
 <span class="token number">32.79931234</span> <span class="token number">33.71603437</span> <span class="token number">20.62134398</span> <span class="token number">26.83678658</span> <span class="token number">22.68850452</span> <span class="token number">17.37312422</span>
 <span class="token number">21.67296898</span> <span class="token number">21.67559608</span> <span class="token number">27.66601539</span> <span class="token number">25.0712154</span>  <span class="token number">23.73692967</span> <span class="token number">14.64799906</span>
 <span class="token number">15.21577315</span>  <span class="token number">3.82030283</span> <span class="token number">29.17847194</span> <span class="token number">20.66853036</span> <span class="token number">22.33184243</span> <span class="token number">28.0180608</span>
 <span class="token number">28.56771983</span><span class="token punctuation">]</span>
梯度下降<span class="token operator">-</span>均方误差：
 <span class="token number">20.644810227653515</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>4）分类算法–逻辑回归与二分类：</p>
<p>a、逻辑回归应用场景：目标值只有正反两个的问题，如是否…..</p>
<p>b、逻辑回归原理：线性回归的输出就是逻辑回归的输入，将输入带入到sigmoid函数 1/（1+e^(-x)）  的x里 </p>
<p><img src="D:\Machine learning\image\逻辑回归.png" alt=""></p>
<p><img src="D:\Machine learning\image\逻辑回归图像.png" alt=""></p>
<p>c、逻辑回归的损失：</p>
<p><img src="D:\Machine learning\image\逻辑回归损失.png" alt=""></p>
<p><img src="D:\Machine learning\image\逻辑回归损失图像.png" alt=""></p>
<p><img src="D:\Machine learning\image\逻辑回归图像2.png" alt=""></p>
<p><img src="D:\Machine learning\image\逻辑回归图像3.png" alt=""></p>
<p>d、逻辑回归损失优化：</p>
<p><img src="D:\Machine learning\image\逻辑回归损失优化.png" alt=""></p>
<p><strong>e、API：sklearn.linear_model.LogisticRegression(solver=’liblinear’,penalty=’l2’,C=1.0)</strong></p>
<p>●solver：优化求解方式，按默认的liblinear就可以</p>
<p>●penalty：正则化的种类</p>
<p>●C：正则化力度</p>
<p>默认将类别数量少的当作正例</p>
<p><img src="D:\Machine learning\image\SAG.png" alt=""></p>
<p>f、分类的评估方法：</p>
<p>f-1：精确率与召回率：</p>
<p>混淆矩阵：</p>
<p><img src="D:\Machine learning\image\混淆矩阵.png" alt=""></p>
<p>精确率：TP/（TP+FP）</p>
<p><img src="D:\Machine learning\image\精确率.png" alt=""></p>
<p>召回率：TP/（TP+FN），查的全不全，应用场景有癌症检测、工厂质量检测找次品</p>
<p><img src="D:\Machine learning\image\召回率.png" alt=""></p>
<p>F1-score：</p>
<p><img src="D:\Machine learning\image\F1-score.png" alt=""></p>
<p><strong>f-2：API：sklearn.metrics.classification_report(y_true,y_pred,labels=[],target_name=None) 返回的结果是每个类别的精确率与召回率、还有一个样本量（support）</strong></p>
<p>●y_true：真实目标值</p>
<p>●y_pred：估计器预测值</p>
<p>●labels：标签值（数字）</p>
<p>●target_name：标签值所代表的意思</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#案列：癌症分类预测-良/恶性乳腺癌肿瘤预测，其中，恶性为正例</span>
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> StandardScaler
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>linear_model <span class="token keyword">import</span> LogisticRegression

<span class="token comment" spellcheck="true">#1、获取数据，读取的时候加上names</span>
path<span class="token operator">=</span><span class="token string">'http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data'</span>
<span class="token comment" spellcheck="true">#加列索引</span>
column_name<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'Sample code number'</span><span class="token punctuation">,</span><span class="token string">'Clump Thickness'</span><span class="token punctuation">,</span><span class="token string">'Uniformity of Cell Size'</span><span class="token punctuation">,</span><span class="token string">'Uniformity of Cell Shape'</span><span class="token punctuation">,</span><span class="token string">'Marginal Adhesion'</span><span class="token punctuation">,</span><span class="token string">'Single Epithelial Cell Size'</span><span class="token punctuation">,</span><span class="token string">'Bare Nuclei'</span><span class="token punctuation">,</span><span class="token string">'Bland Chromatin'</span><span class="token punctuation">,</span><span class="token string">'Normal Nucleoli'</span><span class="token punctuation">,</span><span class="token string">'Mitoses'</span><span class="token punctuation">,</span><span class="token string">'Class'</span><span class="token punctuation">]</span>
data<span class="token operator">=</span>pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>path<span class="token punctuation">,</span>names<span class="token operator">=</span>column_name<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># print(data)</span>
<span class="token comment" spellcheck="true">#2、数据处理，处理缺失值</span>
<span class="token comment" spellcheck="true">#替换->np.nan</span>
data<span class="token punctuation">.</span>replace<span class="token punctuation">(</span>to_replace<span class="token operator">=</span><span class="token string">'?'</span><span class="token punctuation">,</span>value<span class="token operator">=</span>np<span class="token punctuation">.</span>nan<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#删除缺失样本,按行删除</span>
data<span class="token punctuation">.</span>dropna<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#检验是否还存在缺失值,False则为不存在缺失值</span>
<span class="token comment" spellcheck="true">#print(data.isnull().any())</span>
<span class="token comment" spellcheck="true">#3、数据集划分</span>
<span class="token comment" spellcheck="true">#筛选特征值和目标值</span>
x<span class="token operator">=</span>data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
y<span class="token operator">=</span>data<span class="token punctuation">[</span><span class="token string">'Class'</span><span class="token punctuation">]</span>
x_train<span class="token punctuation">,</span>x_test<span class="token punctuation">,</span>y_train<span class="token punctuation">,</span>y_test<span class="token operator">=</span>train_test_split<span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#4、特征工程：标准化</span>
transfer<span class="token operator">=</span>StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span>
x_train<span class="token operator">=</span>transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>x_train<span class="token punctuation">)</span>
x_test<span class="token operator">=</span>transfer<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#print(x_train)</span>
<span class="token comment" spellcheck="true">#5、逻辑回归估计器</span>
estimator<span class="token operator">=</span>LogisticRegression<span class="token punctuation">(</span><span class="token punctuation">)</span>
estimator<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span>y_train<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#逻辑回归的模型参数：回归系数和偏置</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'回归系数：\n'</span><span class="token punctuation">,</span>estimator<span class="token punctuation">.</span>coef_<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'偏置：\n'</span><span class="token punctuation">,</span>estimator<span class="token punctuation">.</span>intercept_<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#6、模型评估  真的患癌症的、能够被检查出来的概率---召回率</span>
<span class="token comment" spellcheck="true">#方法一：直接比对真实值和预测值</span>
y_predict<span class="token operator">=</span>estimator<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"y_predict:\n"</span><span class="token punctuation">,</span>y_predict<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"直接比对真实值和预测值:\n"</span><span class="token punctuation">,</span>y_test<span class="token operator">==</span>y_predict<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#方法二：计算准确率</span>
score<span class="token operator">=</span>estimator<span class="token punctuation">.</span>score<span class="token punctuation">(</span>x_test<span class="token punctuation">,</span>y_test<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'准确率为：\n'</span><span class="token punctuation">,</span>score<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#查看精确率、召回率、F1-score</span>
report<span class="token operator">=</span>classification_report<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span>y_predict<span class="token punctuation">,</span>labels<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span>target_names<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'良性'</span><span class="token punctuation">,</span><span class="token string">'恶性'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>report<span class="token punctuation">)</span>

report结果如下：
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><img src="D:\Machine learning\image\report.png" alt=""></p>
<p>假设共有100个人，99个人患有癌症，1个人没患，默认患癌症的为正例，准确率为99%，召回率为99/99=100%</p>
<p>精确率为99/100=99%，F1-score为2*99%/（100%+99%）=99.497%，那么预测新的样本是会预测成错的，这就是样本不均衡导致的，解决办法是ROC曲线和AUC指标</p>
<p>g、ROC曲线和AUC指标：解决样本不均衡问题</p>
<p>g-1：TPR和FPR： </p>
<p>TPR=TP/（TP+FN） 所有真实类别为1的样本中，预测类别为1的比例 —–即召回率</p>
<p>FPR=FP/（FP+TN） 所有真实类别为0的样本中，预测类别为1的比列 </p>
<p>g-2：ROC：</p>
<p><img src="D:\Machine learning\image\ROC.png" alt=""></p>
<p>g-3：AUC：ROC曲线与x、y轴包成的面积</p>
<p><img src="D:\Machine learning\image\AUC.png" alt=""></p>
<p>若AUC&lt;0.5，则可用1-AUC得到准确结果</p>
<p><strong>g-4：API：sklearn.metrics.roc_auc_score(y_true,y_score) 计算ROC曲线面积，即AUC值</strong></p>
<p>●y_true：每个样本的真实类别，必须为0为反例，1为正例标记</p>
<p>●y_score：预测得分，可以是正类的估计概率、置信值或者分类器方法的返回值</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#ROC与AUC</span>
<span class="token comment" spellcheck="true">#将y_test值转换成0 1,y_test大于3的转为1，小于3的转为0</span>
y_true<span class="token operator">=</span>np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>y_test<span class="token operator">></span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span>
auc<span class="token operator">=</span>roc_auc_score<span class="token punctuation">(</span>y_true<span class="token punctuation">,</span>y_predict<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'AUC:\n'</span><span class="token punctuation">,</span>auc<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>g-5：总计：AUC只能用来评价二分类，非常适合评价样本不均衡中的分类器性能</p>
<p>5）模型保存与加载：解决了每次预测时重新训练数据的问题</p>
<p><strong>API：from sklearn.externals import joblib</strong></p>
<p>●保存：joblib.dump(rf,’test.pkl’)  rf是估计器  第二个是路径，后缀是pkl</p>
<p>●加载：estimator=joblib.load(‘test.pkl’)</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#岭回归</span>
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> load_boston
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> StandardScaler
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>linear_model <span class="token keyword">import</span> Ridge
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> mean_squared_error
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>externals <span class="token keyword">import</span> joblib


<span class="token comment" spellcheck="true">#1、获取数据集</span>
boston<span class="token operator">=</span>load_boston<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#2、数据集划分</span>
x_train<span class="token punctuation">,</span>x_test<span class="token punctuation">,</span>y_train<span class="token punctuation">,</span>y_test<span class="token operator">=</span>train_test_split<span class="token punctuation">(</span>boston<span class="token punctuation">.</span>data<span class="token punctuation">,</span>boston<span class="token punctuation">.</span>target<span class="token punctuation">,</span>random_state<span class="token operator">=</span><span class="token number">22</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#3、特征工程--标准化</span>
transfer<span class="token operator">=</span>StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span>
x_train<span class="token operator">=</span>transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>x_train<span class="token punctuation">)</span>
x_test<span class="token operator">=</span>transfer<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#4、估计器</span>
estimator<span class="token operator">=</span>Ridge<span class="token punctuation">(</span>alpha<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span>max_iter<span class="token operator">=</span><span class="token number">10000</span><span class="token punctuation">)</span>
estimator<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span>y_train<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#5、保存模型</span>
joblib<span class="token punctuation">.</span>dump<span class="token punctuation">(</span>estimator<span class="token punctuation">,</span><span class="token string">'my_ridge.pkl'</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#加载模型  保存完之后可以把估计器和保存模型部分注释掉</span>
estimator<span class="token operator">=</span>joblib<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'my_ridge.pkl'</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#6、得出模型</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'权重系数：\n'</span><span class="token punctuation">,</span>estimator<span class="token punctuation">.</span>coef_<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'偏置：\n'</span><span class="token punctuation">,</span>estimator<span class="token punctuation">.</span>intercept_<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#7、模型评估</span>
y_predict<span class="token operator">=</span>estimator<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"预测房价：\n"</span><span class="token punctuation">,</span>y_predict<span class="token punctuation">)</span>
error<span class="token operator">=</span>mean_squared_error<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span>y_predict<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'梯度下降-均方误差：\n'</span><span class="token punctuation">,</span>error<span class="token punctuation">)</span>

<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>6）无监督学习–K-means算法：</p>
<p>a、无监督学习：没有目标值（标签）</p>

					
				</div>
			</div>
		</article>

		<ul class="am-pagination">
    
    	<li class="am-pagination-prev">
   		<a class="pull-left" href="/2019/03/01/深度学习入门笔记/" title="">
      		&laquo; 上一篇
		</a>
		</li>
	
	
		<li class="am-pagination-next">
		<a class="pull-right" href="/2019/03/01/机器学习笔记2/" title="">
			下一篇 &raquo;
		</a>
		</li>
	 
 </ul>
        

		<div class="theme-annie-comment-button-container">
	<button id="annie-comment-button" class="theme-annie-comment-button" onclick="Annie_Comment()">
		加载评论
		<!--加载评论-->
	</button>
</div>

<div id="annie-comment-container" class="theme-annie-comment-main-container">

	
		
			<!-- comment gitalk -->
			<!-- show gitalk comment -->

  <div id="gitalk-container"></div>


<!-- gitalk`s css & js -->
<link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
<link rel="stylesheet" href="/css/comment.css">
<script src="https://cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.min.js"></script>
<script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>

<script type="text/javascript">
	//thanks O-R
	//https://github.com/gitalk/gitalk/issues/102#issuecomment-382970552
	//去除尾部匹配正则数组的字符串  
	//remove redundant characters
	String.prototype.trimEnd = function(regStr) {
		var result = this;
		if(regStr == undefined || regStr == null || regStr == "") {
			return result;
		}
		var array = regStr.split(',');

		if(array.length > 0) {

			var c = array.shift();
			var str = this;
			var i = str.length;
			var rg = new RegExp(c);
			var matchArr = str.match(rg);

			if(matchArr != undefined && matchArr != null && matchArr.length > 0) {
				var matchStr = matchArr[0].replace(/\\/g, "\\\\").replace(/\*/g, "\\*")
					.replace(/\+/g, "\\+").replace(/\|/g, "\\|")
					.replace(/\{/g, "\\{").replace(/\}/g, "\\}")
					.replace(/\(/g, "\\(").replace(/\)/g, "\\)")
					.replace(/\^/g, "\\^").replace(/\$/g, "\\$")
					.replace(/\[/g, "\\[").replace(/\]/g, "\\]")
					.replace(/\?/g, "\\?").replace(/\,/g, "\\,")
					.replace(/\./g, "\\.").replace(/\&/g, "\\&");
				matchStr = matchStr + '$';
				result = str.replace(new RegExp(matchStr), "");
			}

			if(array.length > 0) {
				return result.trimEnd(array.join())
			} else {
				return result;
			}
		}
	};

	//create gitalk
	var gitalk = new Gitalk({
		clientID: 'b718a3924c38e43a46fd',
		clientSecret: 'a90fe88f7fdac55dfa97a7acfff4e73d3ccd7115',
		//id: window.location.pathname,
		// id: (window.location.pathname).split("/").pop().substring(0, 49),
		id: md5(location.href.trimEnd('#.*$,\\?.*$,index.html$')),
		repo: 'gitalk',
		owner: 'zhang666xin',
		admin: 'zhang666xin',
		distractionFreeMode: 'true',
	})
	gitalk.render('gitalk-container');
</script>
		
	

</div>

<script type="text/javascript">
	/* Show Comment */
	var Annie_Comment = function() {
		function Show_Hidden(obj) {
			obj.style.display = 'block';
		}
		
		//var obutton = $('#annie-comment-button');
		//var obutton = $('#annie-comment-container');
		var obutton = document.getElementById("annie-comment-button" || "0");
		var odiv = document.getElementById("annie-comment-container");
		if( 'obutton' ) {
			obutton.onclick = function() {
				Show_Hidden(odiv);
				$("#annie-comment-button").css("display", 'none');
				return false;
			}
		}
	};

	(function Annie_Init() {
		Annie_Comment();
	})();
</script>
		
		<!--
	时间：2018-09-24
	描述：The TOC module refers to 'https://github.com/codefine/hexo-theme-mellow', include toc.ejs、toc.js、toc.css. All rights reserved by codefine. 
-->

	
		<aside class="post-widget">
			<nav class="post-toc-wrap" id="post-toc">
				
					<strong>文章目录</strong>
				
				
				<!--toc(post.content)-->
				<ol class="post-toc"><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#机器学习入门："><span class="post-toc-text">机器学习入门：</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#1、机器学习算法分类："><span class="post-toc-text">1、机器学习算法分类：</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#2、数据集："><span class="post-toc-text">2、数据集：</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#3、机器学习开发流程："><span class="post-toc-text">3、机器学习开发流程：</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#4、如何学机器学习："><span class="post-toc-text">4、如何学机器学习：</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#5、机器学习框架："><span class="post-toc-text">5、机器学习框架：</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#6、特征工程："><span class="post-toc-text">6、特征工程：</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#7、以上内容总结："><span class="post-toc-text">7、以上内容总结：</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#7、分类算法："><span class="post-toc-text">7、分类算法：</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#八、以上总结："><span class="post-toc-text">八、以上总结：</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#九、回归与聚类："><span class="post-toc-text">九、回归与聚类：</span></a></li></ol></li></ol></li></ol></li></ol>
			</nav>
			<div class="post-toc-bar"><div>
		</aside>
	

	</div>
</div>
		</div>
		</main>
		
		<!--footer-->
		<footer>
	<div class="blog-text-center">
		<div class="theme-annie-social">
				
				
					<a href="http://github.com/" title="Github" target="_blank"><i class="fa fa-github"></i>&nbsp;</a>
					
				
					<a href="http://github.com/" title="Weibo" target="_blank"><i class="fa fa-weibo"></i>&nbsp;</a>
				
				
					<a href="http://github.com/" title="Email" target="_blank"><i class="fa fa-envelope-o"></i>&nbsp;</a>
					
				
					<a href="http://github.com/" title="QQ" target="_blank"><i class="fa fa-qq"></i>&nbsp;</a>
					
				
					<a href="http://github.com/" title="Twitter" target="_blank"><i class="fa fa-twitter"></i>&nbsp;</a>
						
				
		</div>
	</div>

	<div  class="blog-text-center">
		<div class="theme-annie-copyright">
			
				&copy; 2017 - 2019, content by Mr.zx. All Rights Reserved.			       	
			
		</div>
	</div>

	<div class="blog-text-center">
		<div class="theme-annie-copyright">
			<a href="http://hexo.io/" title="Hexo" target="_blank" rel="noopener">Hexo</a> Theme <a href="https://github.com/Sariay/hexo-theme-Annie" title="Annie" target="_blank" rel="noopener">Annie</a> by Sariay.		
		</div>
	</div>
</footer>
		<!-- <script src="http://code.jquery.com/jquery-2.1.1.min.js" type="text/javascript"></script> -->

<script>
	window.jQuery || document.write('<script src="/js/jquery-2.1.1.min.js"><\/script>')
</script>

<style>
	.motto {
		color: #000000;
		font-size: 20px;
		margin: 100px 25% 0;
		width: 50%;
		line-height: 1.4;
		font-family:"KaiTi", "STXingkai", "Source Sans Pro", "Segoe UI", "Lucida Grande", Helvetica, Arial, "Microsoft YaHei", FreeSans, Arimo, "Droid Sans", "wenquanyi micro hei", "Hiragino Sans GB", "Hiragino Sans GB W3", FontAwesome, sans-serif;
		text-align: center;
	}
	@media(max-width: 890px) {
		.motto {	
			margin: 100px 10% 0;
			width: 80%;
		}
	}
	@media(max-width: 890px) {
		.motto {
			margin: 100px 5% 0;
			width: 90%;
		}
	}
</style>


	<script src="/js/motto.js"></script>
	<script type="text/javascript">
		$(".motto").html(getMingYanContent());
	</script>	



	<div class="popup search-popup local-search-popup">
    <span class="popup-btn-close">
      ESC
    </span>
    <div class="container">
      <div class="col-md-8 col-md-offset-2">

        <div class="local-search-header clearfix">
            <span class="search-icon"></span>
            <div class="local-search-input-wrapper">
              <input autocomplete="off" placeholder="Search..." type="text" id="local-search-input">
            </div>
        </div>

        <div id="local-search-result"></div>

      </div>
    </div>
</div>

<script src="/js/ziploader.js"></script>


  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.json";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').fadeOut(300);
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $('.popup').fadeIn(300);
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // get search zip version
    $.get('/searchVersion.txt?t=' + (+new Date()), function(res) {
      if (localStorage.getItem('searchVersion') !== res) {
        localStorage.setItem('searchVersion', res);
        initSearchJson();
      }
    });

    function initSearchJson () {
      initLoad(['/search.zip'], {
        loadOptions: {
          success: function(obj) {
            localStorage.setItem('searchJson', obj['search.json'])
          },
          error: function(e) {
            return console.log(e)
          }
        },
        returnOptions: {
          'json': TYPE_TEXT
        },
        mimeOptions:{
          'json':'application/json'
        }
      })
    }

    // search function;
    var searchFunc = function(search_id, content_id) {
      'use strict';

      isfetched = true;
      var datas = JSON.parse(localStorage.getItem('searchJson'));
      console.log(search_id)
      var input = document.getElementById(search_id);
      var resultContent = document.getElementById(content_id);
      var inputEventFunction = function() {
        var searchText = input.value.trim().toLowerCase();
        var keywords = searchText.split(/[\s\-]+/);
        if (keywords.length > 1) {
          keywords.push(searchText);
        }
        var resultItems = [];
        if (searchText.length > 0) {
          // perform local searching
          datas.forEach(function(data) {
            var isMatch = false;
            var hitCount = 0;
            var searchTextCount = 0;
            var title = data.title ? data.title.trim() : '';
            var titleInLowerCase = title.toLowerCase();
            var content = data.content ? data.content.trim().replace(/<[^>]+>/g,"") : '';
            var contentInLowerCase = content.toLowerCase();
            var articleUrl = decodeURIComponent(data.url);
            var indexOfTitle = [];
            var indexOfContent = [];
            // only match articles with not empty titles
            keywords.forEach(function(keyword) {
              function getIndexByWord(word, text, caseSensitive) {
                var wordLen = word.length;
                if (wordLen === 0) {
                  return [];
                }
                var startPosition = 0, position = [], index = [];
                if (!caseSensitive) {
                  text = text.toLowerCase();
                  word = word.toLowerCase();
                }
                while ((position = text.indexOf(word, startPosition)) > -1) {
                  index.push({position: position, word: word});
                  startPosition = position + wordLen;
                }
                return index;
              }

              indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
              indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
            });
            if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
              isMatch = true;
              hitCount = indexOfTitle.length + indexOfContent.length;
            }

            // show search results

            if (isMatch) {
              // sort index by position of keyword

              [indexOfTitle, indexOfContent].forEach(function (index) {
                index.sort(function (itemLeft, itemRight) {
                  if (itemRight.position !== itemLeft.position) {
                    return itemRight.position - itemLeft.position;
                  } else {
                    return itemLeft.word.length - itemRight.word.length;
                  }
                });
              });

              // merge hits into slices

              function mergeIntoSlice(text, start, end, index) {
                var item = index[index.length - 1];
                var position = item.position;
                var word = item.word;
                var hits = [];
                var searchTextCountInSlice = 0;
                while (position + word.length <= end && index.length != 0) {
                  if (word === searchText) {
                    searchTextCountInSlice++;
                  }
                  hits.push({position: position, length: word.length});
                  var wordEnd = position + word.length;

                  // move to next position of hit

                  index.pop();
                  while (index.length != 0) {
                    item = index[index.length - 1];
                    position = item.position;
                    word = item.word;
                    if (wordEnd > position) {
                      index.pop();
                    } else {
                      break;
                    }
                  }
                }
                searchTextCount += searchTextCountInSlice;
                return {
                  hits: hits,
                  start: start,
                  end: end,
                  searchTextCount: searchTextCountInSlice
                };
              }

              var slicesOfTitle = [];
              if (indexOfTitle.length != 0) {
                slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
              }

              var slicesOfContent = [];
              while (indexOfContent.length != 0) {
                var item = indexOfContent[indexOfContent.length - 1];
                var position = item.position;
                var word = item.word;
                // cut out 100 characters
                var start = position - 20;
                var end = position + 80;
                if(start < 0){
                  start = 0;
                }
                if (end < position + word.length) {
                  end = position + word.length;
                }
                if(end > content.length){
                  end = content.length;
                }
                slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
              }

              // sort slices in content by search text's count and hits' count

              slicesOfContent.sort(function (sliceLeft, sliceRight) {
                if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                  return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                  return sliceRight.hits.length - sliceLeft.hits.length;
                } else {
                  return sliceLeft.start - sliceRight.start;
                }
              });

              // select top N slices in content

              var upperBound = parseInt('2');
              if (upperBound >= 0) {
                slicesOfContent = slicesOfContent.slice(0, upperBound);
              }

              // highlight title and content

              function highlightKeyword(text, slice) {
                var result = '';
                var prevEnd = slice.start;
                slice.hits.forEach(function (hit) {
                  result += text.substring(prevEnd, hit.position);
                  var end = hit.position + hit.length;
                  result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                  prevEnd = end;
                });
                result += text.substring(prevEnd, slice.end);
                return result;
              }

              var resultItem = '';

              if (slicesOfTitle.length != 0) {
                resultItem += "<li><a target='_blank' href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
              } else {
                resultItem += "<li><a target='_blank' href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
              }

              slicesOfContent.forEach(function (slice) {
                resultItem +=  "<p class=\"search-result\">" + highlightKeyword(content, slice) + "...</p>";
              });

              resultItem += "</li>";
              resultItems.push({
                item: resultItem,
                searchTextCount: searchTextCount,
                hitCount: hitCount,
                id: resultItems.length
              });
            }
          })
        };
        if (keywords.length === 1 && keywords[0] === "") {
          resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
        } else if (resultItems.length === 0) {
          resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /> no result </div>'
        } else {
          resultItems.sort(function (resultLeft, resultRight) {
            if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
              return resultRight.searchTextCount - resultLeft.searchTextCount;
            } else if (resultLeft.hitCount !== resultRight.hitCount) {
              return resultRight.hitCount - resultLeft.hitCount;
            } else {
              return resultRight.id - resultLeft.id;
            }
          });
          var searchResultList = '<ul class=\"search-result-list\">';
          resultItems.forEach(function (result) {
            searchResultList += result.item;
          })
          searchResultList += "</ul>";
          resultContent.innerHTML = searchResultList;
        }
      }

      if ('auto' === 'auto') {
        input.addEventListener('input', inputEventFunction);
      } else {
        $('.search-icon').click(inputEventFunction);
        input.addEventListener('keypress', function (event) {
          if (event.keyCode === 13) {
            inputEventFunction();
          }
        });
      }

      // remove loading animation
      $('body').css('overflow', '');

      proceedsearch();
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        $('.sb-close').click();
        searchFunc('local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





	<script type="text/javascript" src="/js/love.js"></script>



	<script type="text/javascript" src="/js/toc.js"></script>


<script type="text/javascript" src="/js/main.js"></script>

<script type="text/javascript">
	//generate a random img that pre_name 'from 0 to 110'
	var random_bg = Math.floor(Math.random() * 109 + 1);

	//var bg = 'url(/img/random/' + random_bg + '.jpg)';		
	var bg = 'url(https://zhang666xin.github.io/Random-img/' + random_bg + '.jpg)';

	$("#header-bg-2").css("background-image", bg);
</script>
<div style="position:absolute; bottom:120px; left:36px;width:76%;">
<iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=86 src="//music.163.com/outchain/player?type=2&id=41500546&auto=1&height=66"></iframe>
</div>
		
		<!--back to top-->
        <style type="text/css">
	#totop {
		background: white;
		border-radius: 50%;
		position: fixed;
		right: 5.4%;
		bottom: 80px;
		cursor: pointer;
	}
	
	#totop a {
		color: #474747;
		background-color: transparent;
		padding: 10px;
		text-decoration: none;
	}
	
	@media(max-width:512px) {
		#totop {
			display: none;
			visibility: hidden;
		}
	}
</style>


	<div id="totop">
  		<a href="javascript:;" class="fa fa-arrow-up"></a>
	</div>

	<script src="/live2dw/lib/L2Dwidget.min.js?0c58a1486de42ac6cc1c59c7d98ae887"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>
	</html>

